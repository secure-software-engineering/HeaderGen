{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34510209",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "source_hidden": true
   },
   "source": [
    "### Index of ML Operations<a id='top_phases'></a>\n",
    "<div><ul>\n",
    "<ul><li><details><summary style='list-style: none; cursor: pointer;'><strong>Imported Libraries</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li><b>numpy</b></li>\n",
    "<li><b>pandas</b></li>\n",
    "<li><b>scipy</b></li>\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none; cursor: pointer;'><strong>Visualization</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li><details><summary style='list-style: none; cursor: pointer;'><u>View All \"Visualization\" Calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.dendrogram</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [] | <b>Kwargs:</b> {'no_plot': True, 'get_leaves': True}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Plot the hierarchical clustering as a dendrogram.\n",
    "\n",
    "The dendrogram illustrates how each cluster is\n",
    "composed by drawing a U-shaped link between a non-singleton\n",
    "cluster and its children. The top of the U-link indicates a\n",
    "cluster merge. The two legs of the U-link indicate which clusters\n",
    "were merged. The length of the two legs of the U-link represents\n",
    "the distance between the child clusters. It is also the\n",
    "cophenetic distance between original observations in the two\n",
    "children clusters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The linkage matrix encoding the hierarchical clustering to\n",
    "    render as a dendrogram. See the ``linkage`` function for more\n",
    "    information on the format of ``Z``.\n",
    "p : int, optional\n",
    "    The ``p`` parameter for ``truncate_mode``.\n",
    "truncate_mode : str, optional\n",
    "    The dendrogram can be hard to read when the original\n",
    "    observation matrix from which the linkage is derived is\n",
    "    large. Truncation is used to condense the dendrogram. There\n",
    "    are several modes:\n",
    "\n",
    "    ``None``\n",
    "      No truncation is performed (default).\n",
    "      Note: ``'none'`` is an alias for ``None`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "    ``'lastp'``\n",
    "      The last ``p`` non-singleton clusters formed in the linkage are the\n",
    "      only non-leaf nodes in the linkage; they correspond to rows\n",
    "      ``Z[n-p-2:end]`` in ``Z``. All other non-singleton clusters are\n",
    "      contracted into leaf nodes.\n",
    "\n",
    "    ``'level'``\n",
    "      No more than ``p`` levels of the dendrogram tree are displayed.\n",
    "      A \"level\" includes all nodes with ``p`` merges from the final merge.\n",
    "\n",
    "      Note: ``'mtica'`` is an alias for ``'level'`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "color_threshold : double, optional\n",
    "    For brevity, let :math:`t` be the ``color_threshold``.\n",
    "    Colors all the descendent links below a cluster node\n",
    "    :math:`k` the same color if :math:`k` is the first node below\n",
    "    the cut threshold :math:`t`. All links connecting nodes with\n",
    "    distances greater than or equal to the threshold are colored\n",
    "    with de default matplotlib color ``'C0'``. If :math:`t` is less\n",
    "    than or equal to zero, all nodes are colored ``'C0'``.\n",
    "    If ``color_threshold`` is None or 'default',\n",
    "    corresponding with MATLAB(TM) behavior, the threshold is set to\n",
    "    ``0.7*max(Z[:,2])``.\n",
    "\n",
    "get_leaves : bool, optional\n",
    "    Includes a list ``R['leaves']=H`` in the result\n",
    "    dictionary. For each :math:`i`, ``H[i] == j``, cluster node\n",
    "    ``j`` appears in position ``i`` in the left-to-right traversal\n",
    "    of the leaves, where :math:`j < 2n-1` and :math:`i < n`.\n",
    "orientation : str, optional\n",
    "    The direction to plot the dendrogram, which can be any\n",
    "    of the following strings:\n",
    "\n",
    "    ``'top'``\n",
    "      Plots the root at the top, and plot descendent links going downwards.\n",
    "      (default).\n",
    "\n",
    "    ``'bottom'``\n",
    "      Plots the root at the bottom, and plot descendent links going\n",
    "      upwards.\n",
    "\n",
    "    ``'left'``\n",
    "      Plots the root at the left, and plot descendent links going right.\n",
    "\n",
    "    ``'right'``\n",
    "      Plots the root at the right, and plot descendent links going left.\n",
    "\n",
    "labels : ndarray, optional\n",
    "    By default, ``labels`` is None so the index of the original observation\n",
    "    is used to label the leaf nodes.  Otherwise, this is an :math:`n`-sized\n",
    "    sequence, with ``n == Z.shape[0] + 1``. The ``labels[i]`` value is the\n",
    "    text to put under the :math:`i` th leaf node only if it corresponds to\n",
    "    an original observation and not a non-singleton cluster.\n",
    "count_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    Note, ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "distance_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    Note ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "show_leaf_counts : bool, optional\n",
    "     When True, leaf nodes representing :math:`k>1` original\n",
    "     observation are labeled with the number of observations they\n",
    "     contain in parentheses.\n",
    "no_plot : bool, optional\n",
    "    When True, the final rendering is not performed. This is\n",
    "    useful if only the data structures computed for the rendering\n",
    "    are needed or if matplotlib is not available.\n",
    "no_labels : bool, optional\n",
    "    When True, no labels appear next to the leaf nodes in the\n",
    "    rendering of the dendrogram.\n",
    "leaf_rotation : double, optional\n",
    "    Specifies the angle (in degrees) to rotate the leaf\n",
    "    labels. When unspecified, the rotation is based on the number of\n",
    "    nodes in the dendrogram (default is 0).\n",
    "leaf_font_size : int, optional\n",
    "    Specifies the font size (in points) of the leaf labels. When\n",
    "    unspecified, the size based on the number of nodes in the\n",
    "    dendrogram.\n",
    "leaf_label_func : lambda or function, optional\n",
    "    When ``leaf_label_func`` is a callable function, for each\n",
    "    leaf with cluster index :math:`k < 2n-1`. The function\n",
    "    is expected to return a string with the label for the\n",
    "    leaf.\n",
    "\n",
    "    Indices :math:`k < n` correspond to original observations\n",
    "    while indices :math:`k \\geq n` correspond to non-singleton\n",
    "    clusters.\n",
    "\n",
    "    For example, to label singletons with their node id and\n",
    "    non-singletons with their id, count, and inconsistency\n",
    "    coefficient, simply do::\n",
    "\n",
    "        # First define the leaf label function.\n",
    "        def llf(id):\n",
    "            if id < n:\n",
    "                return str(id)\n",
    "            else:\n",
    "                return '[%d %d %1.2f]' % (id, count, R[n-id,3])\n",
    "\n",
    "        # The text for the leaf nodes is going to be big so force\n",
    "        # a rotation of 90 degrees.\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90)\n",
    "\n",
    "        # leaf_label_func can also be used together with ``truncate_mode`` parameter,\n",
    "        # in which case you will get your leaves labeled after truncation:\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90,\n",
    "                   truncate_mode='level', p=2)\n",
    "\n",
    "show_contracted : bool, optional\n",
    "    When True the heights of non-singleton nodes contracted\n",
    "    into a leaf node are plotted as crosses along the link\n",
    "    connecting that leaf node.  This really is only useful when\n",
    "    truncation is used (see ``truncate_mode`` parameter).\n",
    "link_color_func : callable, optional\n",
    "    If given, `link_color_function` is called with each non-singleton id\n",
    "    corresponding to each U-shaped link it will paint. The function is\n",
    "    expected to return the color to paint the link, encoded as a matplotlib\n",
    "    color string code. For example::\n",
    "\n",
    "        dendrogram(Z, link_color_func=lambda k: colors[k])\n",
    "\n",
    "    colors the direct links below each untruncated non-singleton node\n",
    "    ``k`` using ``colors[k]``.\n",
    "ax : matplotlib Axes instance, optional\n",
    "    If None and `no_plot` is not True, the dendrogram will be plotted\n",
    "    on the current axes.  Otherwise if `no_plot` is not True the\n",
    "    dendrogram will be plotted on the given ``Axes`` instance. This can be\n",
    "    useful if the dendrogram is part of a more complex figure.\n",
    "above_threshold_color : str, optional\n",
    "    This matplotlib color string sets the color of the links above the\n",
    "    color_threshold. The default is ``'C0'``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : dict\n",
    "    A dictionary of data structures computed to render the\n",
    "    dendrogram. Its has the following keys:\n",
    "\n",
    "    ``'color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th link.\n",
    "\n",
    "    ``'icoord'`` and ``'dcoord'``\n",
    "      Each of them is a list of lists. Let ``icoord = [I1, I2, ..., Ip]``\n",
    "      where ``Ik = [xk1, xk2, xk3, xk4]`` and ``dcoord = [D1, D2, ..., Dp]``\n",
    "      where ``Dk = [yk1, yk2, yk3, yk4]``, then the k'th link painted is\n",
    "      ``(xk1, yk1)`` - ``(xk2, yk2)`` - ``(xk3, yk3)`` - ``(xk4, yk4)``.\n",
    "\n",
    "    ``'ivl'``\n",
    "      A list of labels corresponding to the leaf nodes.\n",
    "\n",
    "    ``'leaves'``\n",
    "      For each i, ``H[i] == j``, cluster node ``j`` appears in position\n",
    "      ``i`` in the left-to-right traversal of the leaves, where\n",
    "      :math:`j < 2n-1` and :math:`i < n`. If ``j`` is less than ``n``, the\n",
    "      ``i``-th leaf node corresponds to an original observation.\n",
    "      Otherwise, it corresponds to a non-singleton cluster.\n",
    "\n",
    "    ``'leaves_color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th leaf.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage, set_link_color_palette\n",
    "\n",
    "Notes\n",
    "-----\n",
    "It is expected that the distances in ``Z[:,2]`` be monotonic, otherwise\n",
    "crossings appear in the dendrogram.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import numpy as np\n",
    ">>> from scipy.cluster import hierarchy\n",
    ">>> import matplotlib.pyplot as plt\n",
    "\n",
    "A very basic example:\n",
    "\n",
    ">>> ytdist = np.array([662., 877., 255., 412., 996., 295., 468., 268.,\n",
    "...                    400., 754., 564., 138., 219., 869., 669.])\n",
    ">>> Z = hierarchy.linkage(ytdist, 'single')\n",
    ">>> plt.figure()\n",
    ">>> dn = hierarchy.dendrogram(Z)\n",
    "\n",
    "Now, plot in given axes, improve the color scheme and use both vertical and\n",
    "horizontal orientations:\n",
    "\n",
    ">>> hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    ">>> fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    ">>> dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "...                            orientation='top')\n",
    ">>> dn2 = hierarchy.dendrogram(Z, ax=axes[1],\n",
    "...                            above_threshold_color='#bcbddc',\n",
    "...                            orientation='right')\n",
    ">>> hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 21</u></strong></summary><small><a href=#21>goto cell # 21</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.dendrogram</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [] | <b>Kwargs:</b> {'no_plot': True, 'get_leaves': True}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Plot the hierarchical clustering as a dendrogram.\n",
    "\n",
    "The dendrogram illustrates how each cluster is\n",
    "composed by drawing a U-shaped link between a non-singleton\n",
    "cluster and its children. The top of the U-link indicates a\n",
    "cluster merge. The two legs of the U-link indicate which clusters\n",
    "were merged. The length of the two legs of the U-link represents\n",
    "the distance between the child clusters. It is also the\n",
    "cophenetic distance between original observations in the two\n",
    "children clusters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The linkage matrix encoding the hierarchical clustering to\n",
    "    render as a dendrogram. See the ``linkage`` function for more\n",
    "    information on the format of ``Z``.\n",
    "p : int, optional\n",
    "    The ``p`` parameter for ``truncate_mode``.\n",
    "truncate_mode : str, optional\n",
    "    The dendrogram can be hard to read when the original\n",
    "    observation matrix from which the linkage is derived is\n",
    "    large. Truncation is used to condense the dendrogram. There\n",
    "    are several modes:\n",
    "\n",
    "    ``None``\n",
    "      No truncation is performed (default).\n",
    "      Note: ``'none'`` is an alias for ``None`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "    ``'lastp'``\n",
    "      The last ``p`` non-singleton clusters formed in the linkage are the\n",
    "      only non-leaf nodes in the linkage; they correspond to rows\n",
    "      ``Z[n-p-2:end]`` in ``Z``. All other non-singleton clusters are\n",
    "      contracted into leaf nodes.\n",
    "\n",
    "    ``'level'``\n",
    "      No more than ``p`` levels of the dendrogram tree are displayed.\n",
    "      A \"level\" includes all nodes with ``p`` merges from the final merge.\n",
    "\n",
    "      Note: ``'mtica'`` is an alias for ``'level'`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "color_threshold : double, optional\n",
    "    For brevity, let :math:`t` be the ``color_threshold``.\n",
    "    Colors all the descendent links below a cluster node\n",
    "    :math:`k` the same color if :math:`k` is the first node below\n",
    "    the cut threshold :math:`t`. All links connecting nodes with\n",
    "    distances greater than or equal to the threshold are colored\n",
    "    with de default matplotlib color ``'C0'``. If :math:`t` is less\n",
    "    than or equal to zero, all nodes are colored ``'C0'``.\n",
    "    If ``color_threshold`` is None or 'default',\n",
    "    corresponding with MATLAB(TM) behavior, the threshold is set to\n",
    "    ``0.7*max(Z[:,2])``.\n",
    "\n",
    "get_leaves : bool, optional\n",
    "    Includes a list ``R['leaves']=H`` in the result\n",
    "    dictionary. For each :math:`i`, ``H[i] == j``, cluster node\n",
    "    ``j`` appears in position ``i`` in the left-to-right traversal\n",
    "    of the leaves, where :math:`j < 2n-1` and :math:`i < n`.\n",
    "orientation : str, optional\n",
    "    The direction to plot the dendrogram, which can be any\n",
    "    of the following strings:\n",
    "\n",
    "    ``'top'``\n",
    "      Plots the root at the top, and plot descendent links going downwards.\n",
    "      (default).\n",
    "\n",
    "    ``'bottom'``\n",
    "      Plots the root at the bottom, and plot descendent links going\n",
    "      upwards.\n",
    "\n",
    "    ``'left'``\n",
    "      Plots the root at the left, and plot descendent links going right.\n",
    "\n",
    "    ``'right'``\n",
    "      Plots the root at the right, and plot descendent links going left.\n",
    "\n",
    "labels : ndarray, optional\n",
    "    By default, ``labels`` is None so the index of the original observation\n",
    "    is used to label the leaf nodes.  Otherwise, this is an :math:`n`-sized\n",
    "    sequence, with ``n == Z.shape[0] + 1``. The ``labels[i]`` value is the\n",
    "    text to put under the :math:`i` th leaf node only if it corresponds to\n",
    "    an original observation and not a non-singleton cluster.\n",
    "count_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    Note, ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "distance_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    Note ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "show_leaf_counts : bool, optional\n",
    "     When True, leaf nodes representing :math:`k>1` original\n",
    "     observation are labeled with the number of observations they\n",
    "     contain in parentheses.\n",
    "no_plot : bool, optional\n",
    "    When True, the final rendering is not performed. This is\n",
    "    useful if only the data structures computed for the rendering\n",
    "    are needed or if matplotlib is not available.\n",
    "no_labels : bool, optional\n",
    "    When True, no labels appear next to the leaf nodes in the\n",
    "    rendering of the dendrogram.\n",
    "leaf_rotation : double, optional\n",
    "    Specifies the angle (in degrees) to rotate the leaf\n",
    "    labels. When unspecified, the rotation is based on the number of\n",
    "    nodes in the dendrogram (default is 0).\n",
    "leaf_font_size : int, optional\n",
    "    Specifies the font size (in points) of the leaf labels. When\n",
    "    unspecified, the size based on the number of nodes in the\n",
    "    dendrogram.\n",
    "leaf_label_func : lambda or function, optional\n",
    "    When ``leaf_label_func`` is a callable function, for each\n",
    "    leaf with cluster index :math:`k < 2n-1`. The function\n",
    "    is expected to return a string with the label for the\n",
    "    leaf.\n",
    "\n",
    "    Indices :math:`k < n` correspond to original observations\n",
    "    while indices :math:`k \\geq n` correspond to non-singleton\n",
    "    clusters.\n",
    "\n",
    "    For example, to label singletons with their node id and\n",
    "    non-singletons with their id, count, and inconsistency\n",
    "    coefficient, simply do::\n",
    "\n",
    "        # First define the leaf label function.\n",
    "        def llf(id):\n",
    "            if id < n:\n",
    "                return str(id)\n",
    "            else:\n",
    "                return '[%d %d %1.2f]' % (id, count, R[n-id,3])\n",
    "\n",
    "        # The text for the leaf nodes is going to be big so force\n",
    "        # a rotation of 90 degrees.\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90)\n",
    "\n",
    "        # leaf_label_func can also be used together with ``truncate_mode`` parameter,\n",
    "        # in which case you will get your leaves labeled after truncation:\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90,\n",
    "                   truncate_mode='level', p=2)\n",
    "\n",
    "show_contracted : bool, optional\n",
    "    When True the heights of non-singleton nodes contracted\n",
    "    into a leaf node are plotted as crosses along the link\n",
    "    connecting that leaf node.  This really is only useful when\n",
    "    truncation is used (see ``truncate_mode`` parameter).\n",
    "link_color_func : callable, optional\n",
    "    If given, `link_color_function` is called with each non-singleton id\n",
    "    corresponding to each U-shaped link it will paint. The function is\n",
    "    expected to return the color to paint the link, encoded as a matplotlib\n",
    "    color string code. For example::\n",
    "\n",
    "        dendrogram(Z, link_color_func=lambda k: colors[k])\n",
    "\n",
    "    colors the direct links below each untruncated non-singleton node\n",
    "    ``k`` using ``colors[k]``.\n",
    "ax : matplotlib Axes instance, optional\n",
    "    If None and `no_plot` is not True, the dendrogram will be plotted\n",
    "    on the current axes.  Otherwise if `no_plot` is not True the\n",
    "    dendrogram will be plotted on the given ``Axes`` instance. This can be\n",
    "    useful if the dendrogram is part of a more complex figure.\n",
    "above_threshold_color : str, optional\n",
    "    This matplotlib color string sets the color of the links above the\n",
    "    color_threshold. The default is ``'C0'``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : dict\n",
    "    A dictionary of data structures computed to render the\n",
    "    dendrogram. Its has the following keys:\n",
    "\n",
    "    ``'color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th link.\n",
    "\n",
    "    ``'icoord'`` and ``'dcoord'``\n",
    "      Each of them is a list of lists. Let ``icoord = [I1, I2, ..., Ip]``\n",
    "      where ``Ik = [xk1, xk2, xk3, xk4]`` and ``dcoord = [D1, D2, ..., Dp]``\n",
    "      where ``Dk = [yk1, yk2, yk3, yk4]``, then the k'th link painted is\n",
    "      ``(xk1, yk1)`` - ``(xk2, yk2)`` - ``(xk3, yk3)`` - ``(xk4, yk4)``.\n",
    "\n",
    "    ``'ivl'``\n",
    "      A list of labels corresponding to the leaf nodes.\n",
    "\n",
    "    ``'leaves'``\n",
    "      For each i, ``H[i] == j``, cluster node ``j`` appears in position\n",
    "      ``i`` in the left-to-right traversal of the leaves, where\n",
    "      :math:`j < 2n-1` and :math:`i < n`. If ``j`` is less than ``n``, the\n",
    "      ``i``-th leaf node corresponds to an original observation.\n",
    "      Otherwise, it corresponds to a non-singleton cluster.\n",
    "\n",
    "    ``'leaves_color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th leaf.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage, set_link_color_palette\n",
    "\n",
    "Notes\n",
    "-----\n",
    "It is expected that the distances in ``Z[:,2]`` be monotonic, otherwise\n",
    "crossings appear in the dendrogram.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import numpy as np\n",
    ">>> from scipy.cluster import hierarchy\n",
    ">>> import matplotlib.pyplot as plt\n",
    "\n",
    "A very basic example:\n",
    "\n",
    ">>> ytdist = np.array([662., 877., 255., 412., 996., 295., 468., 268.,\n",
    "...                    400., 754., 564., 138., 219., 869., 669.])\n",
    ">>> Z = hierarchy.linkage(ytdist, 'single')\n",
    ">>> plt.figure()\n",
    ">>> dn = hierarchy.dendrogram(Z)\n",
    "\n",
    "Now, plot in given axes, improve the color scheme and use both vertical and\n",
    "horizontal orientations:\n",
    "\n",
    ">>> hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    ">>> fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    ">>> dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "...                            orientation='top')\n",
    ">>> dn2 = hierarchy.dendrogram(Z, ax=axes[1],\n",
    "...                            above_threshold_color='#bcbddc',\n",
    "...                            orientation='right')\n",
    ">>> hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 27</u></strong></summary><small><a href=#27>goto cell # 27</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.dendrogram</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [] | <b>Kwargs:</b> {'no_plot': True, 'get_leaves': True}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Plot the hierarchical clustering as a dendrogram.\n",
    "\n",
    "The dendrogram illustrates how each cluster is\n",
    "composed by drawing a U-shaped link between a non-singleton\n",
    "cluster and its children. The top of the U-link indicates a\n",
    "cluster merge. The two legs of the U-link indicate which clusters\n",
    "were merged. The length of the two legs of the U-link represents\n",
    "the distance between the child clusters. It is also the\n",
    "cophenetic distance between original observations in the two\n",
    "children clusters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The linkage matrix encoding the hierarchical clustering to\n",
    "    render as a dendrogram. See the ``linkage`` function for more\n",
    "    information on the format of ``Z``.\n",
    "p : int, optional\n",
    "    The ``p`` parameter for ``truncate_mode``.\n",
    "truncate_mode : str, optional\n",
    "    The dendrogram can be hard to read when the original\n",
    "    observation matrix from which the linkage is derived is\n",
    "    large. Truncation is used to condense the dendrogram. There\n",
    "    are several modes:\n",
    "\n",
    "    ``None``\n",
    "      No truncation is performed (default).\n",
    "      Note: ``'none'`` is an alias for ``None`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "    ``'lastp'``\n",
    "      The last ``p`` non-singleton clusters formed in the linkage are the\n",
    "      only non-leaf nodes in the linkage; they correspond to rows\n",
    "      ``Z[n-p-2:end]`` in ``Z``. All other non-singleton clusters are\n",
    "      contracted into leaf nodes.\n",
    "\n",
    "    ``'level'``\n",
    "      No more than ``p`` levels of the dendrogram tree are displayed.\n",
    "      A \"level\" includes all nodes with ``p`` merges from the final merge.\n",
    "\n",
    "      Note: ``'mtica'`` is an alias for ``'level'`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "color_threshold : double, optional\n",
    "    For brevity, let :math:`t` be the ``color_threshold``.\n",
    "    Colors all the descendent links below a cluster node\n",
    "    :math:`k` the same color if :math:`k` is the first node below\n",
    "    the cut threshold :math:`t`. All links connecting nodes with\n",
    "    distances greater than or equal to the threshold are colored\n",
    "    with de default matplotlib color ``'C0'``. If :math:`t` is less\n",
    "    than or equal to zero, all nodes are colored ``'C0'``.\n",
    "    If ``color_threshold`` is None or 'default',\n",
    "    corresponding with MATLAB(TM) behavior, the threshold is set to\n",
    "    ``0.7*max(Z[:,2])``.\n",
    "\n",
    "get_leaves : bool, optional\n",
    "    Includes a list ``R['leaves']=H`` in the result\n",
    "    dictionary. For each :math:`i`, ``H[i] == j``, cluster node\n",
    "    ``j`` appears in position ``i`` in the left-to-right traversal\n",
    "    of the leaves, where :math:`j < 2n-1` and :math:`i < n`.\n",
    "orientation : str, optional\n",
    "    The direction to plot the dendrogram, which can be any\n",
    "    of the following strings:\n",
    "\n",
    "    ``'top'``\n",
    "      Plots the root at the top, and plot descendent links going downwards.\n",
    "      (default).\n",
    "\n",
    "    ``'bottom'``\n",
    "      Plots the root at the bottom, and plot descendent links going\n",
    "      upwards.\n",
    "\n",
    "    ``'left'``\n",
    "      Plots the root at the left, and plot descendent links going right.\n",
    "\n",
    "    ``'right'``\n",
    "      Plots the root at the right, and plot descendent links going left.\n",
    "\n",
    "labels : ndarray, optional\n",
    "    By default, ``labels`` is None so the index of the original observation\n",
    "    is used to label the leaf nodes.  Otherwise, this is an :math:`n`-sized\n",
    "    sequence, with ``n == Z.shape[0] + 1``. The ``labels[i]`` value is the\n",
    "    text to put under the :math:`i` th leaf node only if it corresponds to\n",
    "    an original observation and not a non-singleton cluster.\n",
    "count_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    Note, ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "distance_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    Note ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "show_leaf_counts : bool, optional\n",
    "     When True, leaf nodes representing :math:`k>1` original\n",
    "     observation are labeled with the number of observations they\n",
    "     contain in parentheses.\n",
    "no_plot : bool, optional\n",
    "    When True, the final rendering is not performed. This is\n",
    "    useful if only the data structures computed for the rendering\n",
    "    are needed or if matplotlib is not available.\n",
    "no_labels : bool, optional\n",
    "    When True, no labels appear next to the leaf nodes in the\n",
    "    rendering of the dendrogram.\n",
    "leaf_rotation : double, optional\n",
    "    Specifies the angle (in degrees) to rotate the leaf\n",
    "    labels. When unspecified, the rotation is based on the number of\n",
    "    nodes in the dendrogram (default is 0).\n",
    "leaf_font_size : int, optional\n",
    "    Specifies the font size (in points) of the leaf labels. When\n",
    "    unspecified, the size based on the number of nodes in the\n",
    "    dendrogram.\n",
    "leaf_label_func : lambda or function, optional\n",
    "    When ``leaf_label_func`` is a callable function, for each\n",
    "    leaf with cluster index :math:`k < 2n-1`. The function\n",
    "    is expected to return a string with the label for the\n",
    "    leaf.\n",
    "\n",
    "    Indices :math:`k < n` correspond to original observations\n",
    "    while indices :math:`k \\geq n` correspond to non-singleton\n",
    "    clusters.\n",
    "\n",
    "    For example, to label singletons with their node id and\n",
    "    non-singletons with their id, count, and inconsistency\n",
    "    coefficient, simply do::\n",
    "\n",
    "        # First define the leaf label function.\n",
    "        def llf(id):\n",
    "            if id < n:\n",
    "                return str(id)\n",
    "            else:\n",
    "                return '[%d %d %1.2f]' % (id, count, R[n-id,3])\n",
    "\n",
    "        # The text for the leaf nodes is going to be big so force\n",
    "        # a rotation of 90 degrees.\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90)\n",
    "\n",
    "        # leaf_label_func can also be used together with ``truncate_mode`` parameter,\n",
    "        # in which case you will get your leaves labeled after truncation:\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90,\n",
    "                   truncate_mode='level', p=2)\n",
    "\n",
    "show_contracted : bool, optional\n",
    "    When True the heights of non-singleton nodes contracted\n",
    "    into a leaf node are plotted as crosses along the link\n",
    "    connecting that leaf node.  This really is only useful when\n",
    "    truncation is used (see ``truncate_mode`` parameter).\n",
    "link_color_func : callable, optional\n",
    "    If given, `link_color_function` is called with each non-singleton id\n",
    "    corresponding to each U-shaped link it will paint. The function is\n",
    "    expected to return the color to paint the link, encoded as a matplotlib\n",
    "    color string code. For example::\n",
    "\n",
    "        dendrogram(Z, link_color_func=lambda k: colors[k])\n",
    "\n",
    "    colors the direct links below each untruncated non-singleton node\n",
    "    ``k`` using ``colors[k]``.\n",
    "ax : matplotlib Axes instance, optional\n",
    "    If None and `no_plot` is not True, the dendrogram will be plotted\n",
    "    on the current axes.  Otherwise if `no_plot` is not True the\n",
    "    dendrogram will be plotted on the given ``Axes`` instance. This can be\n",
    "    useful if the dendrogram is part of a more complex figure.\n",
    "above_threshold_color : str, optional\n",
    "    This matplotlib color string sets the color of the links above the\n",
    "    color_threshold. The default is ``'C0'``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : dict\n",
    "    A dictionary of data structures computed to render the\n",
    "    dendrogram. Its has the following keys:\n",
    "\n",
    "    ``'color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th link.\n",
    "\n",
    "    ``'icoord'`` and ``'dcoord'``\n",
    "      Each of them is a list of lists. Let ``icoord = [I1, I2, ..., Ip]``\n",
    "      where ``Ik = [xk1, xk2, xk3, xk4]`` and ``dcoord = [D1, D2, ..., Dp]``\n",
    "      where ``Dk = [yk1, yk2, yk3, yk4]``, then the k'th link painted is\n",
    "      ``(xk1, yk1)`` - ``(xk2, yk2)`` - ``(xk3, yk3)`` - ``(xk4, yk4)``.\n",
    "\n",
    "    ``'ivl'``\n",
    "      A list of labels corresponding to the leaf nodes.\n",
    "\n",
    "    ``'leaves'``\n",
    "      For each i, ``H[i] == j``, cluster node ``j`` appears in position\n",
    "      ``i`` in the left-to-right traversal of the leaves, where\n",
    "      :math:`j < 2n-1` and :math:`i < n`. If ``j`` is less than ``n``, the\n",
    "      ``i``-th leaf node corresponds to an original observation.\n",
    "      Otherwise, it corresponds to a non-singleton cluster.\n",
    "\n",
    "    ``'leaves_color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th leaf.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage, set_link_color_palette\n",
    "\n",
    "Notes\n",
    "-----\n",
    "It is expected that the distances in ``Z[:,2]`` be monotonic, otherwise\n",
    "crossings appear in the dendrogram.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import numpy as np\n",
    ">>> from scipy.cluster import hierarchy\n",
    ">>> import matplotlib.pyplot as plt\n",
    "\n",
    "A very basic example:\n",
    "\n",
    ">>> ytdist = np.array([662., 877., 255., 412., 996., 295., 468., 268.,\n",
    "...                    400., 754., 564., 138., 219., 869., 669.])\n",
    ">>> Z = hierarchy.linkage(ytdist, 'single')\n",
    ">>> plt.figure()\n",
    ">>> dn = hierarchy.dendrogram(Z)\n",
    "\n",
    "Now, plot in given axes, improve the color scheme and use both vertical and\n",
    "horizontal orientations:\n",
    "\n",
    ">>> hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    ">>> fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    ">>> dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "...                            orientation='top')\n",
    ">>> dn2 = hierarchy.dendrogram(Z, ax=axes[1],\n",
    "...                            above_threshold_color='#bcbddc',\n",
    "...                            orientation='right')\n",
    ">>> hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<li><details><summary style='list-style: none;'><h3><span style='color:#42a5f5'>Data Preparation</span></h3></summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Data Profiling and Exploratory Data Analysis</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Data Cleaning Filtering</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Data Sub-sampling and Train-test Splitting</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<li><details><summary style='list-style: none;'><h3><span style='color:#42a5f5'>Feature Engineering</span></h3></summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Feature Transformation</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Feature Selection</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<li><details><summary style='list-style: none;'><h3><span style='color:#42a5f5'>Model Building and Training</span></h3></summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<ul><li><details><summary style='list-style: none; cursor: pointer;'><strong>Model Training</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li><details><summary style='list-style: none; cursor: pointer;'><u>View All \"Model Training\" Calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.linkage</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Perform hierarchical/agglomerative clustering.\n",
    "\n",
    "The input y may be either a 1-D condensed distance matrix\n",
    "or a 2-D array of observation vectors.\n",
    "\n",
    "If y is a 1-D condensed distance matrix,\n",
    "then y must be a :math:`\\binom{n}{2}` sized\n",
    "vector, where n is the number of original observations paired\n",
    "in the distance matrix. The behavior of this function is very\n",
    "similar to the MATLAB linkage function.\n",
    "\n",
    "A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
    ":math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
    "``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
    "cluster with an index less than :math:`n` corresponds to one of\n",
    "the :math:`n` original observations. The distance between\n",
    "clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
    "fourth value ``Z[i, 3]`` represents the number of original\n",
    "observations in the newly formed cluster.\n",
    "\n",
    "The following linkage methods are used to compute the distance\n",
    ":math:`d(s, t)` between two clusters :math:`s` and\n",
    ":math:`t`. The algorithm begins with a forest of clusters that\n",
    "have yet to be used in the hierarchy being formed. When two\n",
    "clusters :math:`s` and :math:`t` from this forest are combined\n",
    "into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
    "removed from the forest, and :math:`u` is added to the\n",
    "forest. When only one cluster remains in the forest, the algorithm\n",
    "stops, and this cluster becomes the root.\n",
    "\n",
    "A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
    "entry corresponds to the distance between cluster :math:`i` and\n",
    ":math:`j` in the original forest.\n",
    "\n",
    "At each iteration, the algorithm must update the distance matrix\n",
    "to reflect the distance of the newly formed cluster u with the\n",
    "remaining clusters in the forest.\n",
    "\n",
    "Suppose there are :math:`|u|` original observations\n",
    ":math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
    ":math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
    "cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n",
    "combined to form cluster :math:`u`. Let :math:`v` be any\n",
    "remaining cluster in the forest that is not :math:`u`.\n",
    "\n",
    "The following are methods for calculating the distance between the\n",
    "newly formed cluster :math:`u` and each :math:`v`.\n",
    "\n",
    "  * method='single' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\min(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster :math:`u` and\n",
    "    :math:`j` in cluster :math:`v`. This is also known as the\n",
    "    Nearest Point Algorithm.\n",
    "\n",
    "  * method='complete' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u, v) = \\max(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster u and :math:`j` in\n",
    "    cluster :math:`v`. This is also known by the Farthest Point\n",
    "    Algorithm or Voor Hees Algorithm.\n",
    "\n",
    "  * method='average' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
    "                               {(|u|*|v|)}\n",
    "\n",
    "    for all points :math:`i` and :math:`j` where :math:`|u|`\n",
    "    and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
    "    and :math:`v`, respectively. This is also called the UPGMA\n",
    "    algorithm.\n",
    "\n",
    "  * method='weighted' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = (dist(s,v) + dist(t,v))/2\n",
    "\n",
    "    where cluster u was formed with cluster s and t and v\n",
    "    is a remaining cluster in the forest (also called WPGMA).\n",
    "\n",
    "  * method='centroid' assigns\n",
    "\n",
    "    .. math::\n",
    "       dist(s,t) = ||c_s-c_t||_2\n",
    "\n",
    "    where :math:`c_s` and :math:`c_t` are the centroids of\n",
    "    clusters :math:`s` and :math:`t`, respectively. When two\n",
    "    clusters :math:`s` and :math:`t` are combined into a new\n",
    "    cluster :math:`u`, the new centroid is computed over all the\n",
    "    original objects in clusters :math:`s` and :math:`t`. The\n",
    "    distance then becomes the Euclidean distance between the\n",
    "    centroid of :math:`u` and the centroid of a remaining cluster\n",
    "    :math:`v` in the forest. This is also known as the UPGMC\n",
    "    algorithm.\n",
    "\n",
    "  * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
    "    method. When two clusters :math:`s` and :math:`t` are combined\n",
    "    into a new cluster :math:`u`, the average of centroids s and t\n",
    "    give the new centroid :math:`u`. This is also known as the\n",
    "    WPGMC algorithm.\n",
    "\n",
    "  * method='ward' uses the Ward variance minimization algorithm.\n",
    "    The new entry :math:`d(u,v)` is computed as follows,\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
    "                           {T}d(v,s)^2\n",
    "                    + \\frac{|v|+|t|}\n",
    "                           {T}d(v,t)^2\n",
    "                    - \\frac{|v|}\n",
    "                           {T}d(s,t)^2}\n",
    "\n",
    "    where :math:`u` is the newly joined cluster consisting of\n",
    "    clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
    "    cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
    "    :math:`|*|` is the cardinality of its argument. This is also\n",
    "    known as the incremental algorithm.\n",
    "\n",
    "Warning: When the minimum distance pair in the forest is chosen, there\n",
    "may be two or more pairs with the same minimum distance. This\n",
    "implementation may choose a different minimum than the MATLAB\n",
    "version.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "y : ndarray\n",
    "    A condensed distance matrix. A condensed distance matrix\n",
    "    is a flat array containing the upper triangular of the distance matrix.\n",
    "    This is the form that ``pdist`` returns. Alternatively, a collection of\n",
    "    :math:`m` observation vectors in :math:`n` dimensions may be passed as\n",
    "    an :math:`m` by :math:`n` array. All elements of the condensed distance\n",
    "    matrix must be finite, i.e., no NaNs or infs.\n",
    "method : str, optional\n",
    "    The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
    "    for full descriptions.\n",
    "metric : str or function, optional\n",
    "    The distance metric to use in the case that y is a collection of\n",
    "    observation vectors; ignored otherwise. See the ``pdist``\n",
    "    function for a list of valid distance metrics. A custom distance\n",
    "    function can also be used.\n",
    "optimal_ordering : bool, optional\n",
    "    If True, the linkage matrix will be reordered so that the distance\n",
    "    between successive leaves is minimal. This results in a more intuitive\n",
    "    tree structure when the data are visualized. defaults to False, because\n",
    "    this algorithm can be slow, particularly on large datasets [2]_. See\n",
    "    also the `optimal_leaf_ordering` function.\n",
    "\n",
    "    .. versionadded:: 1.0.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded as a linkage matrix.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "1. For method 'single', an optimized algorithm based on minimum spanning\n",
    "   tree is implemented. It has time complexity :math:`O(n^2)`.\n",
    "   For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n",
    "   called nearest-neighbors chain is implemented. It also has time\n",
    "   complexity :math:`O(n^2)`.\n",
    "   For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n",
    "   time complexity.\n",
    "   All algorithms use :math:`O(n^2)` memory.\n",
    "   Refer to [1]_ for details about the algorithms.\n",
    "2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n",
    "   Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
    "   pairwise distances, then it is the user's responsibility to assure that\n",
    "   these distances are in fact Euclidean, otherwise the produced result\n",
    "   will be incorrect.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "scipy.spatial.distance.pdist : pairwise distance metrics\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
    "       algorithms\", :arXiv:`1109.2378v1`.\n",
    ".. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n",
    "       leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n",
    "       :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import dendrogram, linkage\n",
    ">>> from matplotlib import pyplot as plt\n",
    ">>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "\n",
    ">>> Z = linkage(X, 'ward')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    "\n",
    ">>> Z = linkage(X, 'single')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.fcluster</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [5] | <b>Kwargs:</b> {'criterion': 'maxclust'}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Form flat clusters from the hierarchical clustering defined by\n",
    "the given linkage matrix.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded with the matrix returned\n",
    "    by the `linkage` function.\n",
    "t : scalar\n",
    "    For criteria 'inconsistent', 'distance' or 'monocrit',\n",
    "     this is the threshold to apply when forming flat clusters.\n",
    "    For 'maxclust' or 'maxclust_monocrit' criteria,\n",
    "     this would be max number of clusters requested.\n",
    "criterion : str, optional\n",
    "    The criterion to use in forming flat clusters. This can\n",
    "    be any of the following values:\n",
    "\n",
    "      ``inconsistent`` :\n",
    "          If a cluster node and all its\n",
    "          descendants have an inconsistent value less than or equal\n",
    "          to `t`, then all its leaf descendants belong to the\n",
    "          same flat cluster. When no non-singleton cluster meets\n",
    "          this criterion, every node is assigned to its own\n",
    "          cluster. (Default)\n",
    "\n",
    "      ``distance`` :\n",
    "          Forms flat clusters so that the original\n",
    "          observations in each flat cluster have no greater a\n",
    "          cophenetic distance than `t`.\n",
    "\n",
    "      ``maxclust`` :\n",
    "          Finds a minimum threshold ``r`` so that\n",
    "          the cophenetic distance between any two original\n",
    "          observations in the same flat cluster is no more than\n",
    "          ``r`` and no more than `t` flat clusters are formed.\n",
    "\n",
    "      ``monocrit`` :\n",
    "          Forms a flat cluster from a cluster node c\n",
    "          with index i when ``monocrit[j] <= t``.\n",
    "\n",
    "          For example, to threshold on the maximum mean distance\n",
    "          as computed in the inconsistency matrix R with a\n",
    "          threshold of 0.8 do::\n",
    "\n",
    "              MR = maxRstat(Z, R, 3)\n",
    "              fcluster(Z, t=0.8, criterion='monocrit', monocrit=MR)\n",
    "\n",
    "      ``maxclust_monocrit`` :\n",
    "          Forms a flat cluster from a\n",
    "          non-singleton cluster node ``c`` when ``monocrit[i] <=\n",
    "          r`` for all cluster indices ``i`` below and including\n",
    "          ``c``. ``r`` is minimized such that no more than ``t``\n",
    "          flat clusters are formed. monocrit must be\n",
    "          monotonic. For example, to minimize the threshold t on\n",
    "          maximum inconsistency values so that no more than 3 flat\n",
    "          clusters are formed, do::\n",
    "\n",
    "              MI = maxinconsts(Z, R)\n",
    "              fcluster(Z, t=3, criterion='maxclust_monocrit', monocrit=MI)\n",
    "depth : int, optional\n",
    "    The maximum depth to perform the inconsistency calculation.\n",
    "    It has no meaning for the other criteria. Default is 2.\n",
    "R : ndarray, optional\n",
    "    The inconsistency matrix to use for the 'inconsistent'\n",
    "    criterion. This matrix is computed if not provided.\n",
    "monocrit : ndarray, optional\n",
    "    An array of length n-1. `monocrit[i]` is the\n",
    "    statistics upon which non-singleton i is thresholded. The\n",
    "    monocrit vector must be monotonic, i.e., given a node c with\n",
    "    index i, for all node indices j corresponding to nodes\n",
    "    below c, ``monocrit[i] >= monocrit[j]``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "fcluster : ndarray\n",
    "    An array of length ``n``. ``T[i]`` is the flat cluster number to\n",
    "    which original observation ``i`` belongs.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage : for information about hierarchical clustering methods work.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import ward, fcluster\n",
    ">>> from scipy.spatial.distance import pdist\n",
    "\n",
    "All cluster linkage methods - e.g., `scipy.cluster.hierarchy.ward`\n",
    "generate a linkage matrix ``Z`` as their output:\n",
    "\n",
    ">>> X = [[0, 0], [0, 1], [1, 0],\n",
    "...      [0, 4], [0, 3], [1, 4],\n",
    "...      [4, 0], [3, 0], [4, 1],\n",
    "...      [4, 4], [3, 4], [4, 3]]\n",
    "\n",
    ">>> Z = ward(pdist(X))\n",
    "\n",
    ">>> Z\n",
    "array([[ 0.        ,  1.        ,  1.        ,  2.        ],\n",
    "       [ 3.        ,  4.        ,  1.        ,  2.        ],\n",
    "       [ 6.        ,  7.        ,  1.        ,  2.        ],\n",
    "       [ 9.        , 10.        ,  1.        ,  2.        ],\n",
    "       [ 2.        , 12.        ,  1.29099445,  3.        ],\n",
    "       [ 5.        , 13.        ,  1.29099445,  3.        ],\n",
    "       [ 8.        , 14.        ,  1.29099445,  3.        ],\n",
    "       [11.        , 15.        ,  1.29099445,  3.        ],\n",
    "       [16.        , 17.        ,  5.77350269,  6.        ],\n",
    "       [18.        , 19.        ,  5.77350269,  6.        ],\n",
    "       [20.        , 21.        ,  8.16496581, 12.        ]])\n",
    "\n",
    "This matrix represents a dendrogram, where the first and second elements\n",
    "are the two clusters merged at each step, the third element is the\n",
    "distance between these clusters, and the fourth element is the size of\n",
    "the new cluster - the number of original data points included.\n",
    "\n",
    "`scipy.cluster.hierarchy.fcluster` can be used to flatten the\n",
    "dendrogram, obtaining as a result an assignation of the original data\n",
    "points to single clusters.\n",
    "\n",
    "This assignation mostly depends on a distance threshold ``t`` - the maximum\n",
    "inter-cluster distance allowed:\n",
    "\n",
    ">>> fcluster(Z, t=0.9, criterion='distance')\n",
    "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=1.1, criterion='distance')\n",
    "array([1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=3, criterion='distance')\n",
    "array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=9, criterion='distance')\n",
    "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)\n",
    "\n",
    "In the first case, the threshold ``t`` is too small to allow any two\n",
    "samples in the data to form a cluster, so 12 different clusters are\n",
    "returned.\n",
    "\n",
    "In the second case, the threshold is large enough to allow the first\n",
    "4 points to be merged with their nearest neighbors. So, here, only 8\n",
    "clusters are returned.\n",
    "\n",
    "The third case, with a much higher threshold, allows for up to 8 data\n",
    "points to be connected - so 4 clusters are returned here.\n",
    "\n",
    "Lastly, the threshold of the fourth case is large enough to allow for\n",
    "all data points to be merged together - so a single cluster is returned.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 20</u></strong></summary><small><a href=#20>goto cell # 20</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.linkage</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [] | <b>Kwargs:</b> {'method': 'ward'}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Perform hierarchical/agglomerative clustering.\n",
    "\n",
    "The input y may be either a 1-D condensed distance matrix\n",
    "or a 2-D array of observation vectors.\n",
    "\n",
    "If y is a 1-D condensed distance matrix,\n",
    "then y must be a :math:`\\binom{n}{2}` sized\n",
    "vector, where n is the number of original observations paired\n",
    "in the distance matrix. The behavior of this function is very\n",
    "similar to the MATLAB linkage function.\n",
    "\n",
    "A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
    ":math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
    "``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
    "cluster with an index less than :math:`n` corresponds to one of\n",
    "the :math:`n` original observations. The distance between\n",
    "clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
    "fourth value ``Z[i, 3]`` represents the number of original\n",
    "observations in the newly formed cluster.\n",
    "\n",
    "The following linkage methods are used to compute the distance\n",
    ":math:`d(s, t)` between two clusters :math:`s` and\n",
    ":math:`t`. The algorithm begins with a forest of clusters that\n",
    "have yet to be used in the hierarchy being formed. When two\n",
    "clusters :math:`s` and :math:`t` from this forest are combined\n",
    "into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
    "removed from the forest, and :math:`u` is added to the\n",
    "forest. When only one cluster remains in the forest, the algorithm\n",
    "stops, and this cluster becomes the root.\n",
    "\n",
    "A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
    "entry corresponds to the distance between cluster :math:`i` and\n",
    ":math:`j` in the original forest.\n",
    "\n",
    "At each iteration, the algorithm must update the distance matrix\n",
    "to reflect the distance of the newly formed cluster u with the\n",
    "remaining clusters in the forest.\n",
    "\n",
    "Suppose there are :math:`|u|` original observations\n",
    ":math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
    ":math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
    "cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n",
    "combined to form cluster :math:`u`. Let :math:`v` be any\n",
    "remaining cluster in the forest that is not :math:`u`.\n",
    "\n",
    "The following are methods for calculating the distance between the\n",
    "newly formed cluster :math:`u` and each :math:`v`.\n",
    "\n",
    "  * method='single' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\min(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster :math:`u` and\n",
    "    :math:`j` in cluster :math:`v`. This is also known as the\n",
    "    Nearest Point Algorithm.\n",
    "\n",
    "  * method='complete' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u, v) = \\max(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster u and :math:`j` in\n",
    "    cluster :math:`v`. This is also known by the Farthest Point\n",
    "    Algorithm or Voor Hees Algorithm.\n",
    "\n",
    "  * method='average' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
    "                               {(|u|*|v|)}\n",
    "\n",
    "    for all points :math:`i` and :math:`j` where :math:`|u|`\n",
    "    and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
    "    and :math:`v`, respectively. This is also called the UPGMA\n",
    "    algorithm.\n",
    "\n",
    "  * method='weighted' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = (dist(s,v) + dist(t,v))/2\n",
    "\n",
    "    where cluster u was formed with cluster s and t and v\n",
    "    is a remaining cluster in the forest (also called WPGMA).\n",
    "\n",
    "  * method='centroid' assigns\n",
    "\n",
    "    .. math::\n",
    "       dist(s,t) = ||c_s-c_t||_2\n",
    "\n",
    "    where :math:`c_s` and :math:`c_t` are the centroids of\n",
    "    clusters :math:`s` and :math:`t`, respectively. When two\n",
    "    clusters :math:`s` and :math:`t` are combined into a new\n",
    "    cluster :math:`u`, the new centroid is computed over all the\n",
    "    original objects in clusters :math:`s` and :math:`t`. The\n",
    "    distance then becomes the Euclidean distance between the\n",
    "    centroid of :math:`u` and the centroid of a remaining cluster\n",
    "    :math:`v` in the forest. This is also known as the UPGMC\n",
    "    algorithm.\n",
    "\n",
    "  * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
    "    method. When two clusters :math:`s` and :math:`t` are combined\n",
    "    into a new cluster :math:`u`, the average of centroids s and t\n",
    "    give the new centroid :math:`u`. This is also known as the\n",
    "    WPGMC algorithm.\n",
    "\n",
    "  * method='ward' uses the Ward variance minimization algorithm.\n",
    "    The new entry :math:`d(u,v)` is computed as follows,\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
    "                           {T}d(v,s)^2\n",
    "                    + \\frac{|v|+|t|}\n",
    "                           {T}d(v,t)^2\n",
    "                    - \\frac{|v|}\n",
    "                           {T}d(s,t)^2}\n",
    "\n",
    "    where :math:`u` is the newly joined cluster consisting of\n",
    "    clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
    "    cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
    "    :math:`|*|` is the cardinality of its argument. This is also\n",
    "    known as the incremental algorithm.\n",
    "\n",
    "Warning: When the minimum distance pair in the forest is chosen, there\n",
    "may be two or more pairs with the same minimum distance. This\n",
    "implementation may choose a different minimum than the MATLAB\n",
    "version.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "y : ndarray\n",
    "    A condensed distance matrix. A condensed distance matrix\n",
    "    is a flat array containing the upper triangular of the distance matrix.\n",
    "    This is the form that ``pdist`` returns. Alternatively, a collection of\n",
    "    :math:`m` observation vectors in :math:`n` dimensions may be passed as\n",
    "    an :math:`m` by :math:`n` array. All elements of the condensed distance\n",
    "    matrix must be finite, i.e., no NaNs or infs.\n",
    "method : str, optional\n",
    "    The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
    "    for full descriptions.\n",
    "metric : str or function, optional\n",
    "    The distance metric to use in the case that y is a collection of\n",
    "    observation vectors; ignored otherwise. See the ``pdist``\n",
    "    function for a list of valid distance metrics. A custom distance\n",
    "    function can also be used.\n",
    "optimal_ordering : bool, optional\n",
    "    If True, the linkage matrix will be reordered so that the distance\n",
    "    between successive leaves is minimal. This results in a more intuitive\n",
    "    tree structure when the data are visualized. defaults to False, because\n",
    "    this algorithm can be slow, particularly on large datasets [2]_. See\n",
    "    also the `optimal_leaf_ordering` function.\n",
    "\n",
    "    .. versionadded:: 1.0.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded as a linkage matrix.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "1. For method 'single', an optimized algorithm based on minimum spanning\n",
    "   tree is implemented. It has time complexity :math:`O(n^2)`.\n",
    "   For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n",
    "   called nearest-neighbors chain is implemented. It also has time\n",
    "   complexity :math:`O(n^2)`.\n",
    "   For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n",
    "   time complexity.\n",
    "   All algorithms use :math:`O(n^2)` memory.\n",
    "   Refer to [1]_ for details about the algorithms.\n",
    "2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n",
    "   Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
    "   pairwise distances, then it is the user's responsibility to assure that\n",
    "   these distances are in fact Euclidean, otherwise the produced result\n",
    "   will be incorrect.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "scipy.spatial.distance.pdist : pairwise distance metrics\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
    "       algorithms\", :arXiv:`1109.2378v1`.\n",
    ".. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n",
    "       leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n",
    "       :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import dendrogram, linkage\n",
    ">>> from matplotlib import pyplot as plt\n",
    ">>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "\n",
    ">>> Z = linkage(X, 'ward')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    "\n",
    ">>> Z = linkage(X, 'single')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 23</u></strong></summary><small><a href=#23>goto cell # 23</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.fcluster</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [5] | <b>Kwargs:</b> {'criterion': 'maxclust'}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Form flat clusters from the hierarchical clustering defined by\n",
    "the given linkage matrix.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded with the matrix returned\n",
    "    by the `linkage` function.\n",
    "t : scalar\n",
    "    For criteria 'inconsistent', 'distance' or 'monocrit',\n",
    "     this is the threshold to apply when forming flat clusters.\n",
    "    For 'maxclust' or 'maxclust_monocrit' criteria,\n",
    "     this would be max number of clusters requested.\n",
    "criterion : str, optional\n",
    "    The criterion to use in forming flat clusters. This can\n",
    "    be any of the following values:\n",
    "\n",
    "      ``inconsistent`` :\n",
    "          If a cluster node and all its\n",
    "          descendants have an inconsistent value less than or equal\n",
    "          to `t`, then all its leaf descendants belong to the\n",
    "          same flat cluster. When no non-singleton cluster meets\n",
    "          this criterion, every node is assigned to its own\n",
    "          cluster. (Default)\n",
    "\n",
    "      ``distance`` :\n",
    "          Forms flat clusters so that the original\n",
    "          observations in each flat cluster have no greater a\n",
    "          cophenetic distance than `t`.\n",
    "\n",
    "      ``maxclust`` :\n",
    "          Finds a minimum threshold ``r`` so that\n",
    "          the cophenetic distance between any two original\n",
    "          observations in the same flat cluster is no more than\n",
    "          ``r`` and no more than `t` flat clusters are formed.\n",
    "\n",
    "      ``monocrit`` :\n",
    "          Forms a flat cluster from a cluster node c\n",
    "          with index i when ``monocrit[j] <= t``.\n",
    "\n",
    "          For example, to threshold on the maximum mean distance\n",
    "          as computed in the inconsistency matrix R with a\n",
    "          threshold of 0.8 do::\n",
    "\n",
    "              MR = maxRstat(Z, R, 3)\n",
    "              fcluster(Z, t=0.8, criterion='monocrit', monocrit=MR)\n",
    "\n",
    "      ``maxclust_monocrit`` :\n",
    "          Forms a flat cluster from a\n",
    "          non-singleton cluster node ``c`` when ``monocrit[i] <=\n",
    "          r`` for all cluster indices ``i`` below and including\n",
    "          ``c``. ``r`` is minimized such that no more than ``t``\n",
    "          flat clusters are formed. monocrit must be\n",
    "          monotonic. For example, to minimize the threshold t on\n",
    "          maximum inconsistency values so that no more than 3 flat\n",
    "          clusters are formed, do::\n",
    "\n",
    "              MI = maxinconsts(Z, R)\n",
    "              fcluster(Z, t=3, criterion='maxclust_monocrit', monocrit=MI)\n",
    "depth : int, optional\n",
    "    The maximum depth to perform the inconsistency calculation.\n",
    "    It has no meaning for the other criteria. Default is 2.\n",
    "R : ndarray, optional\n",
    "    The inconsistency matrix to use for the 'inconsistent'\n",
    "    criterion. This matrix is computed if not provided.\n",
    "monocrit : ndarray, optional\n",
    "    An array of length n-1. `monocrit[i]` is the\n",
    "    statistics upon which non-singleton i is thresholded. The\n",
    "    monocrit vector must be monotonic, i.e., given a node c with\n",
    "    index i, for all node indices j corresponding to nodes\n",
    "    below c, ``monocrit[i] >= monocrit[j]``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "fcluster : ndarray\n",
    "    An array of length ``n``. ``T[i]`` is the flat cluster number to\n",
    "    which original observation ``i`` belongs.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage : for information about hierarchical clustering methods work.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import ward, fcluster\n",
    ">>> from scipy.spatial.distance import pdist\n",
    "\n",
    "All cluster linkage methods - e.g., `scipy.cluster.hierarchy.ward`\n",
    "generate a linkage matrix ``Z`` as their output:\n",
    "\n",
    ">>> X = [[0, 0], [0, 1], [1, 0],\n",
    "...      [0, 4], [0, 3], [1, 4],\n",
    "...      [4, 0], [3, 0], [4, 1],\n",
    "...      [4, 4], [3, 4], [4, 3]]\n",
    "\n",
    ">>> Z = ward(pdist(X))\n",
    "\n",
    ">>> Z\n",
    "array([[ 0.        ,  1.        ,  1.        ,  2.        ],\n",
    "       [ 3.        ,  4.        ,  1.        ,  2.        ],\n",
    "       [ 6.        ,  7.        ,  1.        ,  2.        ],\n",
    "       [ 9.        , 10.        ,  1.        ,  2.        ],\n",
    "       [ 2.        , 12.        ,  1.29099445,  3.        ],\n",
    "       [ 5.        , 13.        ,  1.29099445,  3.        ],\n",
    "       [ 8.        , 14.        ,  1.29099445,  3.        ],\n",
    "       [11.        , 15.        ,  1.29099445,  3.        ],\n",
    "       [16.        , 17.        ,  5.77350269,  6.        ],\n",
    "       [18.        , 19.        ,  5.77350269,  6.        ],\n",
    "       [20.        , 21.        ,  8.16496581, 12.        ]])\n",
    "\n",
    "This matrix represents a dendrogram, where the first and second elements\n",
    "are the two clusters merged at each step, the third element is the\n",
    "distance between these clusters, and the fourth element is the size of\n",
    "the new cluster - the number of original data points included.\n",
    "\n",
    "`scipy.cluster.hierarchy.fcluster` can be used to flatten the\n",
    "dendrogram, obtaining as a result an assignation of the original data\n",
    "points to single clusters.\n",
    "\n",
    "This assignation mostly depends on a distance threshold ``t`` - the maximum\n",
    "inter-cluster distance allowed:\n",
    "\n",
    ">>> fcluster(Z, t=0.9, criterion='distance')\n",
    "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=1.1, criterion='distance')\n",
    "array([1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=3, criterion='distance')\n",
    "array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=9, criterion='distance')\n",
    "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)\n",
    "\n",
    "In the first case, the threshold ``t`` is too small to allow any two\n",
    "samples in the data to form a cluster, so 12 different clusters are\n",
    "returned.\n",
    "\n",
    "In the second case, the threshold is large enough to allow the first\n",
    "4 points to be merged with their nearest neighbors. So, here, only 8\n",
    "clusters are returned.\n",
    "\n",
    "The third case, with a much higher threshold, allows for up to 8 data\n",
    "points to be connected - so 4 clusters are returned here.\n",
    "\n",
    "Lastly, the threshold of the fourth case is large enough to allow for\n",
    "all data points to be merged together - so a single cluster is returned.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 26</u></strong></summary><small><a href=#26>goto cell # 26</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.linkage</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [] | <b>Kwargs:</b> {'method': 'ward'}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Perform hierarchical/agglomerative clustering.\n",
    "\n",
    "The input y may be either a 1-D condensed distance matrix\n",
    "or a 2-D array of observation vectors.\n",
    "\n",
    "If y is a 1-D condensed distance matrix,\n",
    "then y must be a :math:`\\binom{n}{2}` sized\n",
    "vector, where n is the number of original observations paired\n",
    "in the distance matrix. The behavior of this function is very\n",
    "similar to the MATLAB linkage function.\n",
    "\n",
    "A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
    ":math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
    "``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
    "cluster with an index less than :math:`n` corresponds to one of\n",
    "the :math:`n` original observations. The distance between\n",
    "clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
    "fourth value ``Z[i, 3]`` represents the number of original\n",
    "observations in the newly formed cluster.\n",
    "\n",
    "The following linkage methods are used to compute the distance\n",
    ":math:`d(s, t)` between two clusters :math:`s` and\n",
    ":math:`t`. The algorithm begins with a forest of clusters that\n",
    "have yet to be used in the hierarchy being formed. When two\n",
    "clusters :math:`s` and :math:`t` from this forest are combined\n",
    "into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
    "removed from the forest, and :math:`u` is added to the\n",
    "forest. When only one cluster remains in the forest, the algorithm\n",
    "stops, and this cluster becomes the root.\n",
    "\n",
    "A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
    "entry corresponds to the distance between cluster :math:`i` and\n",
    ":math:`j` in the original forest.\n",
    "\n",
    "At each iteration, the algorithm must update the distance matrix\n",
    "to reflect the distance of the newly formed cluster u with the\n",
    "remaining clusters in the forest.\n",
    "\n",
    "Suppose there are :math:`|u|` original observations\n",
    ":math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
    ":math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
    "cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n",
    "combined to form cluster :math:`u`. Let :math:`v` be any\n",
    "remaining cluster in the forest that is not :math:`u`.\n",
    "\n",
    "The following are methods for calculating the distance between the\n",
    "newly formed cluster :math:`u` and each :math:`v`.\n",
    "\n",
    "  * method='single' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\min(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster :math:`u` and\n",
    "    :math:`j` in cluster :math:`v`. This is also known as the\n",
    "    Nearest Point Algorithm.\n",
    "\n",
    "  * method='complete' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u, v) = \\max(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster u and :math:`j` in\n",
    "    cluster :math:`v`. This is also known by the Farthest Point\n",
    "    Algorithm or Voor Hees Algorithm.\n",
    "\n",
    "  * method='average' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
    "                               {(|u|*|v|)}\n",
    "\n",
    "    for all points :math:`i` and :math:`j` where :math:`|u|`\n",
    "    and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
    "    and :math:`v`, respectively. This is also called the UPGMA\n",
    "    algorithm.\n",
    "\n",
    "  * method='weighted' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = (dist(s,v) + dist(t,v))/2\n",
    "\n",
    "    where cluster u was formed with cluster s and t and v\n",
    "    is a remaining cluster in the forest (also called WPGMA).\n",
    "\n",
    "  * method='centroid' assigns\n",
    "\n",
    "    .. math::\n",
    "       dist(s,t) = ||c_s-c_t||_2\n",
    "\n",
    "    where :math:`c_s` and :math:`c_t` are the centroids of\n",
    "    clusters :math:`s` and :math:`t`, respectively. When two\n",
    "    clusters :math:`s` and :math:`t` are combined into a new\n",
    "    cluster :math:`u`, the new centroid is computed over all the\n",
    "    original objects in clusters :math:`s` and :math:`t`. The\n",
    "    distance then becomes the Euclidean distance between the\n",
    "    centroid of :math:`u` and the centroid of a remaining cluster\n",
    "    :math:`v` in the forest. This is also known as the UPGMC\n",
    "    algorithm.\n",
    "\n",
    "  * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
    "    method. When two clusters :math:`s` and :math:`t` are combined\n",
    "    into a new cluster :math:`u`, the average of centroids s and t\n",
    "    give the new centroid :math:`u`. This is also known as the\n",
    "    WPGMC algorithm.\n",
    "\n",
    "  * method='ward' uses the Ward variance minimization algorithm.\n",
    "    The new entry :math:`d(u,v)` is computed as follows,\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
    "                           {T}d(v,s)^2\n",
    "                    + \\frac{|v|+|t|}\n",
    "                           {T}d(v,t)^2\n",
    "                    - \\frac{|v|}\n",
    "                           {T}d(s,t)^2}\n",
    "\n",
    "    where :math:`u` is the newly joined cluster consisting of\n",
    "    clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
    "    cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
    "    :math:`|*|` is the cardinality of its argument. This is also\n",
    "    known as the incremental algorithm.\n",
    "\n",
    "Warning: When the minimum distance pair in the forest is chosen, there\n",
    "may be two or more pairs with the same minimum distance. This\n",
    "implementation may choose a different minimum than the MATLAB\n",
    "version.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "y : ndarray\n",
    "    A condensed distance matrix. A condensed distance matrix\n",
    "    is a flat array containing the upper triangular of the distance matrix.\n",
    "    This is the form that ``pdist`` returns. Alternatively, a collection of\n",
    "    :math:`m` observation vectors in :math:`n` dimensions may be passed as\n",
    "    an :math:`m` by :math:`n` array. All elements of the condensed distance\n",
    "    matrix must be finite, i.e., no NaNs or infs.\n",
    "method : str, optional\n",
    "    The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
    "    for full descriptions.\n",
    "metric : str or function, optional\n",
    "    The distance metric to use in the case that y is a collection of\n",
    "    observation vectors; ignored otherwise. See the ``pdist``\n",
    "    function for a list of valid distance metrics. A custom distance\n",
    "    function can also be used.\n",
    "optimal_ordering : bool, optional\n",
    "    If True, the linkage matrix will be reordered so that the distance\n",
    "    between successive leaves is minimal. This results in a more intuitive\n",
    "    tree structure when the data are visualized. defaults to False, because\n",
    "    this algorithm can be slow, particularly on large datasets [2]_. See\n",
    "    also the `optimal_leaf_ordering` function.\n",
    "\n",
    "    .. versionadded:: 1.0.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded as a linkage matrix.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "1. For method 'single', an optimized algorithm based on minimum spanning\n",
    "   tree is implemented. It has time complexity :math:`O(n^2)`.\n",
    "   For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n",
    "   called nearest-neighbors chain is implemented. It also has time\n",
    "   complexity :math:`O(n^2)`.\n",
    "   For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n",
    "   time complexity.\n",
    "   All algorithms use :math:`O(n^2)` memory.\n",
    "   Refer to [1]_ for details about the algorithms.\n",
    "2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n",
    "   Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
    "   pairwise distances, then it is the user's responsibility to assure that\n",
    "   these distances are in fact Euclidean, otherwise the produced result\n",
    "   will be incorrect.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "scipy.spatial.distance.pdist : pairwise distance metrics\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
    "       algorithms\", :arXiv:`1109.2378v1`.\n",
    ".. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n",
    "       leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n",
    "       :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import dendrogram, linkage\n",
    ">>> from matplotlib import pyplot as plt\n",
    ">>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "\n",
    ">>> Z = linkage(X, 'ward')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    "\n",
    ">>> Z = linkage(X, 'single')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 28</u></strong></summary><small><a href=#28>goto cell # 28</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.fcluster</u> | <b>(See Args)</b> </summary> <ul><li><b>Args:</b> [5] | <b>Kwargs:</b> {'criterion': 'maxclust'}</li></ul>\n",
    "<blockquote>\n",
    "<code>\n",
    "Form flat clusters from the hierarchical clustering defined by\n",
    "the given linkage matrix.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded with the matrix returned\n",
    "    by the `linkage` function.\n",
    "t : scalar\n",
    "    For criteria 'inconsistent', 'distance' or 'monocrit',\n",
    "     this is the threshold to apply when forming flat clusters.\n",
    "    For 'maxclust' or 'maxclust_monocrit' criteria,\n",
    "     this would be max number of clusters requested.\n",
    "criterion : str, optional\n",
    "    The criterion to use in forming flat clusters. This can\n",
    "    be any of the following values:\n",
    "\n",
    "      ``inconsistent`` :\n",
    "          If a cluster node and all its\n",
    "          descendants have an inconsistent value less than or equal\n",
    "          to `t`, then all its leaf descendants belong to the\n",
    "          same flat cluster. When no non-singleton cluster meets\n",
    "          this criterion, every node is assigned to its own\n",
    "          cluster. (Default)\n",
    "\n",
    "      ``distance`` :\n",
    "          Forms flat clusters so that the original\n",
    "          observations in each flat cluster have no greater a\n",
    "          cophenetic distance than `t`.\n",
    "\n",
    "      ``maxclust`` :\n",
    "          Finds a minimum threshold ``r`` so that\n",
    "          the cophenetic distance between any two original\n",
    "          observations in the same flat cluster is no more than\n",
    "          ``r`` and no more than `t` flat clusters are formed.\n",
    "\n",
    "      ``monocrit`` :\n",
    "          Forms a flat cluster from a cluster node c\n",
    "          with index i when ``monocrit[j] <= t``.\n",
    "\n",
    "          For example, to threshold on the maximum mean distance\n",
    "          as computed in the inconsistency matrix R with a\n",
    "          threshold of 0.8 do::\n",
    "\n",
    "              MR = maxRstat(Z, R, 3)\n",
    "              fcluster(Z, t=0.8, criterion='monocrit', monocrit=MR)\n",
    "\n",
    "      ``maxclust_monocrit`` :\n",
    "          Forms a flat cluster from a\n",
    "          non-singleton cluster node ``c`` when ``monocrit[i] <=\n",
    "          r`` for all cluster indices ``i`` below and including\n",
    "          ``c``. ``r`` is minimized such that no more than ``t``\n",
    "          flat clusters are formed. monocrit must be\n",
    "          monotonic. For example, to minimize the threshold t on\n",
    "          maximum inconsistency values so that no more than 3 flat\n",
    "          clusters are formed, do::\n",
    "\n",
    "              MI = maxinconsts(Z, R)\n",
    "              fcluster(Z, t=3, criterion='maxclust_monocrit', monocrit=MI)\n",
    "depth : int, optional\n",
    "    The maximum depth to perform the inconsistency calculation.\n",
    "    It has no meaning for the other criteria. Default is 2.\n",
    "R : ndarray, optional\n",
    "    The inconsistency matrix to use for the 'inconsistent'\n",
    "    criterion. This matrix is computed if not provided.\n",
    "monocrit : ndarray, optional\n",
    "    An array of length n-1. `monocrit[i]` is the\n",
    "    statistics upon which non-singleton i is thresholded. The\n",
    "    monocrit vector must be monotonic, i.e., given a node c with\n",
    "    index i, for all node indices j corresponding to nodes\n",
    "    below c, ``monocrit[i] >= monocrit[j]``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "fcluster : ndarray\n",
    "    An array of length ``n``. ``T[i]`` is the flat cluster number to\n",
    "    which original observation ``i`` belongs.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage : for information about hierarchical clustering methods work.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import ward, fcluster\n",
    ">>> from scipy.spatial.distance import pdist\n",
    "\n",
    "All cluster linkage methods - e.g., `scipy.cluster.hierarchy.ward`\n",
    "generate a linkage matrix ``Z`` as their output:\n",
    "\n",
    ">>> X = [[0, 0], [0, 1], [1, 0],\n",
    "...      [0, 4], [0, 3], [1, 4],\n",
    "...      [4, 0], [3, 0], [4, 1],\n",
    "...      [4, 4], [3, 4], [4, 3]]\n",
    "\n",
    ">>> Z = ward(pdist(X))\n",
    "\n",
    ">>> Z\n",
    "array([[ 0.        ,  1.        ,  1.        ,  2.        ],\n",
    "       [ 3.        ,  4.        ,  1.        ,  2.        ],\n",
    "       [ 6.        ,  7.        ,  1.        ,  2.        ],\n",
    "       [ 9.        , 10.        ,  1.        ,  2.        ],\n",
    "       [ 2.        , 12.        ,  1.29099445,  3.        ],\n",
    "       [ 5.        , 13.        ,  1.29099445,  3.        ],\n",
    "       [ 8.        , 14.        ,  1.29099445,  3.        ],\n",
    "       [11.        , 15.        ,  1.29099445,  3.        ],\n",
    "       [16.        , 17.        ,  5.77350269,  6.        ],\n",
    "       [18.        , 19.        ,  5.77350269,  6.        ],\n",
    "       [20.        , 21.        ,  8.16496581, 12.        ]])\n",
    "\n",
    "This matrix represents a dendrogram, where the first and second elements\n",
    "are the two clusters merged at each step, the third element is the\n",
    "distance between these clusters, and the fourth element is the size of\n",
    "the new cluster - the number of original data points included.\n",
    "\n",
    "`scipy.cluster.hierarchy.fcluster` can be used to flatten the\n",
    "dendrogram, obtaining as a result an assignation of the original data\n",
    "points to single clusters.\n",
    "\n",
    "This assignation mostly depends on a distance threshold ``t`` - the maximum\n",
    "inter-cluster distance allowed:\n",
    "\n",
    ">>> fcluster(Z, t=0.9, criterion='distance')\n",
    "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=1.1, criterion='distance')\n",
    "array([1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=3, criterion='distance')\n",
    "array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=9, criterion='distance')\n",
    "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)\n",
    "\n",
    "In the first case, the threshold ``t`` is too small to allow any two\n",
    "samples in the data to form a cluster, so 12 different clusters are\n",
    "returned.\n",
    "\n",
    "In the second case, the threshold is large enough to allow the first\n",
    "4 points to be merged with their nearest neighbors. So, here, only 8\n",
    "clusters are returned.\n",
    "\n",
    "The third case, with a much higher threshold, allows for up to 8 data\n",
    "points to be connected - so 4 clusters are returned here.\n",
    "\n",
    "Lastly, the threshold of the fourth case is large enough to allow for\n",
    "all data points to be merged together - so a single cluster is returned.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Model Parameter Tuning</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Model Validation and Assembling</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "</ul>\n",
    "<hr>\n",
    "\n",
    "<details><summary style='list-style: none; cursor: pointer;'><strong>View All ML API Calls in Notebook</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <b>numpy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "NumPy\n",
    "=====\n",
    "\n",
    "Provides\n",
    "  1. An array object of arbitrary homogeneous items\n",
    "  2. Fast mathematical operations over arrays\n",
    "  3. Linear Algebra, Fourier Transforms, Random Number Generation\n",
    "\n",
    "How to use the documentation\n",
    "----------------------------\n",
    "Documentation is available in two forms: docstrings provided\n",
    "with the code, and a loose standing reference guide, available from\n",
    "`the NumPy homepage <https://numpy.org>`_.\n",
    "\n",
    "We recommend exploring the docstrings using\n",
    "`IPython <https://ipython.org>`_, an advanced Python shell with\n",
    "TAB-completion and introspection capabilities.  See below for further\n",
    "instructions.\n",
    "\n",
    "The docstring examples assume that `numpy` has been imported as `np`::\n",
    "\n",
    "  >>> import numpy as np\n",
    "\n",
    "Code snippets are indicated by three greater-than signs::\n",
    "\n",
    "  >>> x = 42\n",
    "  >>> x = x + 1\n",
    "\n",
    "Use the built-in ``help`` function to view a function's docstring::\n",
    "\n",
    "  >>> help(np.sort)\n",
    "  ... # doctest: +SKIP\n",
    "\n",
    "For some objects, ``np.info(obj)`` may provide additional help.  This is\n",
    "particularly true if you see the line \"Help on ufunc object:\" at the top\n",
    "of the help() page.  Ufuncs are implemented in C, not Python, for speed.\n",
    "The native Python help() does not know how to view their help, but our\n",
    "np.info() function does.\n",
    "\n",
    "To search for documents containing a keyword, do::\n",
    "\n",
    "  >>> np.lookfor('keyword')\n",
    "  ... # doctest: +SKIP\n",
    "\n",
    "General-purpose documents like a glossary and help on the basic concepts\n",
    "of numpy are available under the ``doc`` sub-module::\n",
    "\n",
    "  >>> from numpy import doc\n",
    "  >>> help(doc)\n",
    "  ... # doctest: +SKIP\n",
    "\n",
    "Available subpackages\n",
    "---------------------\n",
    "lib\n",
    "    Basic functions used by several sub-packages.\n",
    "random\n",
    "    Core Random Tools\n",
    "linalg\n",
    "    Core Linear Algebra Tools\n",
    "fft\n",
    "    Core FFT routines\n",
    "polynomial\n",
    "    Polynomial tools\n",
    "testing\n",
    "    NumPy testing tools\n",
    "distutils\n",
    "    Enhancements to distutils with support for\n",
    "    Fortran compilers support and more.\n",
    "\n",
    "Utilities\n",
    "---------\n",
    "test\n",
    "    Run numpy unittests\n",
    "show_config\n",
    "    Show numpy build configuration\n",
    "dual\n",
    "    Overwrite certain functions with high-performance SciPy tools.\n",
    "    Note: `numpy.dual` is deprecated.  Use the functions from NumPy or Scipy\n",
    "    directly instead of importing them from `numpy.dual`.\n",
    "matlib\n",
    "    Make everything matrices.\n",
    "__version__\n",
    "    NumPy version string\n",
    "\n",
    "Viewing documentation using IPython\n",
    "-----------------------------------\n",
    "Start IPython with the NumPy profile (``ipython -p numpy``), which will\n",
    "import `numpy` under the alias `np`.  Then, use the ``cpaste`` command to\n",
    "paste examples into the shell.  To see which functions are available in\n",
    "`numpy`, type ``np.<TAB>`` (where ``<TAB>`` refers to the TAB key), or use\n",
    "``np.*cos*?<ENTER>`` (where ``<ENTER>`` refers to the ENTER key) to narrow\n",
    "down the list.  To view the docstring for a function, use\n",
    "``np.cos?<ENTER>`` (to view the docstring) and ``np.cos??<ENTER>`` (to view\n",
    "the source code).\n",
    "\n",
    "Copies vs. in-place operation\n",
    "-----------------------------\n",
    "Most of the functions in `numpy` return a copy of the array argument\n",
    "(e.g., `np.sort`).  In-place versions of these functions are often\n",
    "available as array methods, i.e. ``x = np.array([1,2,3]); x.sort()``.\n",
    "Exceptions to this rule are documented.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.array</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
    "      like=None)\n",
    "\n",
    "Create an array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "object : array_like\n",
    "    An array, any object exposing the array interface, an object whose\n",
    "    __array__ method returns an array, or any (nested) sequence.\n",
    "    If object is a scalar, a 0-dimensional array containing object is\n",
    "    returned.\n",
    "dtype : data-type, optional\n",
    "    The desired data-type for the array.  If not given, then the type will\n",
    "    be determined as the minimum type required to hold the objects in the\n",
    "    sequence.\n",
    "copy : bool, optional\n",
    "    If true (default), then the object is copied.  Otherwise, a copy will\n",
    "    only be made if __array__ returns a copy, if obj is a nested sequence,\n",
    "    or if a copy is needed to satisfy any of the other requirements\n",
    "    (`dtype`, `order`, etc.).\n",
    "order : {'K', 'A', 'C', 'F'}, optional\n",
    "    Specify the memory layout of the array. If object is not an array, the\n",
    "    newly created array will be in C order (row major) unless 'F' is\n",
    "    specified, in which case it will be in Fortran order (column major).\n",
    "    If object is an array the following holds.\n",
    "\n",
    "    ===== ========= ===================================================\n",
    "    order  no copy                     copy=True\n",
    "    ===== ========= ===================================================\n",
    "    'K'   unchanged F & C order preserved, otherwise most similar order\n",
    "    'A'   unchanged F order if input is F and not C, otherwise C order\n",
    "    'C'   C order   C order\n",
    "    'F'   F order   F order\n",
    "    ===== ========= ===================================================\n",
    "\n",
    "    When ``copy=False`` and a copy is made for other reasons, the result is\n",
    "    the same as if ``copy=True``, with some exceptions for 'A', see the\n",
    "    Notes section. The default order is 'K'.\n",
    "subok : bool, optional\n",
    "    If True, then sub-classes will be passed-through, otherwise\n",
    "    the returned array will be forced to be a base-class array (default).\n",
    "ndmin : int, optional\n",
    "    Specifies the minimum number of dimensions that the resulting\n",
    "    array should have.  Ones will be prepended to the shape as\n",
    "    needed to meet this requirement.\n",
    "like : array_like, optional\n",
    "    Reference object to allow the creation of arrays which are not\n",
    "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
    "    the ``__array_function__`` protocol, the result will be defined\n",
    "    by it. In this case, it ensures the creation of an array object\n",
    "    compatible with that passed in via this argument.\n",
    "\n",
    "    .. versionadded:: 1.20.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    An array object satisfying the specified requirements.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "empty_like : Return an empty array with shape and type of input.\n",
    "ones_like : Return an array of ones with shape and type of input.\n",
    "zeros_like : Return an array of zeros with shape and type of input.\n",
    "full_like : Return a new array with shape of input filled with value.\n",
    "empty : Return a new uninitialized array.\n",
    "ones : Return a new array setting values to one.\n",
    "zeros : Return a new array setting values to zero.\n",
    "full : Return a new array of given shape filled with value.\n",
    "\n",
    "\n",
    "Notes\n",
    "-----\n",
    "When order is 'A' and `object` is an array in neither 'C' nor 'F' order,\n",
    "and a copy is forced by a change in dtype, then the order of the result is\n",
    "not necessarily 'C' as expected. This is likely a bug.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> np.array([1, 2, 3])\n",
    "array([1, 2, 3])\n",
    "\n",
    "Upcasting:\n",
    "\n",
    ">>> np.array([1, 2, 3.0])\n",
    "array([ 1.,  2.,  3.])\n",
    "\n",
    "More than one dimension:\n",
    "\n",
    ">>> np.array([[1, 2], [3, 4]])\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "\n",
    "Minimum dimensions 2:\n",
    "\n",
    ">>> np.array([1, 2, 3], ndmin=2)\n",
    "array([[1, 2, 3]])\n",
    "\n",
    "Type provided:\n",
    "\n",
    ">>> np.array([1, 2, 3], dtype=complex)\n",
    "array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
    "\n",
    "Data-type consisting of more than one element:\n",
    "\n",
    ">>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
    ">>> x['a']\n",
    "array([1, 3])\n",
    "\n",
    "Creating an array from sub-classes:\n",
    "\n",
    ">>> np.array(np.mat('1 2; 3 4'))\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "\n",
    ">>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
    "matrix([[1, 2],\n",
    "        [3, 4]])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core._multiarray_umath.where</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "where(condition, [x, y], /)\n",
    "\n",
    "Return elements chosen from `x` or `y` depending on `condition`.\n",
    "\n",
    ".. note::\n",
    "    When only `condition` is provided, this function is a shorthand for\n",
    "    ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n",
    "    preferred, as it behaves correctly for subclasses. The rest of this\n",
    "    documentation covers only the case where all three arguments are\n",
    "    provided.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "condition : array_like, bool\n",
    "    Where True, yield `x`, otherwise yield `y`.\n",
    "x, y : array_like\n",
    "    Values from which to choose. `x`, `y` and `condition` need to be\n",
    "    broadcastable to some shape.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    An array with elements from `x` where `condition` is True, and elements\n",
    "    from `y` elsewhere.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "choose\n",
    "nonzero : The function that is called when x and y are omitted\n",
    "\n",
    "Notes\n",
    "-----\n",
    "If all the arrays are 1-D, `where` is equivalent to::\n",
    "\n",
    "    [xv if c else yv\n",
    "     for c, xv, yv in zip(condition, x, y)]\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> a = np.arange(10)\n",
    ">>> a\n",
    "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    ">>> np.where(a < 5, a, 10*a)\n",
    "array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n",
    "\n",
    "This can be used on multidimensional arrays too:\n",
    "\n",
    ">>> np.where([[True, False], [True, True]],\n",
    "...          [[1, 2], [3, 4]],\n",
    "...          [[9, 8], [7, 6]])\n",
    "array([[1, 8],\n",
    "       [3, 4]])\n",
    "\n",
    "The shapes of x, y, and the condition are broadcast together:\n",
    "\n",
    ">>> x, y = np.ogrid[:3, :4]\n",
    ">>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n",
    "array([[10,  0,  0,  0],\n",
    "       [10, 11,  1,  1],\n",
    "       [10, 11, 12,  2]])\n",
    "\n",
    ">>> a = np.array([[0, 1, 2],\n",
    "...               [0, 2, 4],\n",
    "...               [0, 3, 6]])\n",
    ">>> np.where(a < 4, a, -1)  # -1 is broadcast\n",
    "array([[ 0,  1,  2],\n",
    "       [ 0,  2, -1],\n",
    "       [ 0,  3, -1]])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core.fromnumeric.around</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Evenly round to the given number of decimals.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : array_like\n",
    "    Input data.\n",
    "decimals : int, optional\n",
    "    Number of decimal places to round to (default: 0).  If\n",
    "    decimals is negative, it specifies the number of positions to\n",
    "    the left of the decimal point.\n",
    "out : ndarray, optional\n",
    "    Alternative output array in which to place the result. It must have\n",
    "    the same shape as the expected output, but the type of the output\n",
    "    values will be cast if necessary. See :ref:`ufuncs-output-type` for more\n",
    "    details.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rounded_array : ndarray\n",
    "    An array of the same type as `a`, containing the rounded values.\n",
    "    Unless `out` was specified, a new array is created.  A reference to\n",
    "    the result is returned.\n",
    "\n",
    "    The real and imaginary parts of complex numbers are rounded\n",
    "    separately.  The result of rounding a float is a float.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "ndarray.round : equivalent method\n",
    "\n",
    "ceil, fix, floor, rint, trunc\n",
    "\n",
    "\n",
    "Notes\n",
    "-----\n",
    "For values exactly halfway between rounded decimal values, NumPy\n",
    "rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n",
    "-0.5 and 0.5 round to 0.0, etc.\n",
    "\n",
    "``np.around`` uses a fast but sometimes inexact algorithm to round\n",
    "floating-point datatypes. For positive `decimals` it is equivalent to\n",
    "``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has\n",
    "error due to the inexact representation of decimal fractions in the IEEE\n",
    "floating point standard [1]_ and errors introduced when scaling by powers\n",
    "of ten. For instance, note the extra \"1\" in the following:\n",
    "\n",
    "    >>> np.round(56294995342131.5, 3)\n",
    "    56294995342131.51\n",
    "\n",
    "If your goal is to print such values with a fixed number of decimals, it is\n",
    "preferable to use numpy's float printing routines to limit the number of\n",
    "printed decimals:\n",
    "\n",
    "    >>> np.format_float_positional(56294995342131.5, precision=3)\n",
    "    '56294995342131.5'\n",
    "\n",
    "The float printing routines use an accurate but much more computationally\n",
    "demanding algorithm to compute the number of digits after the decimal\n",
    "point.\n",
    "\n",
    "Alternatively, Python's builtin `round` function uses a more accurate\n",
    "but slower algorithm for 64-bit floating point values:\n",
    "\n",
    "    >>> round(56294995342131.5, 3)\n",
    "    56294995342131.5\n",
    "    >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997\n",
    "    (16.06, 16.05)\n",
    "\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] \"Lecture Notes on the Status of IEEE 754\", William Kahan,\n",
    "       https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> np.around([0.37, 1.64])\n",
    "array([0., 2.])\n",
    ">>> np.around([0.37, 1.64], decimals=1)\n",
    "array([0.4, 1.6])\n",
    ">>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value\n",
    "array([0., 2., 2., 4., 4.])\n",
    ">>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned\n",
    "array([ 1,  2,  3, 11])\n",
    ">>> np.around([1,2,3,11], decimals=-1)\n",
    "array([ 0,  0,  0, 10])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core.numeric.zeros_like</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return an array of zeros with the same shape and type as a given array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : array_like\n",
    "    The shape and data-type of `a` define these same attributes of\n",
    "    the returned array.\n",
    "dtype : data-type, optional\n",
    "    Overrides the data type of the result.\n",
    "\n",
    "    .. versionadded:: 1.6.0\n",
    "order : {'C', 'F', 'A', or 'K'}, optional\n",
    "    Overrides the memory layout of the result. 'C' means C-order,\n",
    "    'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
    "    'C' otherwise. 'K' means match the layout of `a` as closely\n",
    "    as possible.\n",
    "\n",
    "    .. versionadded:: 1.6.0\n",
    "subok : bool, optional.\n",
    "    If True, then the newly created array will use the sub-class\n",
    "    type of `a`, otherwise it will be a base-class array. Defaults\n",
    "    to True.\n",
    "shape : int or sequence of ints, optional.\n",
    "    Overrides the shape of the result. If order='K' and the number of\n",
    "    dimensions is unchanged, will try to keep order, otherwise,\n",
    "    order='C' is implied.\n",
    "\n",
    "    .. versionadded:: 1.17.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    Array of zeros with the same shape and type as `a`.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "empty_like : Return an empty array with shape and type of input.\n",
    "ones_like : Return an array of ones with shape and type of input.\n",
    "full_like : Return a new array with shape of input filled with value.\n",
    "zeros : Return a new array setting values to zero.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> x = np.arange(6)\n",
    ">>> x = x.reshape((2, 3))\n",
    ">>> x\n",
    "array([[0, 1, 2],\n",
    "       [3, 4, 5]])\n",
    ">>> np.zeros_like(x)\n",
    "array([[0, 0, 0],\n",
    "       [0, 0, 0]])\n",
    "\n",
    ">>> y = np.arange(3, dtype=float)\n",
    ">>> y\n",
    "array([0., 1., 2.])\n",
    ">>> np.zeros_like(y)\n",
    "array([0.,  0.,  0.])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.lib.function_base.corrcoef</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return Pearson product-moment correlation coefficients.\n",
    "\n",
    "Please refer to the documentation for `cov` for more detail.  The\n",
    "relationship between the correlation coefficient matrix, `R`, and the\n",
    "covariance matrix, `C`, is\n",
    "\n",
    ".. math:: R_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} C_{jj} } }\n",
    "\n",
    "The values of `R` are between -1 and 1, inclusive.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x : array_like\n",
    "    A 1-D or 2-D array containing multiple variables and observations.\n",
    "    Each row of `x` represents a variable, and each column a single\n",
    "    observation of all those variables. Also see `rowvar` below.\n",
    "y : array_like, optional\n",
    "    An additional set of variables and observations. `y` has the same\n",
    "    shape as `x`.\n",
    "rowvar : bool, optional\n",
    "    If `rowvar` is True (default), then each row represents a\n",
    "    variable, with observations in the columns. Otherwise, the relationship\n",
    "    is transposed: each column represents a variable, while the rows\n",
    "    contain observations.\n",
    "bias : _NoValue, optional\n",
    "    Has no effect, do not use.\n",
    "\n",
    "    .. deprecated:: 1.10.0\n",
    "ddof : _NoValue, optional\n",
    "    Has no effect, do not use.\n",
    "\n",
    "    .. deprecated:: 1.10.0\n",
    "dtype : data-type, optional\n",
    "    Data-type of the result. By default, the return data-type will have\n",
    "    at least `numpy.float64` precision.\n",
    "\n",
    "    .. versionadded:: 1.20\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : ndarray\n",
    "    The correlation coefficient matrix of the variables.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "cov : Covariance matrix\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Due to floating point rounding the resulting array may not be Hermitian,\n",
    "the diagonal elements may not be 1, and the elements may not satisfy the\n",
    "inequality abs(a) <= 1. The real and imaginary parts are clipped to the\n",
    "interval [-1,  1] in an attempt to improve on that situation but is not\n",
    "much help in the complex case.\n",
    "\n",
    "This function accepts but discards arguments `bias` and `ddof`.  This is\n",
    "for backwards compatibility with previous versions of this function.  These\n",
    "arguments had no effect on the return values of the function and can be\n",
    "safely ignored in this and previous versions of numpy.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "In this example we generate two random arrays, ``xarr`` and ``yarr``, and\n",
    "compute the row-wise and column-wise Pearson correlation coefficients,\n",
    "``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\n",
    "Pearson correlation coefficients between the variables of ``xarr``.\n",
    "\n",
    ">>> import numpy as np\n",
    ">>> rng = np.random.default_rng(seed=42)\n",
    ">>> xarr = rng.random((3, 3))\n",
    ">>> xarr\n",
    "array([[0.77395605, 0.43887844, 0.85859792],\n",
    "       [0.69736803, 0.09417735, 0.97562235],\n",
    "       [0.7611397 , 0.78606431, 0.12811363]])\n",
    ">>> R1 = np.corrcoef(xarr)\n",
    ">>> R1\n",
    "array([[ 1.        ,  0.99256089, -0.68080986],\n",
    "       [ 0.99256089,  1.        , -0.76492172],\n",
    "       [-0.68080986, -0.76492172,  1.        ]])\n",
    "\n",
    "If we add another set of variables and observations ``yarr``, we can\n",
    "compute the row-wise Pearson correlation coefficients between the\n",
    "variables in ``xarr`` and ``yarr``.\n",
    "\n",
    ">>> yarr = rng.random((3, 3))\n",
    ">>> yarr\n",
    "array([[0.45038594, 0.37079802, 0.92676499],\n",
    "       [0.64386512, 0.82276161, 0.4434142 ],\n",
    "       [0.22723872, 0.55458479, 0.06381726]])\n",
    ">>> R2 = np.corrcoef(xarr, yarr)\n",
    ">>> R2\n",
    "array([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n",
    "        -0.99004057],\n",
    "       [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n",
    "        -0.99981569],\n",
    "       [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n",
    "         0.77714685],\n",
    "       [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n",
    "        -0.83571711],\n",
    "       [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n",
    "         0.97517215],\n",
    "       [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n",
    "         1.        ]])\n",
    "\n",
    "Finally if we use the option ``rowvar=False``, the columns are now\n",
    "being treated as the variables and we will find the column-wise Pearson\n",
    "correlation coefficients between variables in ``xarr`` and ``yarr``.\n",
    "\n",
    ">>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n",
    ">>> R3\n",
    "array([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n",
    "         0.22423734],\n",
    "       [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n",
    "        -0.44069024],\n",
    "       [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n",
    "         0.75137473],\n",
    "       [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n",
    "         0.47536961],\n",
    "       [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n",
    "        -0.46666491],\n",
    "       [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n",
    "         1.        ]])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.lib.npyio.load</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n",
    "\n",
    ".. warning:: Loading files that contain object arrays uses the ``pickle``\n",
    "             module, which is not secure against erroneous or maliciously\n",
    "             constructed data. Consider passing ``allow_pickle=False`` to\n",
    "             load data that is known not to contain object arrays for the\n",
    "             safer handling of untrusted sources.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "file : file-like object, string, or pathlib.Path\n",
    "    The file to read. File-like objects must support the\n",
    "    ``seek()`` and ``read()`` methods and must always\n",
    "    be opened in binary mode.  Pickled files require that the\n",
    "    file-like object support the ``readline()`` method as well.\n",
    "mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n",
    "    If not None, then memory-map the file, using the given mode (see\n",
    "    `numpy.memmap` for a detailed description of the modes).  A\n",
    "    memory-mapped array is kept on disk. However, it can be accessed\n",
    "    and sliced like any ndarray.  Memory mapping is especially useful\n",
    "    for accessing small fragments of large files without reading the\n",
    "    entire file into memory.\n",
    "allow_pickle : bool, optional\n",
    "    Allow loading pickled object arrays stored in npy files. Reasons for\n",
    "    disallowing pickles include security, as loading pickled data can\n",
    "    execute arbitrary code. If pickles are disallowed, loading object\n",
    "    arrays will fail. Default: False\n",
    "\n",
    "    .. versionchanged:: 1.16.3\n",
    "        Made default False in response to CVE-2019-6446.\n",
    "\n",
    "fix_imports : bool, optional\n",
    "    Only useful when loading Python 2 generated pickled files on Python 3,\n",
    "    which includes npy/npz files containing object arrays. If `fix_imports`\n",
    "    is True, pickle will try to map the old Python 2 names to the new names\n",
    "    used in Python 3.\n",
    "encoding : str, optional\n",
    "    What encoding to use when reading Python 2 strings. Only useful when\n",
    "    loading Python 2 generated pickled files in Python 3, which includes\n",
    "    npy/npz files containing object arrays. Values other than 'latin1',\n",
    "    'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n",
    "    data. Default: 'ASCII'\n",
    "max_header_size : int, optional\n",
    "    Maximum allowed size of the header.  Large headers may not be safe\n",
    "    to load securely and thus require explicitly passing a larger value.\n",
    "    See :py:meth:`ast.literal_eval()` for details.\n",
    "    This option is ignored when `allow_pickle` is passed.  In that case\n",
    "    the file is by definition trusted and the limit is unnecessary.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "result : array, tuple, dict, etc.\n",
    "    Data stored in the file. For ``.npz`` files, the returned instance\n",
    "    of NpzFile class must be closed to avoid leaking file descriptors.\n",
    "\n",
    "Raises\n",
    "------\n",
    "OSError\n",
    "    If the input file does not exist or cannot be read.\n",
    "UnpicklingError\n",
    "    If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n",
    "ValueError\n",
    "    The file contains an object array, but ``allow_pickle=False`` given.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "save, savez, savez_compressed, loadtxt\n",
    "memmap : Create a memory-map to an array stored in a file on disk.\n",
    "lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- If the file contains pickle data, then whatever object is stored\n",
    "  in the pickle is returned.\n",
    "- If the file is a ``.npy`` file, then a single array is returned.\n",
    "- If the file is a ``.npz`` file, then a dictionary-like object is\n",
    "  returned, containing ``{filename: array}`` key-value pairs, one for\n",
    "  each file in the archive.\n",
    "- If the file is a ``.npz`` file, the returned value supports the\n",
    "  context manager protocol in a similar fashion to the open function::\n",
    "\n",
    "    with load('foo.npz') as data:\n",
    "        a = data['a']\n",
    "\n",
    "  The underlying file descriptor is closed when exiting the 'with'\n",
    "  block.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Store data to disk, and load it again:\n",
    "\n",
    ">>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
    ">>> np.load('/tmp/123.npy')\n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6]])\n",
    "\n",
    "Store compressed data to disk, and load it again:\n",
    "\n",
    ">>> a=np.array([[1, 2, 3], [4, 5, 6]])\n",
    ">>> b=np.array([1, 2])\n",
    ">>> np.savez('/tmp/123.npz', a=a, b=b)\n",
    ">>> data = np.load('/tmp/123.npz')\n",
    ">>> data['a']\n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6]])\n",
    ">>> data['b']\n",
    "array([1, 2])\n",
    ">>> data.close()\n",
    "\n",
    "Mem-map the stored array, and then access the second row\n",
    "directly from disk:\n",
    "\n",
    ">>> X = np.load('/tmp/123.npy', mmap_mode='r')\n",
    ">>> X[1, :]\n",
    "memmap([4, 5, 6])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.ndarray</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "ndarray(shape, dtype=float, buffer=None, offset=0,\n",
    "        strides=None, order=None)\n",
    "\n",
    "An array object represents a multidimensional, homogeneous array\n",
    "of fixed-size items.  An associated data-type object describes the\n",
    "format of each element in the array (its byte-order, how many bytes it\n",
    "occupies in memory, whether it is an integer, a floating point number,\n",
    "or something else, etc.)\n",
    "\n",
    "Arrays should be constructed using `array`, `zeros` or `empty` (refer\n",
    "to the See Also section below).  The parameters given here refer to\n",
    "a low-level method (`ndarray(...)`) for instantiating an array.\n",
    "\n",
    "For more information, refer to the `numpy` module and examine the\n",
    "methods and attributes of an array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "(for the __new__ method; see Notes below)\n",
    "\n",
    "shape : tuple of ints\n",
    "    Shape of created array.\n",
    "dtype : data-type, optional\n",
    "    Any object that can be interpreted as a numpy data type.\n",
    "buffer : object exposing buffer interface, optional\n",
    "    Used to fill the array with data.\n",
    "offset : int, optional\n",
    "    Offset of array data in buffer.\n",
    "strides : tuple of ints, optional\n",
    "    Strides of data in memory.\n",
    "order : {'C', 'F'}, optional\n",
    "    Row-major (C-style) or column-major (Fortran-style) order.\n",
    "\n",
    "Attributes\n",
    "----------\n",
    "T : ndarray\n",
    "    Transpose of the array.\n",
    "data : buffer\n",
    "    The array's elements, in memory.\n",
    "dtype : dtype object\n",
    "    Describes the format of the elements in the array.\n",
    "flags : dict\n",
    "    Dictionary containing information related to memory use, e.g.,\n",
    "    'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.\n",
    "flat : numpy.flatiter object\n",
    "    Flattened version of the array as an iterator.  The iterator\n",
    "    allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for\n",
    "    assignment examples; TODO).\n",
    "imag : ndarray\n",
    "    Imaginary part of the array.\n",
    "real : ndarray\n",
    "    Real part of the array.\n",
    "size : int\n",
    "    Number of elements in the array.\n",
    "itemsize : int\n",
    "    The memory use of each array element in bytes.\n",
    "nbytes : int\n",
    "    The total number of bytes required to store the array data,\n",
    "    i.e., ``itemsize * size``.\n",
    "ndim : int\n",
    "    The array's number of dimensions.\n",
    "shape : tuple of ints\n",
    "    Shape of the array.\n",
    "strides : tuple of ints\n",
    "    The step-size required to move from one element to the next in\n",
    "    memory. For example, a contiguous ``(3, 4)`` array of type\n",
    "    ``int16`` in C-order has strides ``(8, 2)``.  This implies that\n",
    "    to move from element to element in memory requires jumps of 2 bytes.\n",
    "    To move from row-to-row, one needs to jump 8 bytes at a time\n",
    "    (``2 * 4``).\n",
    "ctypes : ctypes object\n",
    "    Class containing properties of the array needed for interaction\n",
    "    with ctypes.\n",
    "base : ndarray\n",
    "    If the array is a view into another array, that array is its `base`\n",
    "    (unless that array is also a view).  The `base` array is where the\n",
    "    array data is actually stored.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "array : Construct an array.\n",
    "zeros : Create an array, each element of which is zero.\n",
    "empty : Create an array, but leave its allocated memory unchanged (i.e.,\n",
    "        it contains \"garbage\").\n",
    "dtype : Create a data-type.\n",
    "numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`\n",
    "                       w.r.t. its `dtype.type <numpy.dtype.type>`.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "There are two modes of creating an array using ``__new__``:\n",
    "\n",
    "1. If `buffer` is None, then only `shape`, `dtype`, and `order`\n",
    "   are used.\n",
    "2. If `buffer` is an object exposing the buffer interface, then\n",
    "   all keywords are interpreted.\n",
    "\n",
    "No ``__init__`` method is needed because the array is fully initialized\n",
    "after the ``__new__`` method.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "These examples illustrate the low-level `ndarray` constructor.  Refer\n",
    "to the `See Also` section above for easier ways of constructing an\n",
    "ndarray.\n",
    "\n",
    "First mode, `buffer` is None:\n",
    "\n",
    ">>> np.ndarray(shape=(2,2), dtype=float, order='F')\n",
    "array([[0.0e+000, 0.0e+000], # random\n",
    "       [     nan, 2.5e-323]])\n",
    "\n",
    "Second mode:\n",
    "\n",
    ">>> np.ndarray((2,), buffer=np.array([1,2,3]),\n",
    "...            offset=np.int_().itemsize,\n",
    "...            dtype=int) # offset = 1*itemsize, i.e. skip first element\n",
    "array([2, 3])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "pandas - a powerful data analysis and manipulation library for Python\n",
    "=====================================================================\n",
    "\n",
    "**pandas** is a Python package providing fast, flexible, and expressive data\n",
    "structures designed to make working with \"relational\" or \"labeled\" data both\n",
    "easy and intuitive. It aims to be the fundamental high-level building block for\n",
    "doing practical, **real world** data analysis in Python. Additionally, it has\n",
    "the broader goal of becoming **the most powerful and flexible open source data\n",
    "analysis / manipulation tool available in any language**. It is already well on\n",
    "its way toward this goal.\n",
    "\n",
    "Main Features\n",
    "-------------\n",
    "Here are just a few of the things that pandas does well:\n",
    "\n",
    "  - Easy handling of missing data in floating point as well as non-floating\n",
    "    point data.\n",
    "  - Size mutability: columns can be inserted and deleted from DataFrame and\n",
    "    higher dimensional objects\n",
    "  - Automatic and explicit data alignment: objects can be explicitly aligned\n",
    "    to a set of labels, or the user can simply ignore the labels and let\n",
    "    `Series`, `DataFrame`, etc. automatically align the data for you in\n",
    "    computations.\n",
    "  - Powerful, flexible group by functionality to perform split-apply-combine\n",
    "    operations on data sets, for both aggregating and transforming data.\n",
    "  - Make it easy to convert ragged, differently-indexed data in other Python\n",
    "    and NumPy data structures into DataFrame objects.\n",
    "  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
    "    data sets.\n",
    "  - Intuitive merging and joining data sets.\n",
    "  - Flexible reshaping and pivoting of data sets.\n",
    "  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
    "  - Robust IO tools for loading data from flat files (CSV and delimited),\n",
    "    Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
    "    format.\n",
    "  - Time series-specific functionality: date range generation and frequency\n",
    "    conversion, moving window statistics, date shifting and lagging.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
    "\n",
    "Data structure also contains labeled axes (rows and columns).\n",
    "Arithmetic operations align on both row and column labels. Can be\n",
    "thought of as a dict-like container for Series objects. The primary\n",
    "pandas data structure.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
    "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
    "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
    "    which have an index defined, it is aligned by its index.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "       If data is a list of dicts, column order follows insertion-order.\n",
    "\n",
    "index : Index or array-like\n",
    "    Index to use for resulting frame. Will default to RangeIndex if\n",
    "    no indexing information part of input data and no index provided.\n",
    "columns : Index or array-like\n",
    "    Column labels to use for resulting frame when data does not have them,\n",
    "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
    "    will perform column selection instead.\n",
    "dtype : dtype, default None\n",
    "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
    "copy : bool or None, default None\n",
    "    Copy data from inputs.\n",
    "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
    "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
    "\n",
    "    .. versionchanged:: 1.3.0\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
    "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
    "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "read_table : Read general delimited file into DataFrame.\n",
    "read_clipboard : Read text from clipboard into DataFrame.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Constructing DataFrame from a dictionary.\n",
    "\n",
    ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    ">>> df = pd.DataFrame(data=d)\n",
    ">>> df\n",
    "   col1  col2\n",
    "0     1     3\n",
    "1     2     4\n",
    "\n",
    "Notice that the inferred dtype is int64.\n",
    "\n",
    ">>> df.dtypes\n",
    "col1    int64\n",
    "col2    int64\n",
    "dtype: object\n",
    "\n",
    "To enforce a single dtype:\n",
    "\n",
    ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
    ">>> df.dtypes\n",
    "col1    int8\n",
    "col2    int8\n",
    "dtype: object\n",
    "\n",
    "Constructing DataFrame from a dictionary including Series:\n",
    "\n",
    ">>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
    ">>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
    "   col1  col2\n",
    "0     0   NaN\n",
    "1     1   NaN\n",
    "2     2   2.0\n",
    "3     3   3.0\n",
    "\n",
    "Constructing DataFrame from numpy ndarray:\n",
    "\n",
    ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "...                    columns=['a', 'b', 'c'])\n",
    ">>> df2\n",
    "   a  b  c\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "2  7  8  9\n",
    "\n",
    "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
    "\n",
    ">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
    "...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
    ">>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
    "...\n",
    ">>> df3\n",
    "   c  a\n",
    "0  3  1\n",
    "1  6  4\n",
    "2  9  7\n",
    "\n",
    "Constructing DataFrame from dataclass:\n",
    "\n",
    ">>> from dataclasses import make_dataclass\n",
    ">>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
    ">>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
    "   x  y\n",
    "0  0  0\n",
    "1  0  3\n",
    "2  2  3\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "One-dimensional ndarray with axis labels (including time series).\n",
    "\n",
    "Labels need not be unique but must be a hashable type. The object\n",
    "supports both integer- and label-based indexing and provides a host of\n",
    "methods for performing operations involving the index. Statistical\n",
    "methods from ndarray have been overridden to automatically exclude\n",
    "missing data (currently represented as NaN).\n",
    "\n",
    "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
    "associated index values-- they need not be the same length. The result\n",
    "index will be the sorted union of the two indexes.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : array-like, Iterable, dict, or scalar value\n",
    "    Contains data stored in Series. If data is a dict, argument order is\n",
    "    maintained.\n",
    "index : array-like or Index (1d)\n",
    "    Values must be hashable and have the same length as `data`.\n",
    "    Non-unique index values are allowed. Will default to\n",
    "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
    "    and index is None, then the keys in the data are used as the index. If the\n",
    "    index is not None, the resulting Series is reindexed with the index values.\n",
    "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
    "    Data type for the output Series. If not specified, this will be\n",
    "    inferred from `data`.\n",
    "    See the :ref:`user guide <basics.dtypes>` for more usages.\n",
    "name : str, optional\n",
    "    The name to give to the Series.\n",
    "copy : bool, default False\n",
    "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Constructing Series from a dictionary with an Index specified\n",
    "\n",
    ">>> d = {'a': 1, 'b': 2, 'c': 3}\n",
    ">>> ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
    ">>> ser\n",
    "a   1\n",
    "b   2\n",
    "c   3\n",
    "dtype: int64\n",
    "\n",
    "The keys of the dictionary match with the Index values, hence the Index\n",
    "values have no effect.\n",
    "\n",
    ">>> d = {'a': 1, 'b': 2, 'c': 3}\n",
    ">>> ser = pd.Series(data=d, index=['x', 'y', 'z'])\n",
    ">>> ser\n",
    "x   NaN\n",
    "y   NaN\n",
    "z   NaN\n",
    "dtype: float64\n",
    "\n",
    "Note that the Index is first build with the keys from the dictionary.\n",
    "After this the Series is reindexed with the given Index values, hence we\n",
    "get all NaN as a result.\n",
    "\n",
    "Constructing Series from a list with `copy=False`.\n",
    "\n",
    ">>> r = [1, 2]\n",
    ">>> ser = pd.Series(r, copy=False)\n",
    ">>> ser.iloc[0] = 999\n",
    ">>> r\n",
    "[1, 2]\n",
    ">>> ser\n",
    "0    999\n",
    "1      2\n",
    "dtype: int64\n",
    "\n",
    "Due to input data type the Series has a `copy` of\n",
    "the original data even though `copy=False`, so\n",
    "the data is unchanged.\n",
    "\n",
    "Constructing Series from a 1d ndarray with `copy=False`.\n",
    "\n",
    ">>> r = np.array([1, 2])\n",
    ">>> ser = pd.Series(r, copy=False)\n",
    ">>> ser.iloc[0] = 999\n",
    ">>> r\n",
    "array([999,   2])\n",
    ">>> ser\n",
    "0    999\n",
    "1      2\n",
    "dtype: int64\n",
    "\n",
    "Due to input data type the Series has a `view` on\n",
    "the original data, so\n",
    "the data is changed as well.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.io.parsers.readers.read_csv</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Read a comma-separated values (csv) file into DataFrame.\n",
    "\n",
    "Also supports optionally iterating or breaking of the file\n",
    "into chunks.\n",
    "\n",
    "Additional help can be found in the online docs for\n",
    "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "filepath_or_buffer : str, path object or file-like object\n",
    "    Any valid string path is acceptable. The string could be a URL. Valid\n",
    "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
    "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
    "\n",
    "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
    "\n",
    "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
    "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
    "sep : str, default ','\n",
    "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
    "    the separator, but the Python parsing engine can, meaning the latter will\n",
    "    be used and automatically detect the separator by Python's builtin sniffer\n",
    "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
    "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
    "    will also force the use of the Python parsing engine. Note that regex\n",
    "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
    "delimiter : str, default ``None``\n",
    "    Alias for sep.\n",
    "header : int, list of int, None, default 'infer'\n",
    "    Row number(s) to use as the column names, and the start of the\n",
    "    data.  Default behavior is to infer the column names: if no names\n",
    "    are passed the behavior is identical to ``header=0`` and column\n",
    "    names are inferred from the first line of the file, if column\n",
    "    names are passed explicitly then the behavior is identical to\n",
    "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
    "    replace existing names. The header can be a list of integers that\n",
    "    specify row locations for a multi-index on the columns\n",
    "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
    "    skipped (e.g. 2 in this example is skipped). Note that this\n",
    "    parameter ignores commented lines and empty lines if\n",
    "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
    "    data rather than the first line of the file.\n",
    "names : array-like, optional\n",
    "    List of column names to use. If the file contains a header row,\n",
    "    then you should explicitly pass ``header=0`` to override the column names.\n",
    "    Duplicates in this list are not allowed.\n",
    "index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
    "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
    "  string name or column index. If a sequence of int / str is given, a\n",
    "  MultiIndex is used.\n",
    "\n",
    "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
    "  column as the index, e.g. when you have a malformed file with delimiters at\n",
    "  the end of each line.\n",
    "usecols : list-like or callable, optional\n",
    "    Return a subset of the columns. If list-like, all elements must either\n",
    "    be positional (i.e. integer indices into the document columns) or strings\n",
    "    that correspond to column names provided either by the user in `names` or\n",
    "    inferred from the document header row(s). If ``names`` are given, the document\n",
    "    header row(s) are not taken into account. For example, a valid list-like\n",
    "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
    "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
    "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
    "    in ``['foo', 'bar']`` order or\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
    "    for ``['bar', 'foo']`` order.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the column\n",
    "    names, returning names where the callable function evaluates to True. An\n",
    "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
    "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
    "    parsing time and lower memory usage.\n",
    "squeeze : bool, default False\n",
    "    If the parsed data only contains one column then return a Series.\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "        Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
    "        the data.\n",
    "prefix : str, optional\n",
    "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "       Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
    "mangle_dupe_cols : bool, default True\n",
    "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
    "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
    "    are duplicate names in the columns.\n",
    "dtype : Type name or dict of column -> type, optional\n",
    "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
    "    'c': 'Int64'}\n",
    "    Use `str` or `object` together with suitable `na_values` settings\n",
    "    to preserve and not interpret dtype.\n",
    "    If converters are specified, they will be applied INSTEAD\n",
    "    of dtype conversion.\n",
    "engine : {'c', 'python', 'pyarrow'}, optional\n",
    "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
    "    is currently more feature-complete. Multithreading is currently only supported by\n",
    "    the pyarrow engine.\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "        The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
    "        are unsupported, or may not work correctly, with this engine.\n",
    "converters : dict, optional\n",
    "    Dict of functions for converting values in certain columns. Keys can either\n",
    "    be integers or column labels.\n",
    "true_values : list, optional\n",
    "    Values to consider as True.\n",
    "false_values : list, optional\n",
    "    Values to consider as False.\n",
    "skipinitialspace : bool, default False\n",
    "    Skip spaces after delimiter.\n",
    "skiprows : list-like, int or callable, optional\n",
    "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
    "    at the start of the file.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the row\n",
    "    indices, returning True if the row should be skipped and False otherwise.\n",
    "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
    "skipfooter : int, default 0\n",
    "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
    "nrows : int, optional\n",
    "    Number of rows of file to read. Useful for reading pieces of large files.\n",
    "na_values : scalar, str, list-like, or dict, optional\n",
    "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
    "    per-column NA values.  By default the following values are interpreted as\n",
    "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
    "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
    "    'nan', 'null'.\n",
    "keep_default_na : bool, default True\n",
    "    Whether or not to include the default NaN values when parsing the data.\n",
    "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
    "\n",
    "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
    "      is appended to the default NaN values used for parsing.\n",
    "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
    "      the default NaN values are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
    "      the NaN values specified `na_values` are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
    "      strings will be parsed as NaN.\n",
    "\n",
    "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
    "    `na_values` parameters will be ignored.\n",
    "na_filter : bool, default True\n",
    "    Detect missing value markers (empty strings and the value of na_values). In\n",
    "    data without any NAs, passing na_filter=False can improve the performance\n",
    "    of reading a large file.\n",
    "verbose : bool, default False\n",
    "    Indicate number of NA values placed in non-numeric columns.\n",
    "skip_blank_lines : bool, default True\n",
    "    If True, skip over blank lines rather than interpreting as NaN values.\n",
    "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
    "    The behavior is as follows:\n",
    "\n",
    "    * boolean. If True -> try parsing the index.\n",
    "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
    "      each as a separate date column.\n",
    "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
    "      a single date column.\n",
    "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
    "      result 'foo'\n",
    "\n",
    "    If a column or index cannot be represented as an array of datetimes,\n",
    "    say because of an unparsable value or a mixture of timezones, the column\n",
    "    or index will be returned unaltered as an object data type. For\n",
    "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
    "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
    "    specify ``date_parser`` to be a partially-applied\n",
    "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
    "    :ref:`io.csv.mixed_timezones` for more.\n",
    "\n",
    "    Note: A fast-path exists for iso8601-formatted dates.\n",
    "infer_datetime_format : bool, default False\n",
    "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
    "    format of the datetime strings in the columns, and if it can be inferred,\n",
    "    switch to a faster method of parsing them. In some cases this can increase\n",
    "    the parsing speed by 5-10x.\n",
    "keep_date_col : bool, default False\n",
    "    If True and `parse_dates` specifies combining multiple columns then\n",
    "    keep the original columns.\n",
    "date_parser : function, optional\n",
    "    Function to use for converting a sequence of string columns to an array of\n",
    "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
    "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
    "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
    "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
    "    string values from the columns defined by `parse_dates` into a single array\n",
    "    and pass that; and 3) call `date_parser` once for each row using one or\n",
    "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
    "    arguments.\n",
    "dayfirst : bool, default False\n",
    "    DD/MM format dates, international and European format.\n",
    "cache_dates : bool, default True\n",
    "    If True, use a cache of unique, converted dates to apply the datetime\n",
    "    conversion. May produce significant speed-up when parsing duplicate\n",
    "    date strings, especially ones with timezone offsets.\n",
    "\n",
    "    .. versionadded:: 0.25.0\n",
    "iterator : bool, default False\n",
    "    Return TextFileReader object for iteration or getting chunks with\n",
    "    ``get_chunk()``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "chunksize : int, optional\n",
    "    Return TextFileReader object for iteration.\n",
    "    See the `IO Tools docs\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
    "    for more information on ``iterator`` and ``chunksize``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "compression : str or dict, default 'infer'\n",
    "    For on-the-fly decompression of on-disk data. If 'infer' and '%s' is\n",
    "    path-like, then detect compression from the following extensions: '.gz',\n",
    "    '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). If using\n",
    "    'zip', the ZIP file must contain only one data file to be read in. Set to\n",
    "    ``None`` for no decompression. Can also be a dict with key ``'method'`` set\n",
    "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
    "    key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
    "    ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
    "    example, the following could be passed for Zstandard decompression using a\n",
    "    custom compression dictionary:\n",
    "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
    "\n",
    "    .. versionchanged:: 1.4.0 Zstandard support.\n",
    "\n",
    "thousands : str, optional\n",
    "    Thousands separator.\n",
    "decimal : str, default '.'\n",
    "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
    "lineterminator : str (length 1), optional\n",
    "    Character to break file into lines. Only valid with C parser.\n",
    "quotechar : str (length 1), optional\n",
    "    The character used to denote the start and end of a quoted item. Quoted\n",
    "    items can include the delimiter and it will be ignored.\n",
    "quoting : int or csv.QUOTE_* instance, default 0\n",
    "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
    "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "doublequote : bool, default ``True``\n",
    "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
    "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
    "   field as a single ``quotechar`` element.\n",
    "escapechar : str (length 1), optional\n",
    "    One-character string used to escape other characters.\n",
    "comment : str, optional\n",
    "    Indicates remainder of line should not be parsed. If found at the beginning\n",
    "    of a line, the line will be ignored altogether. This parameter must be a\n",
    "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
    "    fully commented lines are ignored by the parameter `header` but not by\n",
    "    `skiprows`. For example, if ``comment='#'``, parsing\n",
    "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
    "    treated as the header.\n",
    "encoding : str, optional\n",
    "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
    "    standard encodings\n",
    "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
    "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
    "       This behavior was previously only the case for ``engine=\"python\"``.\n",
    "\n",
    "    .. versionchanged:: 1.3.0\n",
    "\n",
    "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
    "       influence on how encoding errors are handled.\n",
    "\n",
    "encoding_errors : str, optional, default \"strict\"\n",
    "    How encoding errors are treated. `List of possible values\n",
    "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "dialect : str or csv.Dialect, optional\n",
    "    If provided, this parameter will override values (default or not) for the\n",
    "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
    "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
    "    override values, a ParserWarning will be issued. See csv.Dialect\n",
    "    documentation for more details.\n",
    "error_bad_lines : bool, optional, default ``None``\n",
    "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
    "    default cause an exception to be raised, and no DataFrame will be returned.\n",
    "    If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
    "    returned.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "warn_bad_lines : bool, optional, default ``None``\n",
    "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
    "    \"bad line\" will be output.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
    "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
    "    Allowed values are :\n",
    "\n",
    "        - 'error', raise an Exception when a bad line is encountered.\n",
    "        - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
    "        - 'skip', skip bad lines without raising or warning when they are encountered.\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "        - callable, function with signature\n",
    "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
    "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
    "          If the function returns ``None``, the bad line will be ignored.\n",
    "          If the function returns a new list of strings with more elements than\n",
    "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
    "          Only supported when ``engine=\"python\"``\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "delim_whitespace : bool, default False\n",
    "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
    "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
    "    is set to True, nothing should be passed in for the ``delimiter``\n",
    "    parameter.\n",
    "low_memory : bool, default True\n",
    "    Internally process the file in chunks, resulting in lower memory use\n",
    "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
    "    types either set False, or specify the type with the `dtype` parameter.\n",
    "    Note that the entire file is read into a single DataFrame regardless,\n",
    "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
    "    (Only valid with C parser).\n",
    "memory_map : bool, default False\n",
    "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
    "    directly onto memory and access the data directly from there. Using this\n",
    "    option can improve performance because there is no longer any I/O overhead.\n",
    "float_precision : str, optional\n",
    "    Specifies which converter the C engine should use for floating-point\n",
    "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
    "    'legacy' for the original lower precision pandas converter, and\n",
    "    'round_trip' for the round-trip converter.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "storage_options : dict, optional\n",
    "    Extra options that make sense for a particular storage connection, e.g.\n",
    "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
    "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
    "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
    "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
    "\n",
    "    .. versionadded:: 1.2\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame or TextParser\n",
    "    A comma-separated values (csv) file is returned as two-dimensional\n",
    "    data structure with labeled axes.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
    "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li> <b>scipy</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "=========================================\n",
    "Clustering package (:mod:`scipy.cluster`)\n",
    "=========================================\n",
    "\n",
    ".. currentmodule:: scipy.cluster\n",
    "\n",
    ".. toctree::\n",
    "   :hidden:\n",
    "\n",
    "   cluster.vq\n",
    "   cluster.hierarchy\n",
    "\n",
    "Clustering algorithms are useful in information theory, target detection,\n",
    "communications, compression, and other areas. The `vq` module only\n",
    "supports vector quantization and the k-means algorithms.\n",
    "\n",
    "The `hierarchy` module provides functions for hierarchical and\n",
    "agglomerative clustering.  Its features include generating hierarchical\n",
    "clusters from distance matrices,\n",
    "calculating statistics on clusters, cutting linkages\n",
    "to generate flat clusters, and visualizing clusters with dendrograms.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Hierarchical clustering (:mod:`scipy.cluster.hierarchy`)\n",
    "========================================================\n",
    "\n",
    ".. currentmodule:: scipy.cluster.hierarchy\n",
    "\n",
    "These functions cut hierarchical clusterings into flat clusterings\n",
    "or find the roots of the forest formed by a cut by providing the flat\n",
    "cluster ids of each observation.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   fcluster\n",
    "   fclusterdata\n",
    "   leaders\n",
    "\n",
    "These are routines for agglomerative clustering.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   linkage\n",
    "   single\n",
    "   complete\n",
    "   average\n",
    "   weighted\n",
    "   centroid\n",
    "   median\n",
    "   ward\n",
    "\n",
    "These routines compute statistics on hierarchies.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   cophenet\n",
    "   from_mlab_linkage\n",
    "   inconsistent\n",
    "   maxinconsts\n",
    "   maxdists\n",
    "   maxRstat\n",
    "   to_mlab_linkage\n",
    "\n",
    "Routines for visualizing flat clusters.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   dendrogram\n",
    "\n",
    "These are data structures and routines for representing hierarchies as\n",
    "tree objects.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   ClusterNode\n",
    "   leaves_list\n",
    "   to_tree\n",
    "   cut_tree\n",
    "   optimal_leaf_ordering\n",
    "\n",
    "These are predicates for checking the validity of linkage and\n",
    "inconsistency matrices as well as for checking isomorphism of two\n",
    "flat cluster assignments.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   is_valid_im\n",
    "   is_valid_linkage\n",
    "   is_isomorphic\n",
    "   is_monotonic\n",
    "   correspond\n",
    "   num_obs_linkage\n",
    "\n",
    "Utility routines for plotting:\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   set_link_color_palette\n",
    "\n",
    "Utility classes:\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   DisjointSet -- data structure for incremental connectivity queries\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.dendrogram</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Plot the hierarchical clustering as a dendrogram.\n",
    "\n",
    "The dendrogram illustrates how each cluster is\n",
    "composed by drawing a U-shaped link between a non-singleton\n",
    "cluster and its children. The top of the U-link indicates a\n",
    "cluster merge. The two legs of the U-link indicate which clusters\n",
    "were merged. The length of the two legs of the U-link represents\n",
    "the distance between the child clusters. It is also the\n",
    "cophenetic distance between original observations in the two\n",
    "children clusters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The linkage matrix encoding the hierarchical clustering to\n",
    "    render as a dendrogram. See the ``linkage`` function for more\n",
    "    information on the format of ``Z``.\n",
    "p : int, optional\n",
    "    The ``p`` parameter for ``truncate_mode``.\n",
    "truncate_mode : str, optional\n",
    "    The dendrogram can be hard to read when the original\n",
    "    observation matrix from which the linkage is derived is\n",
    "    large. Truncation is used to condense the dendrogram. There\n",
    "    are several modes:\n",
    "\n",
    "    ``None``\n",
    "      No truncation is performed (default).\n",
    "      Note: ``'none'`` is an alias for ``None`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "    ``'lastp'``\n",
    "      The last ``p`` non-singleton clusters formed in the linkage are the\n",
    "      only non-leaf nodes in the linkage; they correspond to rows\n",
    "      ``Z[n-p-2:end]`` in ``Z``. All other non-singleton clusters are\n",
    "      contracted into leaf nodes.\n",
    "\n",
    "    ``'level'``\n",
    "      No more than ``p`` levels of the dendrogram tree are displayed.\n",
    "      A \"level\" includes all nodes with ``p`` merges from the final merge.\n",
    "\n",
    "      Note: ``'mtica'`` is an alias for ``'level'`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "color_threshold : double, optional\n",
    "    For brevity, let :math:`t` be the ``color_threshold``.\n",
    "    Colors all the descendent links below a cluster node\n",
    "    :math:`k` the same color if :math:`k` is the first node below\n",
    "    the cut threshold :math:`t`. All links connecting nodes with\n",
    "    distances greater than or equal to the threshold are colored\n",
    "    with de default matplotlib color ``'C0'``. If :math:`t` is less\n",
    "    than or equal to zero, all nodes are colored ``'C0'``.\n",
    "    If ``color_threshold`` is None or 'default',\n",
    "    corresponding with MATLAB(TM) behavior, the threshold is set to\n",
    "    ``0.7*max(Z[:,2])``.\n",
    "\n",
    "get_leaves : bool, optional\n",
    "    Includes a list ``R['leaves']=H`` in the result\n",
    "    dictionary. For each :math:`i`, ``H[i] == j``, cluster node\n",
    "    ``j`` appears in position ``i`` in the left-to-right traversal\n",
    "    of the leaves, where :math:`j < 2n-1` and :math:`i < n`.\n",
    "orientation : str, optional\n",
    "    The direction to plot the dendrogram, which can be any\n",
    "    of the following strings:\n",
    "\n",
    "    ``'top'``\n",
    "      Plots the root at the top, and plot descendent links going downwards.\n",
    "      (default).\n",
    "\n",
    "    ``'bottom'``\n",
    "      Plots the root at the bottom, and plot descendent links going\n",
    "      upwards.\n",
    "\n",
    "    ``'left'``\n",
    "      Plots the root at the left, and plot descendent links going right.\n",
    "\n",
    "    ``'right'``\n",
    "      Plots the root at the right, and plot descendent links going left.\n",
    "\n",
    "labels : ndarray, optional\n",
    "    By default, ``labels`` is None so the index of the original observation\n",
    "    is used to label the leaf nodes.  Otherwise, this is an :math:`n`-sized\n",
    "    sequence, with ``n == Z.shape[0] + 1``. The ``labels[i]`` value is the\n",
    "    text to put under the :math:`i` th leaf node only if it corresponds to\n",
    "    an original observation and not a non-singleton cluster.\n",
    "count_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    Note, ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "distance_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    Note ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "show_leaf_counts : bool, optional\n",
    "     When True, leaf nodes representing :math:`k>1` original\n",
    "     observation are labeled with the number of observations they\n",
    "     contain in parentheses.\n",
    "no_plot : bool, optional\n",
    "    When True, the final rendering is not performed. This is\n",
    "    useful if only the data structures computed for the rendering\n",
    "    are needed or if matplotlib is not available.\n",
    "no_labels : bool, optional\n",
    "    When True, no labels appear next to the leaf nodes in the\n",
    "    rendering of the dendrogram.\n",
    "leaf_rotation : double, optional\n",
    "    Specifies the angle (in degrees) to rotate the leaf\n",
    "    labels. When unspecified, the rotation is based on the number of\n",
    "    nodes in the dendrogram (default is 0).\n",
    "leaf_font_size : int, optional\n",
    "    Specifies the font size (in points) of the leaf labels. When\n",
    "    unspecified, the size based on the number of nodes in the\n",
    "    dendrogram.\n",
    "leaf_label_func : lambda or function, optional\n",
    "    When ``leaf_label_func`` is a callable function, for each\n",
    "    leaf with cluster index :math:`k < 2n-1`. The function\n",
    "    is expected to return a string with the label for the\n",
    "    leaf.\n",
    "\n",
    "    Indices :math:`k < n` correspond to original observations\n",
    "    while indices :math:`k \\geq n` correspond to non-singleton\n",
    "    clusters.\n",
    "\n",
    "    For example, to label singletons with their node id and\n",
    "    non-singletons with their id, count, and inconsistency\n",
    "    coefficient, simply do::\n",
    "\n",
    "        # First define the leaf label function.\n",
    "        def llf(id):\n",
    "            if id < n:\n",
    "                return str(id)\n",
    "            else:\n",
    "                return '[%d %d %1.2f]' % (id, count, R[n-id,3])\n",
    "\n",
    "        # The text for the leaf nodes is going to be big so force\n",
    "        # a rotation of 90 degrees.\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90)\n",
    "\n",
    "        # leaf_label_func can also be used together with ``truncate_mode`` parameter,\n",
    "        # in which case you will get your leaves labeled after truncation:\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90,\n",
    "                   truncate_mode='level', p=2)\n",
    "\n",
    "show_contracted : bool, optional\n",
    "    When True the heights of non-singleton nodes contracted\n",
    "    into a leaf node are plotted as crosses along the link\n",
    "    connecting that leaf node.  This really is only useful when\n",
    "    truncation is used (see ``truncate_mode`` parameter).\n",
    "link_color_func : callable, optional\n",
    "    If given, `link_color_function` is called with each non-singleton id\n",
    "    corresponding to each U-shaped link it will paint. The function is\n",
    "    expected to return the color to paint the link, encoded as a matplotlib\n",
    "    color string code. For example::\n",
    "\n",
    "        dendrogram(Z, link_color_func=lambda k: colors[k])\n",
    "\n",
    "    colors the direct links below each untruncated non-singleton node\n",
    "    ``k`` using ``colors[k]``.\n",
    "ax : matplotlib Axes instance, optional\n",
    "    If None and `no_plot` is not True, the dendrogram will be plotted\n",
    "    on the current axes.  Otherwise if `no_plot` is not True the\n",
    "    dendrogram will be plotted on the given ``Axes`` instance. This can be\n",
    "    useful if the dendrogram is part of a more complex figure.\n",
    "above_threshold_color : str, optional\n",
    "    This matplotlib color string sets the color of the links above the\n",
    "    color_threshold. The default is ``'C0'``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : dict\n",
    "    A dictionary of data structures computed to render the\n",
    "    dendrogram. Its has the following keys:\n",
    "\n",
    "    ``'color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th link.\n",
    "\n",
    "    ``'icoord'`` and ``'dcoord'``\n",
    "      Each of them is a list of lists. Let ``icoord = [I1, I2, ..., Ip]``\n",
    "      where ``Ik = [xk1, xk2, xk3, xk4]`` and ``dcoord = [D1, D2, ..., Dp]``\n",
    "      where ``Dk = [yk1, yk2, yk3, yk4]``, then the k'th link painted is\n",
    "      ``(xk1, yk1)`` - ``(xk2, yk2)`` - ``(xk3, yk3)`` - ``(xk4, yk4)``.\n",
    "\n",
    "    ``'ivl'``\n",
    "      A list of labels corresponding to the leaf nodes.\n",
    "\n",
    "    ``'leaves'``\n",
    "      For each i, ``H[i] == j``, cluster node ``j`` appears in position\n",
    "      ``i`` in the left-to-right traversal of the leaves, where\n",
    "      :math:`j < 2n-1` and :math:`i < n`. If ``j`` is less than ``n``, the\n",
    "      ``i``-th leaf node corresponds to an original observation.\n",
    "      Otherwise, it corresponds to a non-singleton cluster.\n",
    "\n",
    "    ``'leaves_color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th leaf.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage, set_link_color_palette\n",
    "\n",
    "Notes\n",
    "-----\n",
    "It is expected that the distances in ``Z[:,2]`` be monotonic, otherwise\n",
    "crossings appear in the dendrogram.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import numpy as np\n",
    ">>> from scipy.cluster import hierarchy\n",
    ">>> import matplotlib.pyplot as plt\n",
    "\n",
    "A very basic example:\n",
    "\n",
    ">>> ytdist = np.array([662., 877., 255., 412., 996., 295., 468., 268.,\n",
    "...                    400., 754., 564., 138., 219., 869., 669.])\n",
    ">>> Z = hierarchy.linkage(ytdist, 'single')\n",
    ">>> plt.figure()\n",
    ">>> dn = hierarchy.dendrogram(Z)\n",
    "\n",
    "Now, plot in given axes, improve the color scheme and use both vertical and\n",
    "horizontal orientations:\n",
    "\n",
    ">>> hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    ">>> fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    ">>> dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "...                            orientation='top')\n",
    ">>> dn2 = hierarchy.dendrogram(Z, ax=axes[1],\n",
    "...                            above_threshold_color='#bcbddc',\n",
    "...                            orientation='right')\n",
    ">>> hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.fcluster</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Form flat clusters from the hierarchical clustering defined by\n",
    "the given linkage matrix.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded with the matrix returned\n",
    "    by the `linkage` function.\n",
    "t : scalar\n",
    "    For criteria 'inconsistent', 'distance' or 'monocrit',\n",
    "     this is the threshold to apply when forming flat clusters.\n",
    "    For 'maxclust' or 'maxclust_monocrit' criteria,\n",
    "     this would be max number of clusters requested.\n",
    "criterion : str, optional\n",
    "    The criterion to use in forming flat clusters. This can\n",
    "    be any of the following values:\n",
    "\n",
    "      ``inconsistent`` :\n",
    "          If a cluster node and all its\n",
    "          descendants have an inconsistent value less than or equal\n",
    "          to `t`, then all its leaf descendants belong to the\n",
    "          same flat cluster. When no non-singleton cluster meets\n",
    "          this criterion, every node is assigned to its own\n",
    "          cluster. (Default)\n",
    "\n",
    "      ``distance`` :\n",
    "          Forms flat clusters so that the original\n",
    "          observations in each flat cluster have no greater a\n",
    "          cophenetic distance than `t`.\n",
    "\n",
    "      ``maxclust`` :\n",
    "          Finds a minimum threshold ``r`` so that\n",
    "          the cophenetic distance between any two original\n",
    "          observations in the same flat cluster is no more than\n",
    "          ``r`` and no more than `t` flat clusters are formed.\n",
    "\n",
    "      ``monocrit`` :\n",
    "          Forms a flat cluster from a cluster node c\n",
    "          with index i when ``monocrit[j] <= t``.\n",
    "\n",
    "          For example, to threshold on the maximum mean distance\n",
    "          as computed in the inconsistency matrix R with a\n",
    "          threshold of 0.8 do::\n",
    "\n",
    "              MR = maxRstat(Z, R, 3)\n",
    "              fcluster(Z, t=0.8, criterion='monocrit', monocrit=MR)\n",
    "\n",
    "      ``maxclust_monocrit`` :\n",
    "          Forms a flat cluster from a\n",
    "          non-singleton cluster node ``c`` when ``monocrit[i] <=\n",
    "          r`` for all cluster indices ``i`` below and including\n",
    "          ``c``. ``r`` is minimized such that no more than ``t``\n",
    "          flat clusters are formed. monocrit must be\n",
    "          monotonic. For example, to minimize the threshold t on\n",
    "          maximum inconsistency values so that no more than 3 flat\n",
    "          clusters are formed, do::\n",
    "\n",
    "              MI = maxinconsts(Z, R)\n",
    "              fcluster(Z, t=3, criterion='maxclust_monocrit', monocrit=MI)\n",
    "depth : int, optional\n",
    "    The maximum depth to perform the inconsistency calculation.\n",
    "    It has no meaning for the other criteria. Default is 2.\n",
    "R : ndarray, optional\n",
    "    The inconsistency matrix to use for the 'inconsistent'\n",
    "    criterion. This matrix is computed if not provided.\n",
    "monocrit : ndarray, optional\n",
    "    An array of length n-1. `monocrit[i]` is the\n",
    "    statistics upon which non-singleton i is thresholded. The\n",
    "    monocrit vector must be monotonic, i.e., given a node c with\n",
    "    index i, for all node indices j corresponding to nodes\n",
    "    below c, ``monocrit[i] >= monocrit[j]``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "fcluster : ndarray\n",
    "    An array of length ``n``. ``T[i]`` is the flat cluster number to\n",
    "    which original observation ``i`` belongs.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage : for information about hierarchical clustering methods work.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import ward, fcluster\n",
    ">>> from scipy.spatial.distance import pdist\n",
    "\n",
    "All cluster linkage methods - e.g., `scipy.cluster.hierarchy.ward`\n",
    "generate a linkage matrix ``Z`` as their output:\n",
    "\n",
    ">>> X = [[0, 0], [0, 1], [1, 0],\n",
    "...      [0, 4], [0, 3], [1, 4],\n",
    "...      [4, 0], [3, 0], [4, 1],\n",
    "...      [4, 4], [3, 4], [4, 3]]\n",
    "\n",
    ">>> Z = ward(pdist(X))\n",
    "\n",
    ">>> Z\n",
    "array([[ 0.        ,  1.        ,  1.        ,  2.        ],\n",
    "       [ 3.        ,  4.        ,  1.        ,  2.        ],\n",
    "       [ 6.        ,  7.        ,  1.        ,  2.        ],\n",
    "       [ 9.        , 10.        ,  1.        ,  2.        ],\n",
    "       [ 2.        , 12.        ,  1.29099445,  3.        ],\n",
    "       [ 5.        , 13.        ,  1.29099445,  3.        ],\n",
    "       [ 8.        , 14.        ,  1.29099445,  3.        ],\n",
    "       [11.        , 15.        ,  1.29099445,  3.        ],\n",
    "       [16.        , 17.        ,  5.77350269,  6.        ],\n",
    "       [18.        , 19.        ,  5.77350269,  6.        ],\n",
    "       [20.        , 21.        ,  8.16496581, 12.        ]])\n",
    "\n",
    "This matrix represents a dendrogram, where the first and second elements\n",
    "are the two clusters merged at each step, the third element is the\n",
    "distance between these clusters, and the fourth element is the size of\n",
    "the new cluster - the number of original data points included.\n",
    "\n",
    "`scipy.cluster.hierarchy.fcluster` can be used to flatten the\n",
    "dendrogram, obtaining as a result an assignation of the original data\n",
    "points to single clusters.\n",
    "\n",
    "This assignation mostly depends on a distance threshold ``t`` - the maximum\n",
    "inter-cluster distance allowed:\n",
    "\n",
    ">>> fcluster(Z, t=0.9, criterion='distance')\n",
    "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=1.1, criterion='distance')\n",
    "array([1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=3, criterion='distance')\n",
    "array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=9, criterion='distance')\n",
    "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)\n",
    "\n",
    "In the first case, the threshold ``t`` is too small to allow any two\n",
    "samples in the data to form a cluster, so 12 different clusters are\n",
    "returned.\n",
    "\n",
    "In the second case, the threshold is large enough to allow the first\n",
    "4 points to be merged with their nearest neighbors. So, here, only 8\n",
    "clusters are returned.\n",
    "\n",
    "The third case, with a much higher threshold, allows for up to 8 data\n",
    "points to be connected - so 4 clusters are returned here.\n",
    "\n",
    "Lastly, the threshold of the fourth case is large enough to allow for\n",
    "all data points to be merged together - so a single cluster is returned.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.linkage</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Perform hierarchical/agglomerative clustering.\n",
    "\n",
    "The input y may be either a 1-D condensed distance matrix\n",
    "or a 2-D array of observation vectors.\n",
    "\n",
    "If y is a 1-D condensed distance matrix,\n",
    "then y must be a :math:`\\binom{n}{2}` sized\n",
    "vector, where n is the number of original observations paired\n",
    "in the distance matrix. The behavior of this function is very\n",
    "similar to the MATLAB linkage function.\n",
    "\n",
    "A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
    ":math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
    "``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
    "cluster with an index less than :math:`n` corresponds to one of\n",
    "the :math:`n` original observations. The distance between\n",
    "clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
    "fourth value ``Z[i, 3]`` represents the number of original\n",
    "observations in the newly formed cluster.\n",
    "\n",
    "The following linkage methods are used to compute the distance\n",
    ":math:`d(s, t)` between two clusters :math:`s` and\n",
    ":math:`t`. The algorithm begins with a forest of clusters that\n",
    "have yet to be used in the hierarchy being formed. When two\n",
    "clusters :math:`s` and :math:`t` from this forest are combined\n",
    "into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
    "removed from the forest, and :math:`u` is added to the\n",
    "forest. When only one cluster remains in the forest, the algorithm\n",
    "stops, and this cluster becomes the root.\n",
    "\n",
    "A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
    "entry corresponds to the distance between cluster :math:`i` and\n",
    ":math:`j` in the original forest.\n",
    "\n",
    "At each iteration, the algorithm must update the distance matrix\n",
    "to reflect the distance of the newly formed cluster u with the\n",
    "remaining clusters in the forest.\n",
    "\n",
    "Suppose there are :math:`|u|` original observations\n",
    ":math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
    ":math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
    "cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n",
    "combined to form cluster :math:`u`. Let :math:`v` be any\n",
    "remaining cluster in the forest that is not :math:`u`.\n",
    "\n",
    "The following are methods for calculating the distance between the\n",
    "newly formed cluster :math:`u` and each :math:`v`.\n",
    "\n",
    "  * method='single' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\min(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster :math:`u` and\n",
    "    :math:`j` in cluster :math:`v`. This is also known as the\n",
    "    Nearest Point Algorithm.\n",
    "\n",
    "  * method='complete' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u, v) = \\max(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster u and :math:`j` in\n",
    "    cluster :math:`v`. This is also known by the Farthest Point\n",
    "    Algorithm or Voor Hees Algorithm.\n",
    "\n",
    "  * method='average' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
    "                               {(|u|*|v|)}\n",
    "\n",
    "    for all points :math:`i` and :math:`j` where :math:`|u|`\n",
    "    and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
    "    and :math:`v`, respectively. This is also called the UPGMA\n",
    "    algorithm.\n",
    "\n",
    "  * method='weighted' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = (dist(s,v) + dist(t,v))/2\n",
    "\n",
    "    where cluster u was formed with cluster s and t and v\n",
    "    is a remaining cluster in the forest (also called WPGMA).\n",
    "\n",
    "  * method='centroid' assigns\n",
    "\n",
    "    .. math::\n",
    "       dist(s,t) = ||c_s-c_t||_2\n",
    "\n",
    "    where :math:`c_s` and :math:`c_t` are the centroids of\n",
    "    clusters :math:`s` and :math:`t`, respectively. When two\n",
    "    clusters :math:`s` and :math:`t` are combined into a new\n",
    "    cluster :math:`u`, the new centroid is computed over all the\n",
    "    original objects in clusters :math:`s` and :math:`t`. The\n",
    "    distance then becomes the Euclidean distance between the\n",
    "    centroid of :math:`u` and the centroid of a remaining cluster\n",
    "    :math:`v` in the forest. This is also known as the UPGMC\n",
    "    algorithm.\n",
    "\n",
    "  * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
    "    method. When two clusters :math:`s` and :math:`t` are combined\n",
    "    into a new cluster :math:`u`, the average of centroids s and t\n",
    "    give the new centroid :math:`u`. This is also known as the\n",
    "    WPGMC algorithm.\n",
    "\n",
    "  * method='ward' uses the Ward variance minimization algorithm.\n",
    "    The new entry :math:`d(u,v)` is computed as follows,\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
    "                           {T}d(v,s)^2\n",
    "                    + \\frac{|v|+|t|}\n",
    "                           {T}d(v,t)^2\n",
    "                    - \\frac{|v|}\n",
    "                           {T}d(s,t)^2}\n",
    "\n",
    "    where :math:`u` is the newly joined cluster consisting of\n",
    "    clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
    "    cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
    "    :math:`|*|` is the cardinality of its argument. This is also\n",
    "    known as the incremental algorithm.\n",
    "\n",
    "Warning: When the minimum distance pair in the forest is chosen, there\n",
    "may be two or more pairs with the same minimum distance. This\n",
    "implementation may choose a different minimum than the MATLAB\n",
    "version.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "y : ndarray\n",
    "    A condensed distance matrix. A condensed distance matrix\n",
    "    is a flat array containing the upper triangular of the distance matrix.\n",
    "    This is the form that ``pdist`` returns. Alternatively, a collection of\n",
    "    :math:`m` observation vectors in :math:`n` dimensions may be passed as\n",
    "    an :math:`m` by :math:`n` array. All elements of the condensed distance\n",
    "    matrix must be finite, i.e., no NaNs or infs.\n",
    "method : str, optional\n",
    "    The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
    "    for full descriptions.\n",
    "metric : str or function, optional\n",
    "    The distance metric to use in the case that y is a collection of\n",
    "    observation vectors; ignored otherwise. See the ``pdist``\n",
    "    function for a list of valid distance metrics. A custom distance\n",
    "    function can also be used.\n",
    "optimal_ordering : bool, optional\n",
    "    If True, the linkage matrix will be reordered so that the distance\n",
    "    between successive leaves is minimal. This results in a more intuitive\n",
    "    tree structure when the data are visualized. defaults to False, because\n",
    "    this algorithm can be slow, particularly on large datasets [2]_. See\n",
    "    also the `optimal_leaf_ordering` function.\n",
    "\n",
    "    .. versionadded:: 1.0.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded as a linkage matrix.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "1. For method 'single', an optimized algorithm based on minimum spanning\n",
    "   tree is implemented. It has time complexity :math:`O(n^2)`.\n",
    "   For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n",
    "   called nearest-neighbors chain is implemented. It also has time\n",
    "   complexity :math:`O(n^2)`.\n",
    "   For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n",
    "   time complexity.\n",
    "   All algorithms use :math:`O(n^2)` memory.\n",
    "   Refer to [1]_ for details about the algorithms.\n",
    "2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n",
    "   Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
    "   pairwise distances, then it is the user's responsibility to assure that\n",
    "   these distances are in fact Euclidean, otherwise the produced result\n",
    "   will be incorrect.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "scipy.spatial.distance.pdist : pairwise distance metrics\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
    "       algorithms\", :arXiv:`1109.2378v1`.\n",
    ".. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n",
    "       leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n",
    "       :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import dendrogram, linkage\n",
    ">>> from matplotlib import pyplot as plt\n",
    ">>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "\n",
    ">>> Z = linkage(X, 'ward')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    "\n",
    ">>> Z = linkage(X, 'single')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.io</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "==================================\n",
    "Input and output (:mod:`scipy.io`)\n",
    "==================================\n",
    "\n",
    ".. currentmodule:: scipy.io\n",
    "\n",
    "SciPy has many modules, classes, and functions available to read data\n",
    "from and write data to a variety of file formats.\n",
    "\n",
    ".. seealso:: `NumPy IO routines <https://www.numpy.org/devdocs/reference/routines.io.html>`__\n",
    "\n",
    "MATLAB files\n",
    "=============\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   loadmat - Read a MATLAB style mat file (version 4 through 7.1)\n",
    "   savemat - Write a MATLAB style mat file (version 4 through 7.1)\n",
    "   whosmat - List contents of a MATLAB style mat file (version 4 through 7.1)\n",
    "\n",
    "For low-level MATLAB reading and writing utilities, see `scipy.io.matlab`.\n",
    "\n",
    "IDL files\n",
    "==========\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   readsav - Read an IDL 'save' file\n",
    "\n",
    "Matrix Market files\n",
    "===================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   mminfo - Query matrix info from Matrix Market formatted file\n",
    "   mmread - Read matrix from Matrix Market formatted file\n",
    "   mmwrite - Write matrix to Matrix Market formatted file\n",
    "\n",
    "Unformatted Fortran files\n",
    "===============================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   FortranFile - A file object for unformatted sequential Fortran files\n",
    "   FortranEOFError - Exception indicating the end of a well-formed file\n",
    "   FortranFormattingError - Exception indicating an inappropriate end\n",
    "\n",
    "Netcdf\n",
    "======\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   netcdf_file - A file object for NetCDF data\n",
    "   netcdf_variable - A data object for the netcdf module\n",
    "\n",
    "Harwell-Boeing files\n",
    "====================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   hb_read   -- read H-B file\n",
    "   hb_write  -- write H-B file\n",
    "\n",
    "Wav sound files (:mod:`scipy.io.wavfile`)\n",
    "=========================================\n",
    "\n",
    ".. module:: scipy.io.wavfile\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   read\n",
    "   write\n",
    "   WavFileWarning\n",
    "\n",
    "Arff files (:mod:`scipy.io.arff`)\n",
    "=================================\n",
    "\n",
    ".. module:: scipy.io.arff\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   loadarff\n",
    "   MetaData\n",
    "   ArffError\n",
    "   ParseArffError\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.io.matlab._mio.loadmat</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Load MATLAB file.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "file_name : str\n",
    "   Name of the mat file (do not need .mat extension if\n",
    "   appendmat==True). Can also pass open file-like object.\n",
    "mdict : dict, optional\n",
    "    Dictionary in which to insert matfile variables.\n",
    "appendmat : bool, optional\n",
    "   True to append the .mat extension to the end of the given\n",
    "   filename, if not already present. Default is True.\n",
    "byte_order : str or None, optional\n",
    "   None by default, implying byte order guessed from mat\n",
    "   file. Otherwise can be one of ('native', '=', 'little', '<',\n",
    "   'BIG', '>').\n",
    "mat_dtype : bool, optional\n",
    "   If True, return arrays in same dtype as would be loaded into\n",
    "   MATLAB (instead of the dtype with which they are saved).\n",
    "squeeze_me : bool, optional\n",
    "   Whether to squeeze unit matrix dimensions or not.\n",
    "chars_as_strings : bool, optional\n",
    "   Whether to convert char arrays to string arrays.\n",
    "matlab_compatible : bool, optional\n",
    "   Returns matrices as would be loaded by MATLAB (implies\n",
    "   squeeze_me=False, chars_as_strings=False, mat_dtype=True,\n",
    "   struct_as_record=True).\n",
    "struct_as_record : bool, optional\n",
    "   Whether to load MATLAB structs as NumPy record arrays, or as\n",
    "   old-style NumPy arrays with dtype=object. Setting this flag to\n",
    "   False replicates the behavior of scipy version 0.7.x (returning\n",
    "   NumPy object arrays). The default setting is True, because it\n",
    "   allows easier round-trip load and save of MATLAB files.\n",
    "verify_compressed_data_integrity : bool, optional\n",
    "    Whether the length of compressed sequences in the MATLAB file\n",
    "    should be checked, to ensure that they are not longer than we expect.\n",
    "    It is advisable to enable this (the default) because overlong\n",
    "    compressed sequences in MATLAB files generally indicate that the\n",
    "    files have experienced some sort of corruption.\n",
    "variable_names : None or sequence\n",
    "    If None (the default) - read all variables in file. Otherwise,\n",
    "    `variable_names` should be a sequence of strings, giving names of the\n",
    "    MATLAB variables to read from the file. The reader will skip any\n",
    "    variable with a name not in this sequence, possibly saving some read\n",
    "    processing.\n",
    "simplify_cells : False, optional\n",
    "    If True, return a simplified dict structure (which is useful if the mat\n",
    "    file contains cell arrays). Note that this only affects the structure\n",
    "    of the result and not its contents (which is identical for both output\n",
    "    structures). If True, this automatically sets `struct_as_record` to\n",
    "    False and `squeeze_me` to True, which is required to simplify cells.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "mat_dict : dict\n",
    "   dictionary with variable names as keys, and loaded matrices as\n",
    "   values.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "v4 (Level 1.0), v6 and v7 to 7.2 matfiles are supported.\n",
    "\n",
    "You will need an HDF5 Python library to read MATLAB 7.3 format mat\n",
    "files. Because SciPy does not supply one, we do not implement the\n",
    "HDF5 / 7.3 interface here.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from os.path import dirname, join as pjoin\n",
    ">>> import scipy.io as sio\n",
    "\n",
    "Get the filename for an example .mat file from the tests/data directory.\n",
    "\n",
    ">>> data_dir = pjoin(dirname(sio.__file__), 'matlab', 'tests', 'data')\n",
    ">>> mat_fname = pjoin(data_dir, 'testdouble_7.4_GLNX86.mat')\n",
    "\n",
    "Load the .mat file contents.\n",
    "\n",
    ">>> mat_contents = sio.loadmat(mat_fname)\n",
    "\n",
    "The result is a dictionary, one key/value pair for each variable:\n",
    "\n",
    ">>> sorted(mat_contents.keys())\n",
    "['__globals__', '__header__', '__version__', 'testdouble']\n",
    ">>> mat_contents['testdouble']\n",
    "array([[0.        , 0.78539816, 1.57079633, 2.35619449, 3.14159265,\n",
    "        3.92699082, 4.71238898, 5.49778714, 6.28318531]])\n",
    "\n",
    "By default SciPy reads MATLAB structs as structured NumPy arrays where the\n",
    "dtype fields are of type `object` and the names correspond to the MATLAB\n",
    "struct field names. This can be disabled by setting the optional argument\n",
    "`struct_as_record=False`.\n",
    "\n",
    "Get the filename for an example .mat file that contains a MATLAB struct\n",
    "called `teststruct` and load the contents.\n",
    "\n",
    ">>> matstruct_fname = pjoin(data_dir, 'teststruct_7.4_GLNX86.mat')\n",
    ">>> matstruct_contents = sio.loadmat(matstruct_fname)\n",
    ">>> teststruct = matstruct_contents['teststruct']\n",
    ">>> teststruct.dtype\n",
    "dtype([('stringfield', 'O'), ('doublefield', 'O'), ('complexfield', 'O')])\n",
    "\n",
    "The size of the structured array is the size of the MATLAB struct, not the\n",
    "number of elements in any particular field. The shape defaults to 2-D\n",
    "unless the optional argument `squeeze_me=True`, in which case all length 1\n",
    "dimensions are removed.\n",
    "\n",
    ">>> teststruct.size\n",
    "1\n",
    ">>> teststruct.shape\n",
    "(1, 1)\n",
    "\n",
    "Get the 'stringfield' of the first element in the MATLAB struct.\n",
    "\n",
    ">>> teststruct[0, 0]['stringfield']\n",
    "array(['Rats live on no evil star.'],\n",
    "  dtype='<U26')\n",
    "\n",
    "Get the first element of the 'doublefield'.\n",
    "\n",
    ">>> teststruct['doublefield'][0, 0]\n",
    "array([[ 1.41421356,  2.71828183,  3.14159265]])\n",
    "\n",
    "Load the MATLAB struct, squeezing out length 1 dimensions, and get the item\n",
    "from the 'complexfield'.\n",
    "\n",
    ">>> matstruct_squeezed = sio.loadmat(matstruct_fname, squeeze_me=True)\n",
    ">>> matstruct_squeezed['teststruct'].shape\n",
    "()\n",
    ">>> matstruct_squeezed['teststruct']['complexfield'].shape\n",
    "()\n",
    ">>> matstruct_squeezed['teststruct']['complexfield'].item()\n",
    "array([ 1.41421356+1.41421356j,  2.71828183+2.71828183j,\n",
    "    3.14159265+3.14159265j])\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd17a49",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>1. Library Loading</h3>  <a id='1'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from scipy import io as sio\n",
    "from scipy import cluster as scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2a963",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "stack_path = '/data1/subtypes/serial_preps/netstack_dmn_rmap_part_site_279_sample_scale_007.npy'\n",
    "mask_path = '/data1/abide/Mask/mask_data_specific.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4c7c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>3. Data Preparation</h3>  <a id='3'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.lib.npyio.load</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n",
    "\n",
    ".. warning:: Loading files that contain object arrays uses the ``pickle``\n",
    "             module, which is not secure against erroneous or maliciously\n",
    "             constructed data. Consider passing ``allow_pickle=False`` to\n",
    "             load data that is known not to contain object arrays for the\n",
    "             safer handling of untrusted sources.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "file : file-like object, string, or pathlib.Path\n",
    "    The file to read. File-like objects must support the\n",
    "    ``seek()`` and ``read()`` methods and must always\n",
    "    be opened in binary mode.  Pickled files require that the\n",
    "    file-like object support the ``readline()`` method as well.\n",
    "mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n",
    "    If not None, then memory-map the file, using the given mode (see\n",
    "    `numpy.memmap` for a detailed description of the modes).  A\n",
    "    memory-mapped array is kept on disk. However, it can be accessed\n",
    "    and sliced like any ndarray.  Memory mapping is especially useful\n",
    "    for accessing small fragments of large files without reading the\n",
    "    entire file into memory.\n",
    "allow_pickle : bool, optional\n",
    "    Allow loading pickled object arrays stored in npy files. Reasons for\n",
    "    disallowing pickles include security, as loading pickled data can\n",
    "    execute arbitrary code. If pickles are disallowed, loading object\n",
    "    arrays will fail. Default: False\n",
    "\n",
    "    .. versionchanged:: 1.16.3\n",
    "        Made default False in response to CVE-2019-6446.\n",
    "\n",
    "fix_imports : bool, optional\n",
    "    Only useful when loading Python 2 generated pickled files on Python 3,\n",
    "    which includes npy/npz files containing object arrays. If `fix_imports`\n",
    "    is True, pickle will try to map the old Python 2 names to the new names\n",
    "    used in Python 3.\n",
    "encoding : str, optional\n",
    "    What encoding to use when reading Python 2 strings. Only useful when\n",
    "    loading Python 2 generated pickled files in Python 3, which includes\n",
    "    npy/npz files containing object arrays. Values other than 'latin1',\n",
    "    'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n",
    "    data. Default: 'ASCII'\n",
    "max_header_size : int, optional\n",
    "    Maximum allowed size of the header.  Large headers may not be safe\n",
    "    to load securely and thus require explicitly passing a larger value.\n",
    "    See :py:meth:`ast.literal_eval()` for details.\n",
    "    This option is ignored when `allow_pickle` is passed.  In that case\n",
    "    the file is by definition trusted and the limit is unnecessary.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "result : array, tuple, dict, etc.\n",
    "    Data stored in the file. For ``.npz`` files, the returned instance\n",
    "    of NpzFile class must be closed to avoid leaking file descriptors.\n",
    "\n",
    "Raises\n",
    "------\n",
    "OSError\n",
    "    If the input file does not exist or cannot be read.\n",
    "UnpicklingError\n",
    "    If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n",
    "ValueError\n",
    "    The file contains an object array, but ``allow_pickle=False`` given.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "save, savez, savez_compressed, loadtxt\n",
    "memmap : Create a memory-map to an array stored in a file on disk.\n",
    "lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- If the file contains pickle data, then whatever object is stored\n",
    "  in the pickle is returned.\n",
    "- If the file is a ``.npy`` file, then a single array is returned.\n",
    "- If the file is a ``.npz`` file, then a dictionary-like object is\n",
    "  returned, containing ``{filename: array}`` key-value pairs, one for\n",
    "  each file in the archive.\n",
    "- If the file is a ``.npz`` file, the returned value supports the\n",
    "  context manager protocol in a similar fashion to the open function::\n",
    "\n",
    "    with load('foo.npz') as data:\n",
    "        a = data['a']\n",
    "\n",
    "  The underlying file descriptor is closed when exiting the 'with'\n",
    "  block.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Store data to disk, and load it again:\n",
    "\n",
    ">>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
    ">>> np.load('/tmp/123.npy')\n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6]])\n",
    "\n",
    "Store compressed data to disk, and load it again:\n",
    "\n",
    ">>> a=np.array([[1, 2, 3], [4, 5, 6]])\n",
    ">>> b=np.array([1, 2])\n",
    ">>> np.savez('/tmp/123.npz', a=a, b=b)\n",
    ">>> data = np.load('/tmp/123.npz')\n",
    ">>> data['a']\n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6]])\n",
    ">>> data['b']\n",
    "array([1, 2])\n",
    ">>> data.close()\n",
    "\n",
    "Mem-map the stored array, and then access the second row\n",
    "directly from disk:\n",
    "\n",
    ">>> X = np.load('/tmp/123.npy', mmap_mode='r')\n",
    ">>> X[1, :]\n",
    "memmap([4, 5, 6])\n",
    "\n",
    "</code>\n",
    "<a href='#3'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca3bac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "m_img = nib.load(mask_path)\n",
    "mask = m_img.get_data().astype(bool)\n",
    "stack = np.load(stack_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feced58b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>4. Data Preparation</h3>  <a id='4'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788e0ac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9ad64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>5. Data Preparation</h3>  <a id='5'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core.numeric.zeros_like</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return an array of zeros with the same shape and type as a given array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : array_like\n",
    "    The shape and data-type of `a` define these same attributes of\n",
    "    the returned array.\n",
    "dtype : data-type, optional\n",
    "    Overrides the data type of the result.\n",
    "\n",
    "    .. versionadded:: 1.6.0\n",
    "order : {'C', 'F', 'A', or 'K'}, optional\n",
    "    Overrides the memory layout of the result. 'C' means C-order,\n",
    "    'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
    "    'C' otherwise. 'K' means match the layout of `a` as closely\n",
    "    as possible.\n",
    "\n",
    "    .. versionadded:: 1.6.0\n",
    "subok : bool, optional.\n",
    "    If True, then the newly created array will use the sub-class\n",
    "    type of `a`, otherwise it will be a base-class array. Defaults\n",
    "    to True.\n",
    "shape : int or sequence of ints, optional.\n",
    "    Overrides the shape of the result. If order='K' and the number of\n",
    "    dimensions is unchanged, will try to keep order, otherwise,\n",
    "    order='C' is implied.\n",
    "\n",
    "    .. versionadded:: 1.17.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    Array of zeros with the same shape and type as `a`.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "empty_like : Return an empty array with shape and type of input.\n",
    "ones_like : Return an array of ones with shape and type of input.\n",
    "full_like : Return a new array with shape of input filled with value.\n",
    "zeros : Return a new array setting values to zero.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> x = np.arange(6)\n",
    ">>> x = x.reshape((2, 3))\n",
    ">>> x\n",
    "array([[0, 1, 2],\n",
    "       [3, 4, 5]])\n",
    ">>> np.zeros_like(x)\n",
    "array([[0, 0, 0],\n",
    "       [0, 0, 0]])\n",
    "\n",
    ">>> y = np.arange(3, dtype=float)\n",
    ">>> y\n",
    "array([0., 1., 2.])\n",
    ">>> np.zeros_like(y)\n",
    "array([0.,  0.,  0.])\n",
    "\n",
    "</code>\n",
    "<a href='#5'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/data1/abide/legacy_test/mean_centered_old1.nii.gz'\n",
    "old_1 = np.zeros_like(mask, dtype=float)\n",
    "old_1[mask] = stack[0,:,0]\n",
    "\n",
    "old_img = nib.Nifti1Image(old_1, header=m_img.get_header(), affine=m_img.get_affine())\n",
    "nib.save(old_img, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade701cd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Look at similar data\n",
    "comp_data = '/data1/abide/legacy_test/data/test_sub.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812775b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>7. Data Preparation</h3>  <a id='7'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.io.parsers.readers.read_csv</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Read a comma-separated values (csv) file into DataFrame.\n",
    "\n",
    "Also supports optionally iterating or breaking of the file\n",
    "into chunks.\n",
    "\n",
    "Additional help can be found in the online docs for\n",
    "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "filepath_or_buffer : str, path object or file-like object\n",
    "    Any valid string path is acceptable. The string could be a URL. Valid\n",
    "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
    "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
    "\n",
    "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
    "\n",
    "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
    "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
    "sep : str, default ','\n",
    "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
    "    the separator, but the Python parsing engine can, meaning the latter will\n",
    "    be used and automatically detect the separator by Python's builtin sniffer\n",
    "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
    "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
    "    will also force the use of the Python parsing engine. Note that regex\n",
    "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
    "delimiter : str, default ``None``\n",
    "    Alias for sep.\n",
    "header : int, list of int, None, default 'infer'\n",
    "    Row number(s) to use as the column names, and the start of the\n",
    "    data.  Default behavior is to infer the column names: if no names\n",
    "    are passed the behavior is identical to ``header=0`` and column\n",
    "    names are inferred from the first line of the file, if column\n",
    "    names are passed explicitly then the behavior is identical to\n",
    "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
    "    replace existing names. The header can be a list of integers that\n",
    "    specify row locations for a multi-index on the columns\n",
    "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
    "    skipped (e.g. 2 in this example is skipped). Note that this\n",
    "    parameter ignores commented lines and empty lines if\n",
    "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
    "    data rather than the first line of the file.\n",
    "names : array-like, optional\n",
    "    List of column names to use. If the file contains a header row,\n",
    "    then you should explicitly pass ``header=0`` to override the column names.\n",
    "    Duplicates in this list are not allowed.\n",
    "index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
    "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
    "  string name or column index. If a sequence of int / str is given, a\n",
    "  MultiIndex is used.\n",
    "\n",
    "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
    "  column as the index, e.g. when you have a malformed file with delimiters at\n",
    "  the end of each line.\n",
    "usecols : list-like or callable, optional\n",
    "    Return a subset of the columns. If list-like, all elements must either\n",
    "    be positional (i.e. integer indices into the document columns) or strings\n",
    "    that correspond to column names provided either by the user in `names` or\n",
    "    inferred from the document header row(s). If ``names`` are given, the document\n",
    "    header row(s) are not taken into account. For example, a valid list-like\n",
    "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
    "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
    "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
    "    in ``['foo', 'bar']`` order or\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
    "    for ``['bar', 'foo']`` order.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the column\n",
    "    names, returning names where the callable function evaluates to True. An\n",
    "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
    "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
    "    parsing time and lower memory usage.\n",
    "squeeze : bool, default False\n",
    "    If the parsed data only contains one column then return a Series.\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "        Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
    "        the data.\n",
    "prefix : str, optional\n",
    "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "       Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
    "mangle_dupe_cols : bool, default True\n",
    "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
    "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
    "    are duplicate names in the columns.\n",
    "dtype : Type name or dict of column -> type, optional\n",
    "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
    "    'c': 'Int64'}\n",
    "    Use `str` or `object` together with suitable `na_values` settings\n",
    "    to preserve and not interpret dtype.\n",
    "    If converters are specified, they will be applied INSTEAD\n",
    "    of dtype conversion.\n",
    "engine : {'c', 'python', 'pyarrow'}, optional\n",
    "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
    "    is currently more feature-complete. Multithreading is currently only supported by\n",
    "    the pyarrow engine.\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "        The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
    "        are unsupported, or may not work correctly, with this engine.\n",
    "converters : dict, optional\n",
    "    Dict of functions for converting values in certain columns. Keys can either\n",
    "    be integers or column labels.\n",
    "true_values : list, optional\n",
    "    Values to consider as True.\n",
    "false_values : list, optional\n",
    "    Values to consider as False.\n",
    "skipinitialspace : bool, default False\n",
    "    Skip spaces after delimiter.\n",
    "skiprows : list-like, int or callable, optional\n",
    "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
    "    at the start of the file.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the row\n",
    "    indices, returning True if the row should be skipped and False otherwise.\n",
    "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
    "skipfooter : int, default 0\n",
    "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
    "nrows : int, optional\n",
    "    Number of rows of file to read. Useful for reading pieces of large files.\n",
    "na_values : scalar, str, list-like, or dict, optional\n",
    "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
    "    per-column NA values.  By default the following values are interpreted as\n",
    "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
    "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
    "    'nan', 'null'.\n",
    "keep_default_na : bool, default True\n",
    "    Whether or not to include the default NaN values when parsing the data.\n",
    "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
    "\n",
    "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
    "      is appended to the default NaN values used for parsing.\n",
    "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
    "      the default NaN values are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
    "      the NaN values specified `na_values` are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
    "      strings will be parsed as NaN.\n",
    "\n",
    "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
    "    `na_values` parameters will be ignored.\n",
    "na_filter : bool, default True\n",
    "    Detect missing value markers (empty strings and the value of na_values). In\n",
    "    data without any NAs, passing na_filter=False can improve the performance\n",
    "    of reading a large file.\n",
    "verbose : bool, default False\n",
    "    Indicate number of NA values placed in non-numeric columns.\n",
    "skip_blank_lines : bool, default True\n",
    "    If True, skip over blank lines rather than interpreting as NaN values.\n",
    "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
    "    The behavior is as follows:\n",
    "\n",
    "    * boolean. If True -> try parsing the index.\n",
    "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
    "      each as a separate date column.\n",
    "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
    "      a single date column.\n",
    "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
    "      result 'foo'\n",
    "\n",
    "    If a column or index cannot be represented as an array of datetimes,\n",
    "    say because of an unparsable value or a mixture of timezones, the column\n",
    "    or index will be returned unaltered as an object data type. For\n",
    "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
    "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
    "    specify ``date_parser`` to be a partially-applied\n",
    "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
    "    :ref:`io.csv.mixed_timezones` for more.\n",
    "\n",
    "    Note: A fast-path exists for iso8601-formatted dates.\n",
    "infer_datetime_format : bool, default False\n",
    "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
    "    format of the datetime strings in the columns, and if it can be inferred,\n",
    "    switch to a faster method of parsing them. In some cases this can increase\n",
    "    the parsing speed by 5-10x.\n",
    "keep_date_col : bool, default False\n",
    "    If True and `parse_dates` specifies combining multiple columns then\n",
    "    keep the original columns.\n",
    "date_parser : function, optional\n",
    "    Function to use for converting a sequence of string columns to an array of\n",
    "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
    "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
    "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
    "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
    "    string values from the columns defined by `parse_dates` into a single array\n",
    "    and pass that; and 3) call `date_parser` once for each row using one or\n",
    "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
    "    arguments.\n",
    "dayfirst : bool, default False\n",
    "    DD/MM format dates, international and European format.\n",
    "cache_dates : bool, default True\n",
    "    If True, use a cache of unique, converted dates to apply the datetime\n",
    "    conversion. May produce significant speed-up when parsing duplicate\n",
    "    date strings, especially ones with timezone offsets.\n",
    "\n",
    "    .. versionadded:: 0.25.0\n",
    "iterator : bool, default False\n",
    "    Return TextFileReader object for iteration or getting chunks with\n",
    "    ``get_chunk()``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "chunksize : int, optional\n",
    "    Return TextFileReader object for iteration.\n",
    "    See the `IO Tools docs\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
    "    for more information on ``iterator`` and ``chunksize``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "compression : str or dict, default 'infer'\n",
    "    For on-the-fly decompression of on-disk data. If 'infer' and '%s' is\n",
    "    path-like, then detect compression from the following extensions: '.gz',\n",
    "    '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). If using\n",
    "    'zip', the ZIP file must contain only one data file to be read in. Set to\n",
    "    ``None`` for no decompression. Can also be a dict with key ``'method'`` set\n",
    "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
    "    key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
    "    ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
    "    example, the following could be passed for Zstandard decompression using a\n",
    "    custom compression dictionary:\n",
    "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
    "\n",
    "    .. versionchanged:: 1.4.0 Zstandard support.\n",
    "\n",
    "thousands : str, optional\n",
    "    Thousands separator.\n",
    "decimal : str, default '.'\n",
    "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
    "lineterminator : str (length 1), optional\n",
    "    Character to break file into lines. Only valid with C parser.\n",
    "quotechar : str (length 1), optional\n",
    "    The character used to denote the start and end of a quoted item. Quoted\n",
    "    items can include the delimiter and it will be ignored.\n",
    "quoting : int or csv.QUOTE_* instance, default 0\n",
    "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
    "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "doublequote : bool, default ``True``\n",
    "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
    "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
    "   field as a single ``quotechar`` element.\n",
    "escapechar : str (length 1), optional\n",
    "    One-character string used to escape other characters.\n",
    "comment : str, optional\n",
    "    Indicates remainder of line should not be parsed. If found at the beginning\n",
    "    of a line, the line will be ignored altogether. This parameter must be a\n",
    "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
    "    fully commented lines are ignored by the parameter `header` but not by\n",
    "    `skiprows`. For example, if ``comment='#'``, parsing\n",
    "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
    "    treated as the header.\n",
    "encoding : str, optional\n",
    "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
    "    standard encodings\n",
    "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
    "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
    "       This behavior was previously only the case for ``engine=\"python\"``.\n",
    "\n",
    "    .. versionchanged:: 1.3.0\n",
    "\n",
    "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
    "       influence on how encoding errors are handled.\n",
    "\n",
    "encoding_errors : str, optional, default \"strict\"\n",
    "    How encoding errors are treated. `List of possible values\n",
    "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "dialect : str or csv.Dialect, optional\n",
    "    If provided, this parameter will override values (default or not) for the\n",
    "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
    "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
    "    override values, a ParserWarning will be issued. See csv.Dialect\n",
    "    documentation for more details.\n",
    "error_bad_lines : bool, optional, default ``None``\n",
    "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
    "    default cause an exception to be raised, and no DataFrame will be returned.\n",
    "    If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
    "    returned.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "warn_bad_lines : bool, optional, default ``None``\n",
    "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
    "    \"bad line\" will be output.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
    "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
    "    Allowed values are :\n",
    "\n",
    "        - 'error', raise an Exception when a bad line is encountered.\n",
    "        - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
    "        - 'skip', skip bad lines without raising or warning when they are encountered.\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "        - callable, function with signature\n",
    "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
    "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
    "          If the function returns ``None``, the bad line will be ignored.\n",
    "          If the function returns a new list of strings with more elements than\n",
    "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
    "          Only supported when ``engine=\"python\"``\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "delim_whitespace : bool, default False\n",
    "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
    "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
    "    is set to True, nothing should be passed in for the ``delimiter``\n",
    "    parameter.\n",
    "low_memory : bool, default True\n",
    "    Internally process the file in chunks, resulting in lower memory use\n",
    "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
    "    types either set False, or specify the type with the `dtype` parameter.\n",
    "    Note that the entire file is read into a single DataFrame regardless,\n",
    "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
    "    (Only valid with C parser).\n",
    "memory_map : bool, default False\n",
    "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
    "    directly onto memory and access the data directly from there. Using this\n",
    "    option can improve performance because there is no longer any I/O overhead.\n",
    "float_precision : str, optional\n",
    "    Specifies which converter the C engine should use for floating-point\n",
    "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
    "    'legacy' for the original lower precision pandas converter, and\n",
    "    'round_trip' for the round-trip converter.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "storage_options : dict, optional\n",
    "    Extra options that make sense for a particular storage connection, e.g.\n",
    "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
    "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
    "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
    "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
    "\n",
    "    .. versionadded:: 1.2\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame or TextParser\n",
    "    A comma-separated values (csv) file is returned as two-dimensional\n",
    "    data structure with labeled axes.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
    "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
    "\n",
    "</code>\n",
    "<a href='#7'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40dad6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "comp = pd.read_csv(comp_data, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d4abc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>8. Data Preparation</h3>  <a id='8'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "One-dimensional ndarray with axis labels (including time series).\n",
    "\n",
    "Labels need not be unique but must be a hashable type. The object\n",
    "supports both integer- and label-based indexing and provides a host of\n",
    "methods for performing operations involving the index. Statistical\n",
    "methods from ndarray have been overridden to automatically exclude\n",
    "missing data (currently represented as NaN).\n",
    "\n",
    "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
    "associated index values-- they need not be the same length. The result\n",
    "index will be the sorted union of the two indexes.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : array-like, Iterable, dict, or scalar value\n",
    "    Contains data stored in Series. If data is a dict, argument order is\n",
    "    maintained.\n",
    "index : array-like or Index (1d)\n",
    "    Values must be hashable and have the same length as `data`.\n",
    "    Non-unique index values are allowed. Will default to\n",
    "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
    "    and index is None, then the keys in the data are used as the index. If the\n",
    "    index is not None, the resulting Series is reindexed with the index values.\n",
    "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
    "    Data type for the output Series. If not specified, this will be\n",
    "    inferred from `data`.\n",
    "    See the :ref:`user guide <basics.dtypes>` for more usages.\n",
    "name : str, optional\n",
    "    The name to give to the Series.\n",
    "copy : bool, default False\n",
    "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Constructing Series from a dictionary with an Index specified\n",
    "\n",
    ">>> d = {'a': 1, 'b': 2, 'c': 3}\n",
    ">>> ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
    ">>> ser\n",
    "a   1\n",
    "b   2\n",
    "c   3\n",
    "dtype: int64\n",
    "\n",
    "The keys of the dictionary match with the Index values, hence the Index\n",
    "values have no effect.\n",
    "\n",
    ">>> d = {'a': 1, 'b': 2, 'c': 3}\n",
    ">>> ser = pd.Series(data=d, index=['x', 'y', 'z'])\n",
    ">>> ser\n",
    "x   NaN\n",
    "y   NaN\n",
    "z   NaN\n",
    "dtype: float64\n",
    "\n",
    "Note that the Index is first build with the keys from the dictionary.\n",
    "After this the Series is reindexed with the given Index values, hence we\n",
    "get all NaN as a result.\n",
    "\n",
    "Constructing Series from a list with `copy=False`.\n",
    "\n",
    ">>> r = [1, 2]\n",
    ">>> ser = pd.Series(r, copy=False)\n",
    ">>> ser.iloc[0] = 999\n",
    ">>> r\n",
    "[1, 2]\n",
    ">>> ser\n",
    "0    999\n",
    "1      2\n",
    "dtype: int64\n",
    "\n",
    "Due to input data type the Series has a `copy` of\n",
    "the original data even though `copy=False`, so\n",
    "the data is unchanged.\n",
    "\n",
    "Constructing Series from a 1d ndarray with `copy=False`.\n",
    "\n",
    ">>> r = np.array([1, 2])\n",
    ">>> ser = pd.Series(r, copy=False)\n",
    ">>> ser.iloc[0] = 999\n",
    ">>> r\n",
    "array([999,   2])\n",
    ">>> ser\n",
    "0    999\n",
    "1      2\n",
    "dtype: int64\n",
    "\n",
    "Due to input data type the Series has a `view` on\n",
    "the original data, so\n",
    "the data is changed as well.\n",
    "\n",
    "</code>\n",
    "<a href='#8'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78a1f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cp = comp.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6208d56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>9. Data Preparation</h3>  <a id='9'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8efce7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cp[0,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f432e1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>11. Data Preparation</h3>  <a id='11'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.lib.function_base.corrcoef</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return Pearson product-moment correlation coefficients.\n",
    "\n",
    "Please refer to the documentation for `cov` for more detail.  The\n",
    "relationship between the correlation coefficient matrix, `R`, and the\n",
    "covariance matrix, `C`, is\n",
    "\n",
    ".. math:: R_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} C_{jj} } }\n",
    "\n",
    "The values of `R` are between -1 and 1, inclusive.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x : array_like\n",
    "    A 1-D or 2-D array containing multiple variables and observations.\n",
    "    Each row of `x` represents a variable, and each column a single\n",
    "    observation of all those variables. Also see `rowvar` below.\n",
    "y : array_like, optional\n",
    "    An additional set of variables and observations. `y` has the same\n",
    "    shape as `x`.\n",
    "rowvar : bool, optional\n",
    "    If `rowvar` is True (default), then each row represents a\n",
    "    variable, with observations in the columns. Otherwise, the relationship\n",
    "    is transposed: each column represents a variable, while the rows\n",
    "    contain observations.\n",
    "bias : _NoValue, optional\n",
    "    Has no effect, do not use.\n",
    "\n",
    "    .. deprecated:: 1.10.0\n",
    "ddof : _NoValue, optional\n",
    "    Has no effect, do not use.\n",
    "\n",
    "    .. deprecated:: 1.10.0\n",
    "dtype : data-type, optional\n",
    "    Data-type of the result. By default, the return data-type will have\n",
    "    at least `numpy.float64` precision.\n",
    "\n",
    "    .. versionadded:: 1.20\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : ndarray\n",
    "    The correlation coefficient matrix of the variables.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "cov : Covariance matrix\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Due to floating point rounding the resulting array may not be Hermitian,\n",
    "the diagonal elements may not be 1, and the elements may not satisfy the\n",
    "inequality abs(a) <= 1. The real and imaginary parts are clipped to the\n",
    "interval [-1,  1] in an attempt to improve on that situation but is not\n",
    "much help in the complex case.\n",
    "\n",
    "This function accepts but discards arguments `bias` and `ddof`.  This is\n",
    "for backwards compatibility with previous versions of this function.  These\n",
    "arguments had no effect on the return values of the function and can be\n",
    "safely ignored in this and previous versions of numpy.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "In this example we generate two random arrays, ``xarr`` and ``yarr``, and\n",
    "compute the row-wise and column-wise Pearson correlation coefficients,\n",
    "``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\n",
    "Pearson correlation coefficients between the variables of ``xarr``.\n",
    "\n",
    ">>> import numpy as np\n",
    ">>> rng = np.random.default_rng(seed=42)\n",
    ">>> xarr = rng.random((3, 3))\n",
    ">>> xarr\n",
    "array([[0.77395605, 0.43887844, 0.85859792],\n",
    "       [0.69736803, 0.09417735, 0.97562235],\n",
    "       [0.7611397 , 0.78606431, 0.12811363]])\n",
    ">>> R1 = np.corrcoef(xarr)\n",
    ">>> R1\n",
    "array([[ 1.        ,  0.99256089, -0.68080986],\n",
    "       [ 0.99256089,  1.        , -0.76492172],\n",
    "       [-0.68080986, -0.76492172,  1.        ]])\n",
    "\n",
    "If we add another set of variables and observations ``yarr``, we can\n",
    "compute the row-wise Pearson correlation coefficients between the\n",
    "variables in ``xarr`` and ``yarr``.\n",
    "\n",
    ">>> yarr = rng.random((3, 3))\n",
    ">>> yarr\n",
    "array([[0.45038594, 0.37079802, 0.92676499],\n",
    "       [0.64386512, 0.82276161, 0.4434142 ],\n",
    "       [0.22723872, 0.55458479, 0.06381726]])\n",
    ">>> R2 = np.corrcoef(xarr, yarr)\n",
    ">>> R2\n",
    "array([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n",
    "        -0.99004057],\n",
    "       [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n",
    "        -0.99981569],\n",
    "       [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n",
    "         0.77714685],\n",
    "       [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n",
    "        -0.83571711],\n",
    "       [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n",
    "         0.97517215],\n",
    "       [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n",
    "         1.        ]])\n",
    "\n",
    "Finally if we use the option ``rowvar=False``, the columns are now\n",
    "being treated as the variables and we will find the column-wise Pearson\n",
    "correlation coefficients between variables in ``xarr`` and ``yarr``.\n",
    "\n",
    ">>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n",
    ">>> R3\n",
    "array([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n",
    "         0.22423734],\n",
    "       [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n",
    "        -0.44069024],\n",
    "       [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n",
    "         0.75137473],\n",
    "       [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n",
    "         0.47536961],\n",
    "       [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n",
    "        -0.46666491],\n",
    "       [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n",
    "         1.        ]])\n",
    "\n",
    "</code>\n",
    "<a href='#11'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12d679",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "a = np.corrcoef(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c2430",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>12. Data Preparation</h3>  <a id='12'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036258c5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b0267",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>14. Data Preparation</h3>  <a id='14'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.io.matlab._mio.loadmat</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Load MATLAB file.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "file_name : str\n",
    "   Name of the mat file (do not need .mat extension if\n",
    "   appendmat==True). Can also pass open file-like object.\n",
    "mdict : dict, optional\n",
    "    Dictionary in which to insert matfile variables.\n",
    "appendmat : bool, optional\n",
    "   True to append the .mat extension to the end of the given\n",
    "   filename, if not already present. Default is True.\n",
    "byte_order : str or None, optional\n",
    "   None by default, implying byte order guessed from mat\n",
    "   file. Otherwise can be one of ('native', '=', 'little', '<',\n",
    "   'BIG', '>').\n",
    "mat_dtype : bool, optional\n",
    "   If True, return arrays in same dtype as would be loaded into\n",
    "   MATLAB (instead of the dtype with which they are saved).\n",
    "squeeze_me : bool, optional\n",
    "   Whether to squeeze unit matrix dimensions or not.\n",
    "chars_as_strings : bool, optional\n",
    "   Whether to convert char arrays to string arrays.\n",
    "matlab_compatible : bool, optional\n",
    "   Returns matrices as would be loaded by MATLAB (implies\n",
    "   squeeze_me=False, chars_as_strings=False, mat_dtype=True,\n",
    "   struct_as_record=True).\n",
    "struct_as_record : bool, optional\n",
    "   Whether to load MATLAB structs as NumPy record arrays, or as\n",
    "   old-style NumPy arrays with dtype=object. Setting this flag to\n",
    "   False replicates the behavior of scipy version 0.7.x (returning\n",
    "   NumPy object arrays). The default setting is True, because it\n",
    "   allows easier round-trip load and save of MATLAB files.\n",
    "verify_compressed_data_integrity : bool, optional\n",
    "    Whether the length of compressed sequences in the MATLAB file\n",
    "    should be checked, to ensure that they are not longer than we expect.\n",
    "    It is advisable to enable this (the default) because overlong\n",
    "    compressed sequences in MATLAB files generally indicate that the\n",
    "    files have experienced some sort of corruption.\n",
    "variable_names : None or sequence\n",
    "    If None (the default) - read all variables in file. Otherwise,\n",
    "    `variable_names` should be a sequence of strings, giving names of the\n",
    "    MATLAB variables to read from the file. The reader will skip any\n",
    "    variable with a name not in this sequence, possibly saving some read\n",
    "    processing.\n",
    "simplify_cells : False, optional\n",
    "    If True, return a simplified dict structure (which is useful if the mat\n",
    "    file contains cell arrays). Note that this only affects the structure\n",
    "    of the result and not its contents (which is identical for both output\n",
    "    structures). If True, this automatically sets `struct_as_record` to\n",
    "    False and `squeeze_me` to True, which is required to simplify cells.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "mat_dict : dict\n",
    "   dictionary with variable names as keys, and loaded matrices as\n",
    "   values.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "v4 (Level 1.0), v6 and v7 to 7.2 matfiles are supported.\n",
    "\n",
    "You will need an HDF5 Python library to read MATLAB 7.3 format mat\n",
    "files. Because SciPy does not supply one, we do not implement the\n",
    "HDF5 / 7.3 interface here.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from os.path import dirname, join as pjoin\n",
    ">>> import scipy.io as sio\n",
    "\n",
    "Get the filename for an example .mat file from the tests/data directory.\n",
    "\n",
    ">>> data_dir = pjoin(dirname(sio.__file__), 'matlab', 'tests', 'data')\n",
    ">>> mat_fname = pjoin(data_dir, 'testdouble_7.4_GLNX86.mat')\n",
    "\n",
    "Load the .mat file contents.\n",
    "\n",
    ">>> mat_contents = sio.loadmat(mat_fname)\n",
    "\n",
    "The result is a dictionary, one key/value pair for each variable:\n",
    "\n",
    ">>> sorted(mat_contents.keys())\n",
    "['__globals__', '__header__', '__version__', 'testdouble']\n",
    ">>> mat_contents['testdouble']\n",
    "array([[0.        , 0.78539816, 1.57079633, 2.35619449, 3.14159265,\n",
    "        3.92699082, 4.71238898, 5.49778714, 6.28318531]])\n",
    "\n",
    "By default SciPy reads MATLAB structs as structured NumPy arrays where the\n",
    "dtype fields are of type `object` and the names correspond to the MATLAB\n",
    "struct field names. This can be disabled by setting the optional argument\n",
    "`struct_as_record=False`.\n",
    "\n",
    "Get the filename for an example .mat file that contains a MATLAB struct\n",
    "called `teststruct` and load the contents.\n",
    "\n",
    ">>> matstruct_fname = pjoin(data_dir, 'teststruct_7.4_GLNX86.mat')\n",
    ">>> matstruct_contents = sio.loadmat(matstruct_fname)\n",
    ">>> teststruct = matstruct_contents['teststruct']\n",
    ">>> teststruct.dtype\n",
    "dtype([('stringfield', 'O'), ('doublefield', 'O'), ('complexfield', 'O')])\n",
    "\n",
    "The size of the structured array is the size of the MATLAB struct, not the\n",
    "number of elements in any particular field. The shape defaults to 2-D\n",
    "unless the optional argument `squeeze_me=True`, in which case all length 1\n",
    "dimensions are removed.\n",
    "\n",
    ">>> teststruct.size\n",
    "1\n",
    ">>> teststruct.shape\n",
    "(1, 1)\n",
    "\n",
    "Get the 'stringfield' of the first element in the MATLAB struct.\n",
    "\n",
    ">>> teststruct[0, 0]['stringfield']\n",
    "array(['Rats live on no evil star.'],\n",
    "  dtype='<U26')\n",
    "\n",
    "Get the first element of the 'doublefield'.\n",
    "\n",
    ">>> teststruct['doublefield'][0, 0]\n",
    "array([[ 1.41421356,  2.71828183,  3.14159265]])\n",
    "\n",
    "Load the MATLAB struct, squeezing out length 1 dimensions, and get the item\n",
    "from the 'complexfield'.\n",
    "\n",
    ">>> matstruct_squeezed = sio.loadmat(matstruct_fname, squeeze_me=True)\n",
    ">>> matstruct_squeezed['teststruct'].shape\n",
    "()\n",
    ">>> matstruct_squeezed['teststruct']['complexfield'].shape\n",
    "()\n",
    ">>> matstruct_squeezed['teststruct']['complexfield'].item()\n",
    "array([ 1.41421356+1.41421356j,  2.71828183+2.71828183j,\n",
    "    3.14159265+3.14159265j])\n",
    "\n",
    "</code>\n",
    "<a href='#14'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981031e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = sio.loadmat('/data1/abide/legacy_test/subtype/sc7/diag_mean_maybe/network_1/network_1_stack.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400b3d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cpt = cmat['stack']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a7ce0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>16. Data Preparation</h3>  <a id='16'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a08f89",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cpt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a1e43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>17. Data Preparation</h3>  <a id='17'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.lib.function_base.corrcoef</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return Pearson product-moment correlation coefficients.\n",
    "\n",
    "Please refer to the documentation for `cov` for more detail.  The\n",
    "relationship between the correlation coefficient matrix, `R`, and the\n",
    "covariance matrix, `C`, is\n",
    "\n",
    ".. math:: R_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} C_{jj} } }\n",
    "\n",
    "The values of `R` are between -1 and 1, inclusive.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x : array_like\n",
    "    A 1-D or 2-D array containing multiple variables and observations.\n",
    "    Each row of `x` represents a variable, and each column a single\n",
    "    observation of all those variables. Also see `rowvar` below.\n",
    "y : array_like, optional\n",
    "    An additional set of variables and observations. `y` has the same\n",
    "    shape as `x`.\n",
    "rowvar : bool, optional\n",
    "    If `rowvar` is True (default), then each row represents a\n",
    "    variable, with observations in the columns. Otherwise, the relationship\n",
    "    is transposed: each column represents a variable, while the rows\n",
    "    contain observations.\n",
    "bias : _NoValue, optional\n",
    "    Has no effect, do not use.\n",
    "\n",
    "    .. deprecated:: 1.10.0\n",
    "ddof : _NoValue, optional\n",
    "    Has no effect, do not use.\n",
    "\n",
    "    .. deprecated:: 1.10.0\n",
    "dtype : data-type, optional\n",
    "    Data-type of the result. By default, the return data-type will have\n",
    "    at least `numpy.float64` precision.\n",
    "\n",
    "    .. versionadded:: 1.20\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : ndarray\n",
    "    The correlation coefficient matrix of the variables.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "cov : Covariance matrix\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Due to floating point rounding the resulting array may not be Hermitian,\n",
    "the diagonal elements may not be 1, and the elements may not satisfy the\n",
    "inequality abs(a) <= 1. The real and imaginary parts are clipped to the\n",
    "interval [-1,  1] in an attempt to improve on that situation but is not\n",
    "much help in the complex case.\n",
    "\n",
    "This function accepts but discards arguments `bias` and `ddof`.  This is\n",
    "for backwards compatibility with previous versions of this function.  These\n",
    "arguments had no effect on the return values of the function and can be\n",
    "safely ignored in this and previous versions of numpy.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "In this example we generate two random arrays, ``xarr`` and ``yarr``, and\n",
    "compute the row-wise and column-wise Pearson correlation coefficients,\n",
    "``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\n",
    "Pearson correlation coefficients between the variables of ``xarr``.\n",
    "\n",
    ">>> import numpy as np\n",
    ">>> rng = np.random.default_rng(seed=42)\n",
    ">>> xarr = rng.random((3, 3))\n",
    ">>> xarr\n",
    "array([[0.77395605, 0.43887844, 0.85859792],\n",
    "       [0.69736803, 0.09417735, 0.97562235],\n",
    "       [0.7611397 , 0.78606431, 0.12811363]])\n",
    ">>> R1 = np.corrcoef(xarr)\n",
    ">>> R1\n",
    "array([[ 1.        ,  0.99256089, -0.68080986],\n",
    "       [ 0.99256089,  1.        , -0.76492172],\n",
    "       [-0.68080986, -0.76492172,  1.        ]])\n",
    "\n",
    "If we add another set of variables and observations ``yarr``, we can\n",
    "compute the row-wise Pearson correlation coefficients between the\n",
    "variables in ``xarr`` and ``yarr``.\n",
    "\n",
    ">>> yarr = rng.random((3, 3))\n",
    ">>> yarr\n",
    "array([[0.45038594, 0.37079802, 0.92676499],\n",
    "       [0.64386512, 0.82276161, 0.4434142 ],\n",
    "       [0.22723872, 0.55458479, 0.06381726]])\n",
    ">>> R2 = np.corrcoef(xarr, yarr)\n",
    ">>> R2\n",
    "array([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n",
    "        -0.99004057],\n",
    "       [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n",
    "        -0.99981569],\n",
    "       [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n",
    "         0.77714685],\n",
    "       [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n",
    "        -0.83571711],\n",
    "       [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n",
    "         0.97517215],\n",
    "       [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n",
    "         1.        ]])\n",
    "\n",
    "Finally if we use the option ``rowvar=False``, the columns are now\n",
    "being treated as the variables and we will find the column-wise Pearson\n",
    "correlation coefficients between variables in ``xarr`` and ``yarr``.\n",
    "\n",
    ">>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n",
    ">>> R3\n",
    "array([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n",
    "         0.22423734],\n",
    "       [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n",
    "        -0.44069024],\n",
    "       [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n",
    "         0.75137473],\n",
    "       [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n",
    "         0.47536961],\n",
    "       [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n",
    "        -0.46666491],\n",
    "       [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n",
    "         1.        ]])\n",
    "\n",
    "</code>\n",
    "<a href='#17'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46e854",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "R = np.corrcoef(cpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3157e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>18. Data Preparation</h3>  <a id='18'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0605d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "R[0,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea5030",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>20. Model Building and Training</h3>  <a id='20'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.linkage</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Perform hierarchical/agglomerative clustering.\n",
    "\n",
    "The input y may be either a 1-D condensed distance matrix\n",
    "or a 2-D array of observation vectors.\n",
    "\n",
    "If y is a 1-D condensed distance matrix,\n",
    "then y must be a :math:`\\binom{n}{2}` sized\n",
    "vector, where n is the number of original observations paired\n",
    "in the distance matrix. The behavior of this function is very\n",
    "similar to the MATLAB linkage function.\n",
    "\n",
    "A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
    ":math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
    "``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
    "cluster with an index less than :math:`n` corresponds to one of\n",
    "the :math:`n` original observations. The distance between\n",
    "clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
    "fourth value ``Z[i, 3]`` represents the number of original\n",
    "observations in the newly formed cluster.\n",
    "\n",
    "The following linkage methods are used to compute the distance\n",
    ":math:`d(s, t)` between two clusters :math:`s` and\n",
    ":math:`t`. The algorithm begins with a forest of clusters that\n",
    "have yet to be used in the hierarchy being formed. When two\n",
    "clusters :math:`s` and :math:`t` from this forest are combined\n",
    "into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
    "removed from the forest, and :math:`u` is added to the\n",
    "forest. When only one cluster remains in the forest, the algorithm\n",
    "stops, and this cluster becomes the root.\n",
    "\n",
    "A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
    "entry corresponds to the distance between cluster :math:`i` and\n",
    ":math:`j` in the original forest.\n",
    "\n",
    "At each iteration, the algorithm must update the distance matrix\n",
    "to reflect the distance of the newly formed cluster u with the\n",
    "remaining clusters in the forest.\n",
    "\n",
    "Suppose there are :math:`|u|` original observations\n",
    ":math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
    ":math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
    "cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n",
    "combined to form cluster :math:`u`. Let :math:`v` be any\n",
    "remaining cluster in the forest that is not :math:`u`.\n",
    "\n",
    "The following are methods for calculating the distance between the\n",
    "newly formed cluster :math:`u` and each :math:`v`.\n",
    "\n",
    "  * method='single' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\min(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster :math:`u` and\n",
    "    :math:`j` in cluster :math:`v`. This is also known as the\n",
    "    Nearest Point Algorithm.\n",
    "\n",
    "  * method='complete' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u, v) = \\max(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster u and :math:`j` in\n",
    "    cluster :math:`v`. This is also known by the Farthest Point\n",
    "    Algorithm or Voor Hees Algorithm.\n",
    "\n",
    "  * method='average' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
    "                               {(|u|*|v|)}\n",
    "\n",
    "    for all points :math:`i` and :math:`j` where :math:`|u|`\n",
    "    and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
    "    and :math:`v`, respectively. This is also called the UPGMA\n",
    "    algorithm.\n",
    "\n",
    "  * method='weighted' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = (dist(s,v) + dist(t,v))/2\n",
    "\n",
    "    where cluster u was formed with cluster s and t and v\n",
    "    is a remaining cluster in the forest (also called WPGMA).\n",
    "\n",
    "  * method='centroid' assigns\n",
    "\n",
    "    .. math::\n",
    "       dist(s,t) = ||c_s-c_t||_2\n",
    "\n",
    "    where :math:`c_s` and :math:`c_t` are the centroids of\n",
    "    clusters :math:`s` and :math:`t`, respectively. When two\n",
    "    clusters :math:`s` and :math:`t` are combined into a new\n",
    "    cluster :math:`u`, the new centroid is computed over all the\n",
    "    original objects in clusters :math:`s` and :math:`t`. The\n",
    "    distance then becomes the Euclidean distance between the\n",
    "    centroid of :math:`u` and the centroid of a remaining cluster\n",
    "    :math:`v` in the forest. This is also known as the UPGMC\n",
    "    algorithm.\n",
    "\n",
    "  * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
    "    method. When two clusters :math:`s` and :math:`t` are combined\n",
    "    into a new cluster :math:`u`, the average of centroids s and t\n",
    "    give the new centroid :math:`u`. This is also known as the\n",
    "    WPGMC algorithm.\n",
    "\n",
    "  * method='ward' uses the Ward variance minimization algorithm.\n",
    "    The new entry :math:`d(u,v)` is computed as follows,\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
    "                           {T}d(v,s)^2\n",
    "                    + \\frac{|v|+|t|}\n",
    "                           {T}d(v,t)^2\n",
    "                    - \\frac{|v|}\n",
    "                           {T}d(s,t)^2}\n",
    "\n",
    "    where :math:`u` is the newly joined cluster consisting of\n",
    "    clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
    "    cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
    "    :math:`|*|` is the cardinality of its argument. This is also\n",
    "    known as the incremental algorithm.\n",
    "\n",
    "Warning: When the minimum distance pair in the forest is chosen, there\n",
    "may be two or more pairs with the same minimum distance. This\n",
    "implementation may choose a different minimum than the MATLAB\n",
    "version.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "y : ndarray\n",
    "    A condensed distance matrix. A condensed distance matrix\n",
    "    is a flat array containing the upper triangular of the distance matrix.\n",
    "    This is the form that ``pdist`` returns. Alternatively, a collection of\n",
    "    :math:`m` observation vectors in :math:`n` dimensions may be passed as\n",
    "    an :math:`m` by :math:`n` array. All elements of the condensed distance\n",
    "    matrix must be finite, i.e., no NaNs or infs.\n",
    "method : str, optional\n",
    "    The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
    "    for full descriptions.\n",
    "metric : str or function, optional\n",
    "    The distance metric to use in the case that y is a collection of\n",
    "    observation vectors; ignored otherwise. See the ``pdist``\n",
    "    function for a list of valid distance metrics. A custom distance\n",
    "    function can also be used.\n",
    "optimal_ordering : bool, optional\n",
    "    If True, the linkage matrix will be reordered so that the distance\n",
    "    between successive leaves is minimal. This results in a more intuitive\n",
    "    tree structure when the data are visualized. defaults to False, because\n",
    "    this algorithm can be slow, particularly on large datasets [2]_. See\n",
    "    also the `optimal_leaf_ordering` function.\n",
    "\n",
    "    .. versionadded:: 1.0.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded as a linkage matrix.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "1. For method 'single', an optimized algorithm based on minimum spanning\n",
    "   tree is implemented. It has time complexity :math:`O(n^2)`.\n",
    "   For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n",
    "   called nearest-neighbors chain is implemented. It also has time\n",
    "   complexity :math:`O(n^2)`.\n",
    "   For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n",
    "   time complexity.\n",
    "   All algorithms use :math:`O(n^2)` memory.\n",
    "   Refer to [1]_ for details about the algorithms.\n",
    "2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n",
    "   Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
    "   pairwise distances, then it is the user's responsibility to assure that\n",
    "   these distances are in fact Euclidean, otherwise the produced result\n",
    "   will be incorrect.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "scipy.spatial.distance.pdist : pairwise distance metrics\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
    "       algorithms\", :arXiv:`1109.2378v1`.\n",
    ".. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n",
    "       leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n",
    "       :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import dendrogram, linkage\n",
    ">>> from matplotlib import pyplot as plt\n",
    ">>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "\n",
    ">>> Z = linkage(X, 'ward')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    "\n",
    ">>> Z = linkage(X, 'single')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#20'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc763d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "link_mat = scl.hierarchy.linkage(R , method='ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd37ed2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>21. Data Preparation | Visualization</h3>  <a id='21'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.dendrogram</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Plot the hierarchical clustering as a dendrogram.\n",
    "\n",
    "The dendrogram illustrates how each cluster is\n",
    "composed by drawing a U-shaped link between a non-singleton\n",
    "cluster and its children. The top of the U-link indicates a\n",
    "cluster merge. The two legs of the U-link indicate which clusters\n",
    "were merged. The length of the two legs of the U-link represents\n",
    "the distance between the child clusters. It is also the\n",
    "cophenetic distance between original observations in the two\n",
    "children clusters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The linkage matrix encoding the hierarchical clustering to\n",
    "    render as a dendrogram. See the ``linkage`` function for more\n",
    "    information on the format of ``Z``.\n",
    "p : int, optional\n",
    "    The ``p`` parameter for ``truncate_mode``.\n",
    "truncate_mode : str, optional\n",
    "    The dendrogram can be hard to read when the original\n",
    "    observation matrix from which the linkage is derived is\n",
    "    large. Truncation is used to condense the dendrogram. There\n",
    "    are several modes:\n",
    "\n",
    "    ``None``\n",
    "      No truncation is performed (default).\n",
    "      Note: ``'none'`` is an alias for ``None`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "    ``'lastp'``\n",
    "      The last ``p`` non-singleton clusters formed in the linkage are the\n",
    "      only non-leaf nodes in the linkage; they correspond to rows\n",
    "      ``Z[n-p-2:end]`` in ``Z``. All other non-singleton clusters are\n",
    "      contracted into leaf nodes.\n",
    "\n",
    "    ``'level'``\n",
    "      No more than ``p`` levels of the dendrogram tree are displayed.\n",
    "      A \"level\" includes all nodes with ``p`` merges from the final merge.\n",
    "\n",
    "      Note: ``'mtica'`` is an alias for ``'level'`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "color_threshold : double, optional\n",
    "    For brevity, let :math:`t` be the ``color_threshold``.\n",
    "    Colors all the descendent links below a cluster node\n",
    "    :math:`k` the same color if :math:`k` is the first node below\n",
    "    the cut threshold :math:`t`. All links connecting nodes with\n",
    "    distances greater than or equal to the threshold are colored\n",
    "    with de default matplotlib color ``'C0'``. If :math:`t` is less\n",
    "    than or equal to zero, all nodes are colored ``'C0'``.\n",
    "    If ``color_threshold`` is None or 'default',\n",
    "    corresponding with MATLAB(TM) behavior, the threshold is set to\n",
    "    ``0.7*max(Z[:,2])``.\n",
    "\n",
    "get_leaves : bool, optional\n",
    "    Includes a list ``R['leaves']=H`` in the result\n",
    "    dictionary. For each :math:`i`, ``H[i] == j``, cluster node\n",
    "    ``j`` appears in position ``i`` in the left-to-right traversal\n",
    "    of the leaves, where :math:`j < 2n-1` and :math:`i < n`.\n",
    "orientation : str, optional\n",
    "    The direction to plot the dendrogram, which can be any\n",
    "    of the following strings:\n",
    "\n",
    "    ``'top'``\n",
    "      Plots the root at the top, and plot descendent links going downwards.\n",
    "      (default).\n",
    "\n",
    "    ``'bottom'``\n",
    "      Plots the root at the bottom, and plot descendent links going\n",
    "      upwards.\n",
    "\n",
    "    ``'left'``\n",
    "      Plots the root at the left, and plot descendent links going right.\n",
    "\n",
    "    ``'right'``\n",
    "      Plots the root at the right, and plot descendent links going left.\n",
    "\n",
    "labels : ndarray, optional\n",
    "    By default, ``labels`` is None so the index of the original observation\n",
    "    is used to label the leaf nodes.  Otherwise, this is an :math:`n`-sized\n",
    "    sequence, with ``n == Z.shape[0] + 1``. The ``labels[i]`` value is the\n",
    "    text to put under the :math:`i` th leaf node only if it corresponds to\n",
    "    an original observation and not a non-singleton cluster.\n",
    "count_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    Note, ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "distance_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    Note ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "show_leaf_counts : bool, optional\n",
    "     When True, leaf nodes representing :math:`k>1` original\n",
    "     observation are labeled with the number of observations they\n",
    "     contain in parentheses.\n",
    "no_plot : bool, optional\n",
    "    When True, the final rendering is not performed. This is\n",
    "    useful if only the data structures computed for the rendering\n",
    "    are needed or if matplotlib is not available.\n",
    "no_labels : bool, optional\n",
    "    When True, no labels appear next to the leaf nodes in the\n",
    "    rendering of the dendrogram.\n",
    "leaf_rotation : double, optional\n",
    "    Specifies the angle (in degrees) to rotate the leaf\n",
    "    labels. When unspecified, the rotation is based on the number of\n",
    "    nodes in the dendrogram (default is 0).\n",
    "leaf_font_size : int, optional\n",
    "    Specifies the font size (in points) of the leaf labels. When\n",
    "    unspecified, the size based on the number of nodes in the\n",
    "    dendrogram.\n",
    "leaf_label_func : lambda or function, optional\n",
    "    When ``leaf_label_func`` is a callable function, for each\n",
    "    leaf with cluster index :math:`k < 2n-1`. The function\n",
    "    is expected to return a string with the label for the\n",
    "    leaf.\n",
    "\n",
    "    Indices :math:`k < n` correspond to original observations\n",
    "    while indices :math:`k \\geq n` correspond to non-singleton\n",
    "    clusters.\n",
    "\n",
    "    For example, to label singletons with their node id and\n",
    "    non-singletons with their id, count, and inconsistency\n",
    "    coefficient, simply do::\n",
    "\n",
    "        # First define the leaf label function.\n",
    "        def llf(id):\n",
    "            if id < n:\n",
    "                return str(id)\n",
    "            else:\n",
    "                return '[%d %d %1.2f]' % (id, count, R[n-id,3])\n",
    "\n",
    "        # The text for the leaf nodes is going to be big so force\n",
    "        # a rotation of 90 degrees.\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90)\n",
    "\n",
    "        # leaf_label_func can also be used together with ``truncate_mode`` parameter,\n",
    "        # in which case you will get your leaves labeled after truncation:\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90,\n",
    "                   truncate_mode='level', p=2)\n",
    "\n",
    "show_contracted : bool, optional\n",
    "    When True the heights of non-singleton nodes contracted\n",
    "    into a leaf node are plotted as crosses along the link\n",
    "    connecting that leaf node.  This really is only useful when\n",
    "    truncation is used (see ``truncate_mode`` parameter).\n",
    "link_color_func : callable, optional\n",
    "    If given, `link_color_function` is called with each non-singleton id\n",
    "    corresponding to each U-shaped link it will paint. The function is\n",
    "    expected to return the color to paint the link, encoded as a matplotlib\n",
    "    color string code. For example::\n",
    "\n",
    "        dendrogram(Z, link_color_func=lambda k: colors[k])\n",
    "\n",
    "    colors the direct links below each untruncated non-singleton node\n",
    "    ``k`` using ``colors[k]``.\n",
    "ax : matplotlib Axes instance, optional\n",
    "    If None and `no_plot` is not True, the dendrogram will be plotted\n",
    "    on the current axes.  Otherwise if `no_plot` is not True the\n",
    "    dendrogram will be plotted on the given ``Axes`` instance. This can be\n",
    "    useful if the dendrogram is part of a more complex figure.\n",
    "above_threshold_color : str, optional\n",
    "    This matplotlib color string sets the color of the links above the\n",
    "    color_threshold. The default is ``'C0'``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : dict\n",
    "    A dictionary of data structures computed to render the\n",
    "    dendrogram. Its has the following keys:\n",
    "\n",
    "    ``'color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th link.\n",
    "\n",
    "    ``'icoord'`` and ``'dcoord'``\n",
    "      Each of them is a list of lists. Let ``icoord = [I1, I2, ..., Ip]``\n",
    "      where ``Ik = [xk1, xk2, xk3, xk4]`` and ``dcoord = [D1, D2, ..., Dp]``\n",
    "      where ``Dk = [yk1, yk2, yk3, yk4]``, then the k'th link painted is\n",
    "      ``(xk1, yk1)`` - ``(xk2, yk2)`` - ``(xk3, yk3)`` - ``(xk4, yk4)``.\n",
    "\n",
    "    ``'ivl'``\n",
    "      A list of labels corresponding to the leaf nodes.\n",
    "\n",
    "    ``'leaves'``\n",
    "      For each i, ``H[i] == j``, cluster node ``j`` appears in position\n",
    "      ``i`` in the left-to-right traversal of the leaves, where\n",
    "      :math:`j < 2n-1` and :math:`i < n`. If ``j`` is less than ``n``, the\n",
    "      ``i``-th leaf node corresponds to an original observation.\n",
    "      Otherwise, it corresponds to a non-singleton cluster.\n",
    "\n",
    "    ``'leaves_color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th leaf.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage, set_link_color_palette\n",
    "\n",
    "Notes\n",
    "-----\n",
    "It is expected that the distances in ``Z[:,2]`` be monotonic, otherwise\n",
    "crossings appear in the dendrogram.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import numpy as np\n",
    ">>> from scipy.cluster import hierarchy\n",
    ">>> import matplotlib.pyplot as plt\n",
    "\n",
    "A very basic example:\n",
    "\n",
    ">>> ytdist = np.array([662., 877., 255., 412., 996., 295., 468., 268.,\n",
    "...                    400., 754., 564., 138., 219., 869., 669.])\n",
    ">>> Z = hierarchy.linkage(ytdist, 'single')\n",
    ">>> plt.figure()\n",
    ">>> dn = hierarchy.dendrogram(Z)\n",
    "\n",
    "Now, plot in given axes, improve the color scheme and use both vertical and\n",
    "horizontal orientations:\n",
    "\n",
    ">>> hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    ">>> fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    ">>> dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "...                            orientation='top')\n",
    ">>> dn2 = hierarchy.dendrogram(Z, ax=axes[1],\n",
    "...                            above_threshold_color='#bcbddc',\n",
    "...                            orientation='right')\n",
    ">>> hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#21'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.array</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
    "      like=None)\n",
    "\n",
    "Create an array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "object : array_like\n",
    "    An array, any object exposing the array interface, an object whose\n",
    "    __array__ method returns an array, or any (nested) sequence.\n",
    "    If object is a scalar, a 0-dimensional array containing object is\n",
    "    returned.\n",
    "dtype : data-type, optional\n",
    "    The desired data-type for the array.  If not given, then the type will\n",
    "    be determined as the minimum type required to hold the objects in the\n",
    "    sequence.\n",
    "copy : bool, optional\n",
    "    If true (default), then the object is copied.  Otherwise, a copy will\n",
    "    only be made if __array__ returns a copy, if obj is a nested sequence,\n",
    "    or if a copy is needed to satisfy any of the other requirements\n",
    "    (`dtype`, `order`, etc.).\n",
    "order : {'K', 'A', 'C', 'F'}, optional\n",
    "    Specify the memory layout of the array. If object is not an array, the\n",
    "    newly created array will be in C order (row major) unless 'F' is\n",
    "    specified, in which case it will be in Fortran order (column major).\n",
    "    If object is an array the following holds.\n",
    "\n",
    "    ===== ========= ===================================================\n",
    "    order  no copy                     copy=True\n",
    "    ===== ========= ===================================================\n",
    "    'K'   unchanged F & C order preserved, otherwise most similar order\n",
    "    'A'   unchanged F order if input is F and not C, otherwise C order\n",
    "    'C'   C order   C order\n",
    "    'F'   F order   F order\n",
    "    ===== ========= ===================================================\n",
    "\n",
    "    When ``copy=False`` and a copy is made for other reasons, the result is\n",
    "    the same as if ``copy=True``, with some exceptions for 'A', see the\n",
    "    Notes section. The default order is 'K'.\n",
    "subok : bool, optional\n",
    "    If True, then sub-classes will be passed-through, otherwise\n",
    "    the returned array will be forced to be a base-class array (default).\n",
    "ndmin : int, optional\n",
    "    Specifies the minimum number of dimensions that the resulting\n",
    "    array should have.  Ones will be prepended to the shape as\n",
    "    needed to meet this requirement.\n",
    "like : array_like, optional\n",
    "    Reference object to allow the creation of arrays which are not\n",
    "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
    "    the ``__array_function__`` protocol, the result will be defined\n",
    "    by it. In this case, it ensures the creation of an array object\n",
    "    compatible with that passed in via this argument.\n",
    "\n",
    "    .. versionadded:: 1.20.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    An array object satisfying the specified requirements.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "empty_like : Return an empty array with shape and type of input.\n",
    "ones_like : Return an array of ones with shape and type of input.\n",
    "zeros_like : Return an array of zeros with shape and type of input.\n",
    "full_like : Return a new array with shape of input filled with value.\n",
    "empty : Return a new uninitialized array.\n",
    "ones : Return a new array setting values to one.\n",
    "zeros : Return a new array setting values to zero.\n",
    "full : Return a new array of given shape filled with value.\n",
    "\n",
    "\n",
    "Notes\n",
    "-----\n",
    "When order is 'A' and `object` is an array in neither 'C' nor 'F' order,\n",
    "and a copy is forced by a change in dtype, then the order of the result is\n",
    "not necessarily 'C' as expected. This is likely a bug.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> np.array([1, 2, 3])\n",
    "array([1, 2, 3])\n",
    "\n",
    "Upcasting:\n",
    "\n",
    ">>> np.array([1, 2, 3.0])\n",
    "array([ 1.,  2.,  3.])\n",
    "\n",
    "More than one dimension:\n",
    "\n",
    ">>> np.array([[1, 2], [3, 4]])\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "\n",
    "Minimum dimensions 2:\n",
    "\n",
    ">>> np.array([1, 2, 3], ndmin=2)\n",
    "array([[1, 2, 3]])\n",
    "\n",
    "Type provided:\n",
    "\n",
    ">>> np.array([1, 2, 3], dtype=complex)\n",
    "array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
    "\n",
    "Data-type consisting of more than one element:\n",
    "\n",
    ">>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
    ">>> x['a']\n",
    "array([1, 3])\n",
    "\n",
    "Creating an array from sub-classes:\n",
    "\n",
    ">>> np.array(np.mat('1 2; 3 4'))\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "\n",
    ">>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
    "matrix([[1, 2],\n",
    "        [3, 4]])\n",
    "\n",
    "</code>\n",
    "<a href='#21'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40456343",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "order = np.array(scl.hierarchy.dendrogram(link_mat, no_plot=True, get_leaves=True)['leaves'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa094786",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>22. Data Preparation</h3>  <a id='22'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30718ec9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "order[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44604ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>23. Model Building and Training</h3>  <a id='23'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.fcluster</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Form flat clusters from the hierarchical clustering defined by\n",
    "the given linkage matrix.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded with the matrix returned\n",
    "    by the `linkage` function.\n",
    "t : scalar\n",
    "    For criteria 'inconsistent', 'distance' or 'monocrit',\n",
    "     this is the threshold to apply when forming flat clusters.\n",
    "    For 'maxclust' or 'maxclust_monocrit' criteria,\n",
    "     this would be max number of clusters requested.\n",
    "criterion : str, optional\n",
    "    The criterion to use in forming flat clusters. This can\n",
    "    be any of the following values:\n",
    "\n",
    "      ``inconsistent`` :\n",
    "          If a cluster node and all its\n",
    "          descendants have an inconsistent value less than or equal\n",
    "          to `t`, then all its leaf descendants belong to the\n",
    "          same flat cluster. When no non-singleton cluster meets\n",
    "          this criterion, every node is assigned to its own\n",
    "          cluster. (Default)\n",
    "\n",
    "      ``distance`` :\n",
    "          Forms flat clusters so that the original\n",
    "          observations in each flat cluster have no greater a\n",
    "          cophenetic distance than `t`.\n",
    "\n",
    "      ``maxclust`` :\n",
    "          Finds a minimum threshold ``r`` so that\n",
    "          the cophenetic distance between any two original\n",
    "          observations in the same flat cluster is no more than\n",
    "          ``r`` and no more than `t` flat clusters are formed.\n",
    "\n",
    "      ``monocrit`` :\n",
    "          Forms a flat cluster from a cluster node c\n",
    "          with index i when ``monocrit[j] <= t``.\n",
    "\n",
    "          For example, to threshold on the maximum mean distance\n",
    "          as computed in the inconsistency matrix R with a\n",
    "          threshold of 0.8 do::\n",
    "\n",
    "              MR = maxRstat(Z, R, 3)\n",
    "              fcluster(Z, t=0.8, criterion='monocrit', monocrit=MR)\n",
    "\n",
    "      ``maxclust_monocrit`` :\n",
    "          Forms a flat cluster from a\n",
    "          non-singleton cluster node ``c`` when ``monocrit[i] <=\n",
    "          r`` for all cluster indices ``i`` below and including\n",
    "          ``c``. ``r`` is minimized such that no more than ``t``\n",
    "          flat clusters are formed. monocrit must be\n",
    "          monotonic. For example, to minimize the threshold t on\n",
    "          maximum inconsistency values so that no more than 3 flat\n",
    "          clusters are formed, do::\n",
    "\n",
    "              MI = maxinconsts(Z, R)\n",
    "              fcluster(Z, t=3, criterion='maxclust_monocrit', monocrit=MI)\n",
    "depth : int, optional\n",
    "    The maximum depth to perform the inconsistency calculation.\n",
    "    It has no meaning for the other criteria. Default is 2.\n",
    "R : ndarray, optional\n",
    "    The inconsistency matrix to use for the 'inconsistent'\n",
    "    criterion. This matrix is computed if not provided.\n",
    "monocrit : ndarray, optional\n",
    "    An array of length n-1. `monocrit[i]` is the\n",
    "    statistics upon which non-singleton i is thresholded. The\n",
    "    monocrit vector must be monotonic, i.e., given a node c with\n",
    "    index i, for all node indices j corresponding to nodes\n",
    "    below c, ``monocrit[i] >= monocrit[j]``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "fcluster : ndarray\n",
    "    An array of length ``n``. ``T[i]`` is the flat cluster number to\n",
    "    which original observation ``i`` belongs.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage : for information about hierarchical clustering methods work.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import ward, fcluster\n",
    ">>> from scipy.spatial.distance import pdist\n",
    "\n",
    "All cluster linkage methods - e.g., `scipy.cluster.hierarchy.ward`\n",
    "generate a linkage matrix ``Z`` as their output:\n",
    "\n",
    ">>> X = [[0, 0], [0, 1], [1, 0],\n",
    "...      [0, 4], [0, 3], [1, 4],\n",
    "...      [4, 0], [3, 0], [4, 1],\n",
    "...      [4, 4], [3, 4], [4, 3]]\n",
    "\n",
    ">>> Z = ward(pdist(X))\n",
    "\n",
    ">>> Z\n",
    "array([[ 0.        ,  1.        ,  1.        ,  2.        ],\n",
    "       [ 3.        ,  4.        ,  1.        ,  2.        ],\n",
    "       [ 6.        ,  7.        ,  1.        ,  2.        ],\n",
    "       [ 9.        , 10.        ,  1.        ,  2.        ],\n",
    "       [ 2.        , 12.        ,  1.29099445,  3.        ],\n",
    "       [ 5.        , 13.        ,  1.29099445,  3.        ],\n",
    "       [ 8.        , 14.        ,  1.29099445,  3.        ],\n",
    "       [11.        , 15.        ,  1.29099445,  3.        ],\n",
    "       [16.        , 17.        ,  5.77350269,  6.        ],\n",
    "       [18.        , 19.        ,  5.77350269,  6.        ],\n",
    "       [20.        , 21.        ,  8.16496581, 12.        ]])\n",
    "\n",
    "This matrix represents a dendrogram, where the first and second elements\n",
    "are the two clusters merged at each step, the third element is the\n",
    "distance between these clusters, and the fourth element is the size of\n",
    "the new cluster - the number of original data points included.\n",
    "\n",
    "`scipy.cluster.hierarchy.fcluster` can be used to flatten the\n",
    "dendrogram, obtaining as a result an assignation of the original data\n",
    "points to single clusters.\n",
    "\n",
    "This assignation mostly depends on a distance threshold ``t`` - the maximum\n",
    "inter-cluster distance allowed:\n",
    "\n",
    ">>> fcluster(Z, t=0.9, criterion='distance')\n",
    "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=1.1, criterion='distance')\n",
    "array([1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=3, criterion='distance')\n",
    "array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=9, criterion='distance')\n",
    "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)\n",
    "\n",
    "In the first case, the threshold ``t`` is too small to allow any two\n",
    "samples in the data to form a cluster, so 12 different clusters are\n",
    "returned.\n",
    "\n",
    "In the second case, the threshold is large enough to allow the first\n",
    "4 points to be merged with their nearest neighbors. So, here, only 8\n",
    "clusters are returned.\n",
    "\n",
    "The third case, with a much higher threshold, allows for up to 8 data\n",
    "points to be connected - so 4 clusters are returned here.\n",
    "\n",
    "Lastly, the threshold of the fourth case is large enough to allow for\n",
    "all data points to be merged together - so a single cluster is returned.\n",
    "\n",
    "</code>\n",
    "<a href='#23'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf4392",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "part = scl.hierarchy.fcluster(link_mat, 5, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb1978",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>24. Data Preparation</h3>  <a id='24'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core._multiarray_umath.where</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "where(condition, [x, y], /)\n",
    "\n",
    "Return elements chosen from `x` or `y` depending on `condition`.\n",
    "\n",
    ".. note::\n",
    "    When only `condition` is provided, this function is a shorthand for\n",
    "    ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n",
    "    preferred, as it behaves correctly for subclasses. The rest of this\n",
    "    documentation covers only the case where all three arguments are\n",
    "    provided.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "condition : array_like, bool\n",
    "    Where True, yield `x`, otherwise yield `y`.\n",
    "x, y : array_like\n",
    "    Values from which to choose. `x`, `y` and `condition` need to be\n",
    "    broadcastable to some shape.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    An array with elements from `x` where `condition` is True, and elements\n",
    "    from `y` elsewhere.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "choose\n",
    "nonzero : The function that is called when x and y are omitted\n",
    "\n",
    "Notes\n",
    "-----\n",
    "If all the arrays are 1-D, `where` is equivalent to::\n",
    "\n",
    "    [xv if c else yv\n",
    "     for c, xv, yv in zip(condition, x, y)]\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> a = np.arange(10)\n",
    ">>> a\n",
    "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    ">>> np.where(a < 5, a, 10*a)\n",
    "array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n",
    "\n",
    "This can be used on multidimensional arrays too:\n",
    "\n",
    ">>> np.where([[True, False], [True, True]],\n",
    "...          [[1, 2], [3, 4]],\n",
    "...          [[9, 8], [7, 6]])\n",
    "array([[1, 8],\n",
    "       [3, 4]])\n",
    "\n",
    "The shapes of x, y, and the condition are broadcast together:\n",
    "\n",
    ">>> x, y = np.ogrid[:3, :4]\n",
    ">>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n",
    "array([[10,  0,  0,  0],\n",
    "       [10, 11,  1,  1],\n",
    "       [10, 11, 12,  2]])\n",
    "\n",
    ">>> a = np.array([[0, 1, 2],\n",
    "...               [0, 2, 4],\n",
    "...               [0, 3, 6]])\n",
    ">>> np.where(a < 4, a, -1)  # -1 is broadcast\n",
    "array([[ 0,  1,  2],\n",
    "       [ 0,  2, -1],\n",
    "       [ 0,  3, -1]])\n",
    "\n",
    "</code>\n",
    "<a href='#24'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d43ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "np.where(part==5)[0]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59b4c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>25. Data Preparation</h3>  <a id='25'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core.fromnumeric.around</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Evenly round to the given number of decimals.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : array_like\n",
    "    Input data.\n",
    "decimals : int, optional\n",
    "    Number of decimal places to round to (default: 0).  If\n",
    "    decimals is negative, it specifies the number of positions to\n",
    "    the left of the decimal point.\n",
    "out : ndarray, optional\n",
    "    Alternative output array in which to place the result. It must have\n",
    "    the same shape as the expected output, but the type of the output\n",
    "    values will be cast if necessary. See :ref:`ufuncs-output-type` for more\n",
    "    details.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rounded_array : ndarray\n",
    "    An array of the same type as `a`, containing the rounded values.\n",
    "    Unless `out` was specified, a new array is created.  A reference to\n",
    "    the result is returned.\n",
    "\n",
    "    The real and imaginary parts of complex numbers are rounded\n",
    "    separately.  The result of rounding a float is a float.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "ndarray.round : equivalent method\n",
    "\n",
    "ceil, fix, floor, rint, trunc\n",
    "\n",
    "\n",
    "Notes\n",
    "-----\n",
    "For values exactly halfway between rounded decimal values, NumPy\n",
    "rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n",
    "-0.5 and 0.5 round to 0.0, etc.\n",
    "\n",
    "``np.around`` uses a fast but sometimes inexact algorithm to round\n",
    "floating-point datatypes. For positive `decimals` it is equivalent to\n",
    "``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has\n",
    "error due to the inexact representation of decimal fractions in the IEEE\n",
    "floating point standard [1]_ and errors introduced when scaling by powers\n",
    "of ten. For instance, note the extra \"1\" in the following:\n",
    "\n",
    "    >>> np.round(56294995342131.5, 3)\n",
    "    56294995342131.51\n",
    "\n",
    "If your goal is to print such values with a fixed number of decimals, it is\n",
    "preferable to use numpy's float printing routines to limit the number of\n",
    "printed decimals:\n",
    "\n",
    "    >>> np.format_float_positional(56294995342131.5, precision=3)\n",
    "    '56294995342131.5'\n",
    "\n",
    "The float printing routines use an accurate but much more computationally\n",
    "demanding algorithm to compute the number of digits after the decimal\n",
    "point.\n",
    "\n",
    "Alternatively, Python's builtin `round` function uses a more accurate\n",
    "but slower algorithm for 64-bit floating point values:\n",
    "\n",
    "    >>> round(56294995342131.5, 3)\n",
    "    56294995342131.5\n",
    "    >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997\n",
    "    (16.06, 16.05)\n",
    "\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] \"Lecture Notes on the Status of IEEE 754\", William Kahan,\n",
    "       https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> np.around([0.37, 1.64])\n",
    "array([0., 2.])\n",
    ">>> np.around([0.37, 1.64], decimals=1)\n",
    "array([0.4, 1.6])\n",
    ">>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value\n",
    "array([0., 2., 2., 4., 4.])\n",
    ">>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned\n",
    "array([ 1,  2,  3, 11])\n",
    ">>> np.around([1,2,3,11], decimals=-1)\n",
    "array([ 0,  0,  0, 10])\n",
    "\n",
    "</code>\n",
    "<a href='#25'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0cb26",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rr = np.around(R, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e72b09",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>26. Model Building and Training</h3>  <a id='26'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.linkage</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Perform hierarchical/agglomerative clustering.\n",
    "\n",
    "The input y may be either a 1-D condensed distance matrix\n",
    "or a 2-D array of observation vectors.\n",
    "\n",
    "If y is a 1-D condensed distance matrix,\n",
    "then y must be a :math:`\\binom{n}{2}` sized\n",
    "vector, where n is the number of original observations paired\n",
    "in the distance matrix. The behavior of this function is very\n",
    "similar to the MATLAB linkage function.\n",
    "\n",
    "A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
    ":math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
    "``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
    "cluster with an index less than :math:`n` corresponds to one of\n",
    "the :math:`n` original observations. The distance between\n",
    "clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
    "fourth value ``Z[i, 3]`` represents the number of original\n",
    "observations in the newly formed cluster.\n",
    "\n",
    "The following linkage methods are used to compute the distance\n",
    ":math:`d(s, t)` between two clusters :math:`s` and\n",
    ":math:`t`. The algorithm begins with a forest of clusters that\n",
    "have yet to be used in the hierarchy being formed. When two\n",
    "clusters :math:`s` and :math:`t` from this forest are combined\n",
    "into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
    "removed from the forest, and :math:`u` is added to the\n",
    "forest. When only one cluster remains in the forest, the algorithm\n",
    "stops, and this cluster becomes the root.\n",
    "\n",
    "A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
    "entry corresponds to the distance between cluster :math:`i` and\n",
    ":math:`j` in the original forest.\n",
    "\n",
    "At each iteration, the algorithm must update the distance matrix\n",
    "to reflect the distance of the newly formed cluster u with the\n",
    "remaining clusters in the forest.\n",
    "\n",
    "Suppose there are :math:`|u|` original observations\n",
    ":math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
    ":math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
    "cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n",
    "combined to form cluster :math:`u`. Let :math:`v` be any\n",
    "remaining cluster in the forest that is not :math:`u`.\n",
    "\n",
    "The following are methods for calculating the distance between the\n",
    "newly formed cluster :math:`u` and each :math:`v`.\n",
    "\n",
    "  * method='single' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\min(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster :math:`u` and\n",
    "    :math:`j` in cluster :math:`v`. This is also known as the\n",
    "    Nearest Point Algorithm.\n",
    "\n",
    "  * method='complete' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u, v) = \\max(dist(u[i],v[j]))\n",
    "\n",
    "    for all points :math:`i` in cluster u and :math:`j` in\n",
    "    cluster :math:`v`. This is also known by the Farthest Point\n",
    "    Algorithm or Voor Hees Algorithm.\n",
    "\n",
    "  * method='average' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
    "                               {(|u|*|v|)}\n",
    "\n",
    "    for all points :math:`i` and :math:`j` where :math:`|u|`\n",
    "    and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
    "    and :math:`v`, respectively. This is also called the UPGMA\n",
    "    algorithm.\n",
    "\n",
    "  * method='weighted' assigns\n",
    "\n",
    "    .. math::\n",
    "       d(u,v) = (dist(s,v) + dist(t,v))/2\n",
    "\n",
    "    where cluster u was formed with cluster s and t and v\n",
    "    is a remaining cluster in the forest (also called WPGMA).\n",
    "\n",
    "  * method='centroid' assigns\n",
    "\n",
    "    .. math::\n",
    "       dist(s,t) = ||c_s-c_t||_2\n",
    "\n",
    "    where :math:`c_s` and :math:`c_t` are the centroids of\n",
    "    clusters :math:`s` and :math:`t`, respectively. When two\n",
    "    clusters :math:`s` and :math:`t` are combined into a new\n",
    "    cluster :math:`u`, the new centroid is computed over all the\n",
    "    original objects in clusters :math:`s` and :math:`t`. The\n",
    "    distance then becomes the Euclidean distance between the\n",
    "    centroid of :math:`u` and the centroid of a remaining cluster\n",
    "    :math:`v` in the forest. This is also known as the UPGMC\n",
    "    algorithm.\n",
    "\n",
    "  * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
    "    method. When two clusters :math:`s` and :math:`t` are combined\n",
    "    into a new cluster :math:`u`, the average of centroids s and t\n",
    "    give the new centroid :math:`u`. This is also known as the\n",
    "    WPGMC algorithm.\n",
    "\n",
    "  * method='ward' uses the Ward variance minimization algorithm.\n",
    "    The new entry :math:`d(u,v)` is computed as follows,\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
    "                           {T}d(v,s)^2\n",
    "                    + \\frac{|v|+|t|}\n",
    "                           {T}d(v,t)^2\n",
    "                    - \\frac{|v|}\n",
    "                           {T}d(s,t)^2}\n",
    "\n",
    "    where :math:`u` is the newly joined cluster consisting of\n",
    "    clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
    "    cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
    "    :math:`|*|` is the cardinality of its argument. This is also\n",
    "    known as the incremental algorithm.\n",
    "\n",
    "Warning: When the minimum distance pair in the forest is chosen, there\n",
    "may be two or more pairs with the same minimum distance. This\n",
    "implementation may choose a different minimum than the MATLAB\n",
    "version.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "y : ndarray\n",
    "    A condensed distance matrix. A condensed distance matrix\n",
    "    is a flat array containing the upper triangular of the distance matrix.\n",
    "    This is the form that ``pdist`` returns. Alternatively, a collection of\n",
    "    :math:`m` observation vectors in :math:`n` dimensions may be passed as\n",
    "    an :math:`m` by :math:`n` array. All elements of the condensed distance\n",
    "    matrix must be finite, i.e., no NaNs or infs.\n",
    "method : str, optional\n",
    "    The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
    "    for full descriptions.\n",
    "metric : str or function, optional\n",
    "    The distance metric to use in the case that y is a collection of\n",
    "    observation vectors; ignored otherwise. See the ``pdist``\n",
    "    function for a list of valid distance metrics. A custom distance\n",
    "    function can also be used.\n",
    "optimal_ordering : bool, optional\n",
    "    If True, the linkage matrix will be reordered so that the distance\n",
    "    between successive leaves is minimal. This results in a more intuitive\n",
    "    tree structure when the data are visualized. defaults to False, because\n",
    "    this algorithm can be slow, particularly on large datasets [2]_. See\n",
    "    also the `optimal_leaf_ordering` function.\n",
    "\n",
    "    .. versionadded:: 1.0.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded as a linkage matrix.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "1. For method 'single', an optimized algorithm based on minimum spanning\n",
    "   tree is implemented. It has time complexity :math:`O(n^2)`.\n",
    "   For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n",
    "   called nearest-neighbors chain is implemented. It also has time\n",
    "   complexity :math:`O(n^2)`.\n",
    "   For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n",
    "   time complexity.\n",
    "   All algorithms use :math:`O(n^2)` memory.\n",
    "   Refer to [1]_ for details about the algorithms.\n",
    "2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n",
    "   Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
    "   pairwise distances, then it is the user's responsibility to assure that\n",
    "   these distances are in fact Euclidean, otherwise the produced result\n",
    "   will be incorrect.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "scipy.spatial.distance.pdist : pairwise distance metrics\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
    "       algorithms\", :arXiv:`1109.2378v1`.\n",
    ".. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n",
    "       leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n",
    "       :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import dendrogram, linkage\n",
    ">>> from matplotlib import pyplot as plt\n",
    ">>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "\n",
    ">>> Z = linkage(X, 'ward')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    "\n",
    ">>> Z = linkage(X, 'single')\n",
    ">>> fig = plt.figure(figsize=(25, 10))\n",
    ">>> dn = dendrogram(Z)\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#26'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad14a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r_link = scl.hierarchy.linkage(rr, method='ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc0330",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>27. Data Preparation | Visualization</h3>  <a id='27'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.dendrogram</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Plot the hierarchical clustering as a dendrogram.\n",
    "\n",
    "The dendrogram illustrates how each cluster is\n",
    "composed by drawing a U-shaped link between a non-singleton\n",
    "cluster and its children. The top of the U-link indicates a\n",
    "cluster merge. The two legs of the U-link indicate which clusters\n",
    "were merged. The length of the two legs of the U-link represents\n",
    "the distance between the child clusters. It is also the\n",
    "cophenetic distance between original observations in the two\n",
    "children clusters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The linkage matrix encoding the hierarchical clustering to\n",
    "    render as a dendrogram. See the ``linkage`` function for more\n",
    "    information on the format of ``Z``.\n",
    "p : int, optional\n",
    "    The ``p`` parameter for ``truncate_mode``.\n",
    "truncate_mode : str, optional\n",
    "    The dendrogram can be hard to read when the original\n",
    "    observation matrix from which the linkage is derived is\n",
    "    large. Truncation is used to condense the dendrogram. There\n",
    "    are several modes:\n",
    "\n",
    "    ``None``\n",
    "      No truncation is performed (default).\n",
    "      Note: ``'none'`` is an alias for ``None`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "    ``'lastp'``\n",
    "      The last ``p`` non-singleton clusters formed in the linkage are the\n",
    "      only non-leaf nodes in the linkage; they correspond to rows\n",
    "      ``Z[n-p-2:end]`` in ``Z``. All other non-singleton clusters are\n",
    "      contracted into leaf nodes.\n",
    "\n",
    "    ``'level'``\n",
    "      No more than ``p`` levels of the dendrogram tree are displayed.\n",
    "      A \"level\" includes all nodes with ``p`` merges from the final merge.\n",
    "\n",
    "      Note: ``'mtica'`` is an alias for ``'level'`` that's kept for\n",
    "      backward compatibility.\n",
    "\n",
    "color_threshold : double, optional\n",
    "    For brevity, let :math:`t` be the ``color_threshold``.\n",
    "    Colors all the descendent links below a cluster node\n",
    "    :math:`k` the same color if :math:`k` is the first node below\n",
    "    the cut threshold :math:`t`. All links connecting nodes with\n",
    "    distances greater than or equal to the threshold are colored\n",
    "    with de default matplotlib color ``'C0'``. If :math:`t` is less\n",
    "    than or equal to zero, all nodes are colored ``'C0'``.\n",
    "    If ``color_threshold`` is None or 'default',\n",
    "    corresponding with MATLAB(TM) behavior, the threshold is set to\n",
    "    ``0.7*max(Z[:,2])``.\n",
    "\n",
    "get_leaves : bool, optional\n",
    "    Includes a list ``R['leaves']=H`` in the result\n",
    "    dictionary. For each :math:`i`, ``H[i] == j``, cluster node\n",
    "    ``j`` appears in position ``i`` in the left-to-right traversal\n",
    "    of the leaves, where :math:`j < 2n-1` and :math:`i < n`.\n",
    "orientation : str, optional\n",
    "    The direction to plot the dendrogram, which can be any\n",
    "    of the following strings:\n",
    "\n",
    "    ``'top'``\n",
    "      Plots the root at the top, and plot descendent links going downwards.\n",
    "      (default).\n",
    "\n",
    "    ``'bottom'``\n",
    "      Plots the root at the bottom, and plot descendent links going\n",
    "      upwards.\n",
    "\n",
    "    ``'left'``\n",
    "      Plots the root at the left, and plot descendent links going right.\n",
    "\n",
    "    ``'right'``\n",
    "      Plots the root at the right, and plot descendent links going left.\n",
    "\n",
    "labels : ndarray, optional\n",
    "    By default, ``labels`` is None so the index of the original observation\n",
    "    is used to label the leaf nodes.  Otherwise, this is an :math:`n`-sized\n",
    "    sequence, with ``n == Z.shape[0] + 1``. The ``labels[i]`` value is the\n",
    "    text to put under the :math:`i` th leaf node only if it corresponds to\n",
    "    an original observation and not a non-singleton cluster.\n",
    "count_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum number of original objects in its cluster\n",
    "      is plotted first.\n",
    "\n",
    "    Note, ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "distance_sort : str or bool, optional\n",
    "    For each node n, the order (visually, from left-to-right) n's\n",
    "    two descendent links are plotted is determined by this\n",
    "    parameter, which can be any of the following values:\n",
    "\n",
    "    ``False``\n",
    "      Nothing is done.\n",
    "\n",
    "    ``'ascending'`` or ``True``\n",
    "      The child with the minimum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    ``'descending'``\n",
    "      The child with the maximum distance between its direct descendents is\n",
    "      plotted first.\n",
    "\n",
    "    Note ``distance_sort`` and ``count_sort`` cannot both be True.\n",
    "show_leaf_counts : bool, optional\n",
    "     When True, leaf nodes representing :math:`k>1` original\n",
    "     observation are labeled with the number of observations they\n",
    "     contain in parentheses.\n",
    "no_plot : bool, optional\n",
    "    When True, the final rendering is not performed. This is\n",
    "    useful if only the data structures computed for the rendering\n",
    "    are needed or if matplotlib is not available.\n",
    "no_labels : bool, optional\n",
    "    When True, no labels appear next to the leaf nodes in the\n",
    "    rendering of the dendrogram.\n",
    "leaf_rotation : double, optional\n",
    "    Specifies the angle (in degrees) to rotate the leaf\n",
    "    labels. When unspecified, the rotation is based on the number of\n",
    "    nodes in the dendrogram (default is 0).\n",
    "leaf_font_size : int, optional\n",
    "    Specifies the font size (in points) of the leaf labels. When\n",
    "    unspecified, the size based on the number of nodes in the\n",
    "    dendrogram.\n",
    "leaf_label_func : lambda or function, optional\n",
    "    When ``leaf_label_func`` is a callable function, for each\n",
    "    leaf with cluster index :math:`k < 2n-1`. The function\n",
    "    is expected to return a string with the label for the\n",
    "    leaf.\n",
    "\n",
    "    Indices :math:`k < n` correspond to original observations\n",
    "    while indices :math:`k \\geq n` correspond to non-singleton\n",
    "    clusters.\n",
    "\n",
    "    For example, to label singletons with their node id and\n",
    "    non-singletons with their id, count, and inconsistency\n",
    "    coefficient, simply do::\n",
    "\n",
    "        # First define the leaf label function.\n",
    "        def llf(id):\n",
    "            if id < n:\n",
    "                return str(id)\n",
    "            else:\n",
    "                return '[%d %d %1.2f]' % (id, count, R[n-id,3])\n",
    "\n",
    "        # The text for the leaf nodes is going to be big so force\n",
    "        # a rotation of 90 degrees.\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90)\n",
    "\n",
    "        # leaf_label_func can also be used together with ``truncate_mode`` parameter,\n",
    "        # in which case you will get your leaves labeled after truncation:\n",
    "        dendrogram(Z, leaf_label_func=llf, leaf_rotation=90,\n",
    "                   truncate_mode='level', p=2)\n",
    "\n",
    "show_contracted : bool, optional\n",
    "    When True the heights of non-singleton nodes contracted\n",
    "    into a leaf node are plotted as crosses along the link\n",
    "    connecting that leaf node.  This really is only useful when\n",
    "    truncation is used (see ``truncate_mode`` parameter).\n",
    "link_color_func : callable, optional\n",
    "    If given, `link_color_function` is called with each non-singleton id\n",
    "    corresponding to each U-shaped link it will paint. The function is\n",
    "    expected to return the color to paint the link, encoded as a matplotlib\n",
    "    color string code. For example::\n",
    "\n",
    "        dendrogram(Z, link_color_func=lambda k: colors[k])\n",
    "\n",
    "    colors the direct links below each untruncated non-singleton node\n",
    "    ``k`` using ``colors[k]``.\n",
    "ax : matplotlib Axes instance, optional\n",
    "    If None and `no_plot` is not True, the dendrogram will be plotted\n",
    "    on the current axes.  Otherwise if `no_plot` is not True the\n",
    "    dendrogram will be plotted on the given ``Axes`` instance. This can be\n",
    "    useful if the dendrogram is part of a more complex figure.\n",
    "above_threshold_color : str, optional\n",
    "    This matplotlib color string sets the color of the links above the\n",
    "    color_threshold. The default is ``'C0'``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "R : dict\n",
    "    A dictionary of data structures computed to render the\n",
    "    dendrogram. Its has the following keys:\n",
    "\n",
    "    ``'color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th link.\n",
    "\n",
    "    ``'icoord'`` and ``'dcoord'``\n",
    "      Each of them is a list of lists. Let ``icoord = [I1, I2, ..., Ip]``\n",
    "      where ``Ik = [xk1, xk2, xk3, xk4]`` and ``dcoord = [D1, D2, ..., Dp]``\n",
    "      where ``Dk = [yk1, yk2, yk3, yk4]``, then the k'th link painted is\n",
    "      ``(xk1, yk1)`` - ``(xk2, yk2)`` - ``(xk3, yk3)`` - ``(xk4, yk4)``.\n",
    "\n",
    "    ``'ivl'``\n",
    "      A list of labels corresponding to the leaf nodes.\n",
    "\n",
    "    ``'leaves'``\n",
    "      For each i, ``H[i] == j``, cluster node ``j`` appears in position\n",
    "      ``i`` in the left-to-right traversal of the leaves, where\n",
    "      :math:`j < 2n-1` and :math:`i < n`. If ``j`` is less than ``n``, the\n",
    "      ``i``-th leaf node corresponds to an original observation.\n",
    "      Otherwise, it corresponds to a non-singleton cluster.\n",
    "\n",
    "    ``'leaves_color_list'``\n",
    "      A list of color names. The k'th element represents the color of the\n",
    "      k'th leaf.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage, set_link_color_palette\n",
    "\n",
    "Notes\n",
    "-----\n",
    "It is expected that the distances in ``Z[:,2]`` be monotonic, otherwise\n",
    "crossings appear in the dendrogram.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import numpy as np\n",
    ">>> from scipy.cluster import hierarchy\n",
    ">>> import matplotlib.pyplot as plt\n",
    "\n",
    "A very basic example:\n",
    "\n",
    ">>> ytdist = np.array([662., 877., 255., 412., 996., 295., 468., 268.,\n",
    "...                    400., 754., 564., 138., 219., 869., 669.])\n",
    ">>> Z = hierarchy.linkage(ytdist, 'single')\n",
    ">>> plt.figure()\n",
    ">>> dn = hierarchy.dendrogram(Z)\n",
    "\n",
    "Now, plot in given axes, improve the color scheme and use both vertical and\n",
    "horizontal orientations:\n",
    "\n",
    ">>> hierarchy.set_link_color_palette(['m', 'c', 'y', 'k'])\n",
    ">>> fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    ">>> dn1 = hierarchy.dendrogram(Z, ax=axes[0], above_threshold_color='y',\n",
    "...                            orientation='top')\n",
    ">>> dn2 = hierarchy.dendrogram(Z, ax=axes[1],\n",
    "...                            above_threshold_color='#bcbddc',\n",
    "...                            orientation='right')\n",
    ">>> hierarchy.set_link_color_palette(None)  # reset to default after use\n",
    ">>> plt.show()\n",
    "\n",
    "</code>\n",
    "<a href='#27'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.array</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
    "      like=None)\n",
    "\n",
    "Create an array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "object : array_like\n",
    "    An array, any object exposing the array interface, an object whose\n",
    "    __array__ method returns an array, or any (nested) sequence.\n",
    "    If object is a scalar, a 0-dimensional array containing object is\n",
    "    returned.\n",
    "dtype : data-type, optional\n",
    "    The desired data-type for the array.  If not given, then the type will\n",
    "    be determined as the minimum type required to hold the objects in the\n",
    "    sequence.\n",
    "copy : bool, optional\n",
    "    If true (default), then the object is copied.  Otherwise, a copy will\n",
    "    only be made if __array__ returns a copy, if obj is a nested sequence,\n",
    "    or if a copy is needed to satisfy any of the other requirements\n",
    "    (`dtype`, `order`, etc.).\n",
    "order : {'K', 'A', 'C', 'F'}, optional\n",
    "    Specify the memory layout of the array. If object is not an array, the\n",
    "    newly created array will be in C order (row major) unless 'F' is\n",
    "    specified, in which case it will be in Fortran order (column major).\n",
    "    If object is an array the following holds.\n",
    "\n",
    "    ===== ========= ===================================================\n",
    "    order  no copy                     copy=True\n",
    "    ===== ========= ===================================================\n",
    "    'K'   unchanged F & C order preserved, otherwise most similar order\n",
    "    'A'   unchanged F order if input is F and not C, otherwise C order\n",
    "    'C'   C order   C order\n",
    "    'F'   F order   F order\n",
    "    ===== ========= ===================================================\n",
    "\n",
    "    When ``copy=False`` and a copy is made for other reasons, the result is\n",
    "    the same as if ``copy=True``, with some exceptions for 'A', see the\n",
    "    Notes section. The default order is 'K'.\n",
    "subok : bool, optional\n",
    "    If True, then sub-classes will be passed-through, otherwise\n",
    "    the returned array will be forced to be a base-class array (default).\n",
    "ndmin : int, optional\n",
    "    Specifies the minimum number of dimensions that the resulting\n",
    "    array should have.  Ones will be prepended to the shape as\n",
    "    needed to meet this requirement.\n",
    "like : array_like, optional\n",
    "    Reference object to allow the creation of arrays which are not\n",
    "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
    "    the ``__array_function__`` protocol, the result will be defined\n",
    "    by it. In this case, it ensures the creation of an array object\n",
    "    compatible with that passed in via this argument.\n",
    "\n",
    "    .. versionadded:: 1.20.0\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    An array object satisfying the specified requirements.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "empty_like : Return an empty array with shape and type of input.\n",
    "ones_like : Return an array of ones with shape and type of input.\n",
    "zeros_like : Return an array of zeros with shape and type of input.\n",
    "full_like : Return a new array with shape of input filled with value.\n",
    "empty : Return a new uninitialized array.\n",
    "ones : Return a new array setting values to one.\n",
    "zeros : Return a new array setting values to zero.\n",
    "full : Return a new array of given shape filled with value.\n",
    "\n",
    "\n",
    "Notes\n",
    "-----\n",
    "When order is 'A' and `object` is an array in neither 'C' nor 'F' order,\n",
    "and a copy is forced by a change in dtype, then the order of the result is\n",
    "not necessarily 'C' as expected. This is likely a bug.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> np.array([1, 2, 3])\n",
    "array([1, 2, 3])\n",
    "\n",
    "Upcasting:\n",
    "\n",
    ">>> np.array([1, 2, 3.0])\n",
    "array([ 1.,  2.,  3.])\n",
    "\n",
    "More than one dimension:\n",
    "\n",
    ">>> np.array([[1, 2], [3, 4]])\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "\n",
    "Minimum dimensions 2:\n",
    "\n",
    ">>> np.array([1, 2, 3], ndmin=2)\n",
    "array([[1, 2, 3]])\n",
    "\n",
    "Type provided:\n",
    "\n",
    ">>> np.array([1, 2, 3], dtype=complex)\n",
    "array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
    "\n",
    "Data-type consisting of more than one element:\n",
    "\n",
    ">>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
    ">>> x['a']\n",
    "array([1, 3])\n",
    "\n",
    "Creating an array from sub-classes:\n",
    "\n",
    ">>> np.array(np.mat('1 2; 3 4'))\n",
    "array([[1, 2],\n",
    "       [3, 4]])\n",
    "\n",
    ">>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
    "matrix([[1, 2],\n",
    "        [3, 4]])\n",
    "\n",
    "</code>\n",
    "<a href='#27'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e980ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r_order = np.array(scl.hierarchy.dendrogram(r_link, no_plot=True, get_leaves=True)['leaves'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f909a37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>28. Model Building and Training</h3>  <a id='28'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>scipy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>scipy.cluster.hierarchy.fcluster</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Form flat clusters from the hierarchical clustering defined by\n",
    "the given linkage matrix.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Z : ndarray\n",
    "    The hierarchical clustering encoded with the matrix returned\n",
    "    by the `linkage` function.\n",
    "t : scalar\n",
    "    For criteria 'inconsistent', 'distance' or 'monocrit',\n",
    "     this is the threshold to apply when forming flat clusters.\n",
    "    For 'maxclust' or 'maxclust_monocrit' criteria,\n",
    "     this would be max number of clusters requested.\n",
    "criterion : str, optional\n",
    "    The criterion to use in forming flat clusters. This can\n",
    "    be any of the following values:\n",
    "\n",
    "      ``inconsistent`` :\n",
    "          If a cluster node and all its\n",
    "          descendants have an inconsistent value less than or equal\n",
    "          to `t`, then all its leaf descendants belong to the\n",
    "          same flat cluster. When no non-singleton cluster meets\n",
    "          this criterion, every node is assigned to its own\n",
    "          cluster. (Default)\n",
    "\n",
    "      ``distance`` :\n",
    "          Forms flat clusters so that the original\n",
    "          observations in each flat cluster have no greater a\n",
    "          cophenetic distance than `t`.\n",
    "\n",
    "      ``maxclust`` :\n",
    "          Finds a minimum threshold ``r`` so that\n",
    "          the cophenetic distance between any two original\n",
    "          observations in the same flat cluster is no more than\n",
    "          ``r`` and no more than `t` flat clusters are formed.\n",
    "\n",
    "      ``monocrit`` :\n",
    "          Forms a flat cluster from a cluster node c\n",
    "          with index i when ``monocrit[j] <= t``.\n",
    "\n",
    "          For example, to threshold on the maximum mean distance\n",
    "          as computed in the inconsistency matrix R with a\n",
    "          threshold of 0.8 do::\n",
    "\n",
    "              MR = maxRstat(Z, R, 3)\n",
    "              fcluster(Z, t=0.8, criterion='monocrit', monocrit=MR)\n",
    "\n",
    "      ``maxclust_monocrit`` :\n",
    "          Forms a flat cluster from a\n",
    "          non-singleton cluster node ``c`` when ``monocrit[i] <=\n",
    "          r`` for all cluster indices ``i`` below and including\n",
    "          ``c``. ``r`` is minimized such that no more than ``t``\n",
    "          flat clusters are formed. monocrit must be\n",
    "          monotonic. For example, to minimize the threshold t on\n",
    "          maximum inconsistency values so that no more than 3 flat\n",
    "          clusters are formed, do::\n",
    "\n",
    "              MI = maxinconsts(Z, R)\n",
    "              fcluster(Z, t=3, criterion='maxclust_monocrit', monocrit=MI)\n",
    "depth : int, optional\n",
    "    The maximum depth to perform the inconsistency calculation.\n",
    "    It has no meaning for the other criteria. Default is 2.\n",
    "R : ndarray, optional\n",
    "    The inconsistency matrix to use for the 'inconsistent'\n",
    "    criterion. This matrix is computed if not provided.\n",
    "monocrit : ndarray, optional\n",
    "    An array of length n-1. `monocrit[i]` is the\n",
    "    statistics upon which non-singleton i is thresholded. The\n",
    "    monocrit vector must be monotonic, i.e., given a node c with\n",
    "    index i, for all node indices j corresponding to nodes\n",
    "    below c, ``monocrit[i] >= monocrit[j]``.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "fcluster : ndarray\n",
    "    An array of length ``n``. ``T[i]`` is the flat cluster number to\n",
    "    which original observation ``i`` belongs.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "linkage : for information about hierarchical clustering methods work.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> from scipy.cluster.hierarchy import ward, fcluster\n",
    ">>> from scipy.spatial.distance import pdist\n",
    "\n",
    "All cluster linkage methods - e.g., `scipy.cluster.hierarchy.ward`\n",
    "generate a linkage matrix ``Z`` as their output:\n",
    "\n",
    ">>> X = [[0, 0], [0, 1], [1, 0],\n",
    "...      [0, 4], [0, 3], [1, 4],\n",
    "...      [4, 0], [3, 0], [4, 1],\n",
    "...      [4, 4], [3, 4], [4, 3]]\n",
    "\n",
    ">>> Z = ward(pdist(X))\n",
    "\n",
    ">>> Z\n",
    "array([[ 0.        ,  1.        ,  1.        ,  2.        ],\n",
    "       [ 3.        ,  4.        ,  1.        ,  2.        ],\n",
    "       [ 6.        ,  7.        ,  1.        ,  2.        ],\n",
    "       [ 9.        , 10.        ,  1.        ,  2.        ],\n",
    "       [ 2.        , 12.        ,  1.29099445,  3.        ],\n",
    "       [ 5.        , 13.        ,  1.29099445,  3.        ],\n",
    "       [ 8.        , 14.        ,  1.29099445,  3.        ],\n",
    "       [11.        , 15.        ,  1.29099445,  3.        ],\n",
    "       [16.        , 17.        ,  5.77350269,  6.        ],\n",
    "       [18.        , 19.        ,  5.77350269,  6.        ],\n",
    "       [20.        , 21.        ,  8.16496581, 12.        ]])\n",
    "\n",
    "This matrix represents a dendrogram, where the first and second elements\n",
    "are the two clusters merged at each step, the third element is the\n",
    "distance between these clusters, and the fourth element is the size of\n",
    "the new cluster - the number of original data points included.\n",
    "\n",
    "`scipy.cluster.hierarchy.fcluster` can be used to flatten the\n",
    "dendrogram, obtaining as a result an assignation of the original data\n",
    "points to single clusters.\n",
    "\n",
    "This assignation mostly depends on a distance threshold ``t`` - the maximum\n",
    "inter-cluster distance allowed:\n",
    "\n",
    ">>> fcluster(Z, t=0.9, criterion='distance')\n",
    "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=1.1, criterion='distance')\n",
    "array([1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=3, criterion='distance')\n",
    "array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4], dtype=int32)\n",
    "\n",
    ">>> fcluster(Z, t=9, criterion='distance')\n",
    "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)\n",
    "\n",
    "In the first case, the threshold ``t`` is too small to allow any two\n",
    "samples in the data to form a cluster, so 12 different clusters are\n",
    "returned.\n",
    "\n",
    "In the second case, the threshold is large enough to allow the first\n",
    "4 points to be merged with their nearest neighbors. So, here, only 8\n",
    "clusters are returned.\n",
    "\n",
    "The third case, with a much higher threshold, allows for up to 8 data\n",
    "points to be connected - so 4 clusters are returned here.\n",
    "\n",
    "Lastly, the threshold of the fourth case is large enough to allow for\n",
    "all data points to be merged together - so a single cluster is returned.\n",
    "\n",
    "</code>\n",
    "<a href='#28'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_part = scl.hierarchy.fcluster(r_link, 5, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa67bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r_part[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473198e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>30. Data Preparation</h3>  <a id='30'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>numpy</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>numpy.core._multiarray_umath.where</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "where(condition, [x, y], /)\n",
    "\n",
    "Return elements chosen from `x` or `y` depending on `condition`.\n",
    "\n",
    ".. note::\n",
    "    When only `condition` is provided, this function is a shorthand for\n",
    "    ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n",
    "    preferred, as it behaves correctly for subclasses. The rest of this\n",
    "    documentation covers only the case where all three arguments are\n",
    "    provided.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "condition : array_like, bool\n",
    "    Where True, yield `x`, otherwise yield `y`.\n",
    "x, y : array_like\n",
    "    Values from which to choose. `x`, `y` and `condition` need to be\n",
    "    broadcastable to some shape.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "out : ndarray\n",
    "    An array with elements from `x` where `condition` is True, and elements\n",
    "    from `y` elsewhere.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "choose\n",
    "nonzero : The function that is called when x and y are omitted\n",
    "\n",
    "Notes\n",
    "-----\n",
    "If all the arrays are 1-D, `where` is equivalent to::\n",
    "\n",
    "    [xv if c else yv\n",
    "     for c, xv, yv in zip(condition, x, y)]\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> a = np.arange(10)\n",
    ">>> a\n",
    "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    ">>> np.where(a < 5, a, 10*a)\n",
    "array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n",
    "\n",
    "This can be used on multidimensional arrays too:\n",
    "\n",
    ">>> np.where([[True, False], [True, True]],\n",
    "...          [[1, 2], [3, 4]],\n",
    "...          [[9, 8], [7, 6]])\n",
    "array([[1, 8],\n",
    "       [3, 4]])\n",
    "\n",
    "The shapes of x, y, and the condition are broadcast together:\n",
    "\n",
    ">>> x, y = np.ogrid[:3, :4]\n",
    ">>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n",
    "array([[10,  0,  0,  0],\n",
    "       [10, 11,  1,  1],\n",
    "       [10, 11, 12,  2]])\n",
    "\n",
    ">>> a = np.array([[0, 1, 2],\n",
    "...               [0, 2, 4],\n",
    "...               [0, 3, 6]])\n",
    ">>> np.where(a < 4, a, -1)  # -1 is broadcast\n",
    "array([[ 0,  1,  2],\n",
    "       [ 0,  2, -1],\n",
    "       [ 0,  3, -1]])\n",
    "\n",
    "</code>\n",
    "<a href='#30'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(r_part==5)[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e5206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
